 Loading feature files...
 <s> = 1
 </s> = 2
 All scenes loaded.
 Hyperparameters:Namespace(LR=0.01, alternatives=1, batch_size=100, dec='LSTM', dropout=0.0, epochs=20, hidden_sz=100, load=None, log_interval=10, model='s0', no_cuda=False, save=None, seed=1)
 Speaker0: Speaker0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=100)
  )
  (string_decoder): LSTMStringDecoder(
    (embedding): Embedding(1063, 100)
    (lstm): LSTM(100, 100, num_layers=2, batch_first=True)
    (linear): Linear(in_features=100, out_features=1063)
    (dropout): Dropout(p=0.0)
  )
)
 Training Speaker0...
 Epoch [1/20], Step[0/483], loss: 6.9985
 Epoch [1/20], Step[10/483], loss: 2.6626
 Epoch [1/20], Step[20/483], loss: 2.1435
 Epoch [1/20], Step[30/483], loss: 1.8411
 Epoch [1/20], Step[40/483], loss: 1.7735
 Epoch [1/20], Step[50/483], loss: 1.8183
 Epoch [1/20], Step[60/483], loss: 1.8052
 Epoch [1/20], Step[70/483], loss: 1.5266
 Epoch [1/20], Step[80/483], loss: 1.7012
 Epoch [1/20], Step[90/483], loss: 1.1539
 Epoch [1/20], Step[100/483], loss: 1.1415
 Epoch [1/20], Step[110/483], loss: 1.3090
 Epoch [1/20], Step[120/483], loss: 1.3660
 Epoch [1/20], Step[130/483], loss: 1.1378
 Epoch [1/20], Step[140/483], loss: 1.3071
 Epoch [1/20], Step[150/483], loss: 1.3533
 Epoch [1/20], Step[160/483], loss: 1.4739
 Epoch [1/20], Step[170/483], loss: 0.9745
 Epoch [1/20], Step[180/483], loss: 1.3291
 Epoch [1/20], Step[190/483], loss: 1.2767
 Epoch [1/20], Step[200/483], loss: 0.9198
 Epoch [1/20], Step[210/483], loss: 1.1654
 Epoch [1/20], Step[220/483], loss: 1.0063
 Epoch [1/20], Step[230/483], loss: 0.9204
 Epoch [1/20], Step[240/483], loss: 1.1741
 Epoch [1/20], Step[250/483], loss: 1.1697
 Epoch [1/20], Step[260/483], loss: 0.7679
 Epoch [1/20], Step[270/483], loss: 1.1465
 Epoch [1/20], Step[280/483], loss: 0.9759
 Epoch [1/20], Step[290/483], loss: 0.8238
 Epoch [1/20], Step[300/483], loss: 1.1735
 Epoch [1/20], Step[310/483], loss: 1.1564
 Epoch [1/20], Step[320/483], loss: 1.2067
 Epoch [1/20], Step[330/483], loss: 1.0946
 Epoch [1/20], Step[340/483], loss: 1.1486
 Epoch [1/20], Step[350/483], loss: 1.1106
 Epoch [1/20], Step[360/483], loss: 0.8437
 Epoch [1/20], Step[370/483], loss: 0.7162
 Epoch [1/20], Step[380/483], loss: 0.9813
 Epoch [1/20], Step[390/483], loss: 1.0933
 Epoch [1/20], Step[400/483], loss: 1.0396
 Epoch [1/20], Step[410/483], loss: 0.8203
 Epoch [1/20], Step[420/483], loss: 1.0114
 Epoch [1/20], Step[430/483], loss: 1.0054
 Epoch [1/20], Step[440/483], loss: 1.0391
 Epoch [1/20], Step[450/483], loss: 0.8637
 Epoch [1/20], Step[460/483], loss: 1.1382
 Epoch [1/20], Step[470/483], loss: 1.2345
 Epoch [1/20], Step[480/483], loss: 0.6951
 ====> Epoch 1: Training loss: 621.8966
 ====> Epoch 1: Validation loss: 62.3956
 Epoch [2/20], Step[0/483], loss: 0.8820
 Epoch [2/20], Step[10/483], loss: 1.0195
 Epoch [2/20], Step[20/483], loss: 1.0951
 Epoch [2/20], Step[30/483], loss: 1.0245
 Epoch [2/20], Step[40/483], loss: 1.0626
 Epoch [2/20], Step[50/483], loss: 1.1657
 Epoch [2/20], Step[60/483], loss: 1.2476
 Epoch [2/20], Step[70/483], loss: 1.1425
 Epoch [2/20], Step[80/483], loss: 1.2824
 Epoch [2/20], Step[90/483], loss: 0.8508
 Epoch [2/20], Step[100/483], loss: 0.8538
 Epoch [2/20], Step[110/483], loss: 1.0237
 Epoch [2/20], Step[120/483], loss: 1.1284
 Epoch [2/20], Step[130/483], loss: 0.9143
 Epoch [2/20], Step[140/483], loss: 1.0698
 Epoch [2/20], Step[150/483], loss: 1.0851
 Epoch [2/20], Step[160/483], loss: 1.2410
 Epoch [2/20], Step[170/483], loss: 0.8127
 Epoch [2/20], Step[180/483], loss: 1.1252
 Epoch [2/20], Step[190/483], loss: 1.1208
 Epoch [2/20], Step[200/483], loss: 0.8115
 Epoch [2/20], Step[210/483], loss: 0.9641
 Epoch [2/20], Step[220/483], loss: 0.8859
 Epoch [2/20], Step[230/483], loss: 0.7825
 Epoch [2/20], Step[240/483], loss: 1.0129
 Epoch [2/20], Step[250/483], loss: 1.0173
 Epoch [2/20], Step[260/483], loss: 0.6640
 Epoch [2/20], Step[270/483], loss: 0.9562
 Epoch [2/20], Step[280/483], loss: 0.8508
 Epoch [2/20], Step[290/483], loss: 0.7037
 Epoch [2/20], Step[300/483], loss: 1.0291
 Epoch [2/20], Step[310/483], loss: 1.0074
 Epoch [2/20], Step[320/483], loss: 1.0608
 Epoch [2/20], Step[330/483], loss: 0.9813
 Epoch [2/20], Step[340/483], loss: 1.0111
 Epoch [2/20], Step[350/483], loss: 0.9803
 Epoch [2/20], Step[360/483], loss: 0.7380
 Epoch [2/20], Step[370/483], loss: 0.6475
 Epoch [2/20], Step[380/483], loss: 0.8793
 Epoch [2/20], Step[390/483], loss: 0.9768
 Epoch [2/20], Step[400/483], loss: 0.9466
 Epoch [2/20], Step[410/483], loss: 0.7432
 Epoch [2/20], Step[420/483], loss: 0.8818
 Epoch [2/20], Step[430/483], loss: 0.9239
 Epoch [2/20], Step[440/483], loss: 0.9134
 Epoch [2/20], Step[450/483], loss: 0.7679
 Epoch [2/20], Step[460/483], loss: 1.0279
 Epoch [2/20], Step[470/483], loss: 1.0876
 Epoch [2/20], Step[480/483], loss: 0.6312
 ====> Epoch 2: Training loss: 475.4034
 ====> Epoch 2: Validation loss: 57.5250
 Epoch [3/20], Step[0/483], loss: 0.8100
 Epoch [3/20], Step[10/483], loss: 0.9082
 Epoch [3/20], Step[20/483], loss: 0.9802
 Epoch [3/20], Step[30/483], loss: 0.9105
 Epoch [3/20], Step[40/483], loss: 0.9433
 Epoch [3/20], Step[50/483], loss: 1.0316
 Epoch [3/20], Step[60/483], loss: 1.1197
 Epoch [3/20], Step[70/483], loss: 1.0479
 Epoch [3/20], Step[80/483], loss: 1.1767
 Epoch [3/20], Step[90/483], loss: 0.7813
 Epoch [3/20], Step[100/483], loss: 0.7944
 Epoch [3/20], Step[110/483], loss: 0.9446
 Epoch [3/20], Step[120/483], loss: 1.0437
 Epoch [3/20], Step[130/483], loss: 0.8462
 Epoch [3/20], Step[140/483], loss: 0.9922
 Epoch [3/20], Step[150/483], loss: 1.0137
 Epoch [3/20], Step[160/483], loss: 1.1215
 Epoch [3/20], Step[170/483], loss: 0.7372
 Epoch [3/20], Step[180/483], loss: 1.0379
 Epoch [3/20], Step[190/483], loss: 1.0398
 Epoch [3/20], Step[200/483], loss: 0.7540
 Epoch [3/20], Step[210/483], loss: 0.9088
 Epoch [3/20], Step[220/483], loss: 0.8326
 Epoch [3/20], Step[230/483], loss: 0.7422
 Epoch [3/20], Step[240/483], loss: 0.9389
 Epoch [3/20], Step[250/483], loss: 0.9560
 Epoch [3/20], Step[260/483], loss: 0.6248
 Epoch [3/20], Step[270/483], loss: 0.9025
 Epoch [3/20], Step[280/483], loss: 0.7893
 Epoch [3/20], Step[290/483], loss: 0.6642
 Epoch [3/20], Step[300/483], loss: 0.9511
 Epoch [3/20], Step[310/483], loss: 0.9430
 Epoch [3/20], Step[320/483], loss: 0.9935
 Epoch [3/20], Step[330/483], loss: 0.9193
 Epoch [3/20], Step[340/483], loss: 0.9247
 Epoch [3/20], Step[350/483], loss: 0.8916
 Epoch [3/20], Step[360/483], loss: 0.6758
 Epoch [3/20], Step[370/483], loss: 0.5988
 Epoch [3/20], Step[380/483], loss: 0.8206
 Epoch [3/20], Step[390/483], loss: 0.9094
 Epoch [3/20], Step[400/483], loss: 0.8654
 Epoch [3/20], Step[410/483], loss: 0.7077
 Epoch [3/20], Step[420/483], loss: 0.8246
 Epoch [3/20], Step[430/483], loss: 0.8658
 Epoch [3/20], Step[440/483], loss: 0.8393
 Epoch [3/20], Step[450/483], loss: 0.7057
 Epoch [3/20], Step[460/483], loss: 0.9500
 Epoch [3/20], Step[470/483], loss: 1.0173
 Epoch [3/20], Step[480/483], loss: 0.5950
 ====> Epoch 3: Training loss: 438.4940
 ====> Epoch 3: Validation loss: 55.6498
 Epoch [4/20], Step[0/483], loss: 0.7430
 Epoch [4/20], Step[10/483], loss: 0.8588
 Epoch [4/20], Step[20/483], loss: 0.9309
 Epoch [4/20], Step[30/483], loss: 0.8733
 Epoch [4/20], Step[40/483], loss: 0.8923
 Epoch [4/20], Step[50/483], loss: 0.9585
 Epoch [4/20], Step[60/483], loss: 1.0458
 Epoch [4/20], Step[70/483], loss: 0.9668
 Epoch [4/20], Step[80/483], loss: 1.1079
 Epoch [4/20], Step[90/483], loss: 0.7414
 Epoch [4/20], Step[100/483], loss: 0.7659
 Epoch [4/20], Step[110/483], loss: 0.8945
 Epoch [4/20], Step[120/483], loss: 0.9761
 Epoch [4/20], Step[130/483], loss: 0.8043
 Epoch [4/20], Step[140/483], loss: 0.9332
 Epoch [4/20], Step[150/483], loss: 0.9497
 Epoch [4/20], Step[160/483], loss: 1.0497
 Epoch [4/20], Step[170/483], loss: 0.6971
 Epoch [4/20], Step[180/483], loss: 1.0009
 Epoch [4/20], Step[190/483], loss: 0.9717
 Epoch [4/20], Step[200/483], loss: 0.7232
 Epoch [4/20], Step[210/483], loss: 0.8691
 Epoch [4/20], Step[220/483], loss: 0.7921
 Epoch [4/20], Step[230/483], loss: 0.7070
 Epoch [4/20], Step[240/483], loss: 0.8816
 Epoch [4/20], Step[250/483], loss: 0.9167
 Epoch [4/20], Step[260/483], loss: 0.5989
 Epoch [4/20], Step[270/483], loss: 0.8553
 Epoch [4/20], Step[280/483], loss: 0.7737
 Epoch [4/20], Step[290/483], loss: 0.6359
 Epoch [4/20], Step[300/483], loss: 0.9139
 Epoch [4/20], Step[310/483], loss: 0.8919
 Epoch [4/20], Step[320/483], loss: 0.9426
 Epoch [4/20], Step[330/483], loss: 0.8902
 Epoch [4/20], Step[340/483], loss: 0.8809
 Epoch [4/20], Step[350/483], loss: 0.8453
 Epoch [4/20], Step[360/483], loss: 0.6413
 Epoch [4/20], Step[370/483], loss: 0.5770
 Epoch [4/20], Step[380/483], loss: 0.7920
 Epoch [4/20], Step[390/483], loss: 0.8610
 Epoch [4/20], Step[400/483], loss: 0.8232
 Epoch [4/20], Step[410/483], loss: 0.6797
 Epoch [4/20], Step[420/483], loss: 0.7988
 Epoch [4/20], Step[430/483], loss: 0.8302
 Epoch [4/20], Step[440/483], loss: 0.8230
 Epoch [4/20], Step[450/483], loss: 0.6788
 Epoch [4/20], Step[460/483], loss: 0.9263
 Epoch [4/20], Step[470/483], loss: 0.9717
 Epoch [4/20], Step[480/483], loss: 0.5816
 ====> Epoch 4: Training loss: 416.9273
 ====> Epoch 4: Validation loss: 54.8834
 Epoch [5/20], Step[0/483], loss: 0.7049
 Epoch [5/20], Step[10/483], loss: 0.8309
 Epoch [5/20], Step[20/483], loss: 0.8952
 Epoch [5/20], Step[30/483], loss: 0.8418
 Epoch [5/20], Step[40/483], loss: 0.8527
 Epoch [5/20], Step[50/483], loss: 0.9034
 Epoch [5/20], Step[60/483], loss: 0.9998
 Epoch [5/20], Step[70/483], loss: 0.9385
 Epoch [5/20], Step[80/483], loss: 1.0629
 Epoch [5/20], Step[90/483], loss: 0.7138
 Epoch [5/20], Step[100/483], loss: 0.7384
 Epoch [5/20], Step[110/483], loss: 0.8626
 Epoch [5/20], Step[120/483], loss: 0.9371
 Epoch [5/20], Step[130/483], loss: 0.7721
 Epoch [5/20], Step[140/483], loss: 0.9050
 Epoch [5/20], Step[150/483], loss: 0.9148
 Epoch [5/20], Step[160/483], loss: 1.0084
 Epoch [5/20], Step[170/483], loss: 0.6659
 Epoch [5/20], Step[180/483], loss: 0.9669
 Epoch [5/20], Step[190/483], loss: 0.9322
 Epoch [5/20], Step[200/483], loss: 0.7050
 Epoch [5/20], Step[210/483], loss: 0.8310
 Epoch [5/20], Step[220/483], loss: 0.7683
 Epoch [5/20], Step[230/483], loss: 0.6866
 Epoch [5/20], Step[240/483], loss: 0.8634
 Epoch [5/20], Step[250/483], loss: 0.8888
 Epoch [5/20], Step[260/483], loss: 0.5900
 Epoch [5/20], Step[270/483], loss: 0.8436
 Epoch [5/20], Step[280/483], loss: 0.7495
 Epoch [5/20], Step[290/483], loss: 0.6268
 Epoch [5/20], Step[300/483], loss: 0.8937
 Epoch [5/20], Step[310/483], loss: 0.8656
 Epoch [5/20], Step[320/483], loss: 0.8985
 Epoch [5/20], Step[330/483], loss: 0.8729
 Epoch [5/20], Step[340/483], loss: 0.8641
 Epoch [5/20], Step[350/483], loss: 0.8363
 Epoch [5/20], Step[360/483], loss: 0.6269
 Epoch [5/20], Step[370/483], loss: 0.5570
 Epoch [5/20], Step[380/483], loss: 0.7643
 Epoch [5/20], Step[390/483], loss: 0.8209
 Epoch [5/20], Step[400/483], loss: 0.8043
 Epoch [5/20], Step[410/483], loss: 0.6764
 Epoch [5/20], Step[420/483], loss: 0.7754
 Epoch [5/20], Step[430/483], loss: 0.8152
 Epoch [5/20], Step[440/483], loss: 0.8034
 Epoch [5/20], Step[450/483], loss: 0.6729
 Epoch [5/20], Step[460/483], loss: 0.9097
 Epoch [5/20], Step[470/483], loss: 0.9598
 Epoch [5/20], Step[480/483], loss: 0.5634
 ====> Epoch 5: Training loss: 403.7762
 ====> Epoch 5: Validation loss: 54.6232
 Epoch [6/20], Step[0/483], loss: 0.6945
 Epoch [6/20], Step[10/483], loss: 0.8034
 Epoch [6/20], Step[20/483], loss: 0.8753
 Epoch [6/20], Step[30/483], loss: 0.8300
 Epoch [6/20], Step[40/483], loss: 0.8371
 Epoch [6/20], Step[50/483], loss: 0.9029
 Epoch [6/20], Step[60/483], loss: 0.9809
 Epoch [6/20], Step[70/483], loss: 0.8961
 Epoch [6/20], Step[80/483], loss: 1.0183
 Epoch [6/20], Step[90/483], loss: 0.6965
 Epoch [6/20], Step[100/483], loss: 0.7227
 Epoch [6/20], Step[110/483], loss: 0.8518
 Epoch [6/20], Step[120/483], loss: 0.9106
 Epoch [6/20], Step[130/483], loss: 0.7476
 Epoch [6/20], Step[140/483], loss: 0.8710
 Epoch [6/20], Step[150/483], loss: 0.8867
 Epoch [6/20], Step[160/483], loss: 0.9614
 Epoch [6/20], Step[170/483], loss: 0.6499
 Epoch [6/20], Step[180/483], loss: 0.9182
 Epoch [6/20], Step[190/483], loss: 0.9257
 Epoch [6/20], Step[200/483], loss: 0.6827
 Epoch [6/20], Step[210/483], loss: 0.8413
 Epoch [6/20], Step[220/483], loss: 0.7520
 Epoch [6/20], Step[230/483], loss: 0.6699
 Epoch [6/20], Step[240/483], loss: 0.8257
 Epoch [6/20], Step[250/483], loss: 0.8702
 Epoch [6/20], Step[260/483], loss: 0.5853
 Epoch [6/20], Step[270/483], loss: 0.8250
 Epoch [6/20], Step[280/483], loss: 0.7435
 Epoch [6/20], Step[290/483], loss: 0.6134
 Epoch [6/20], Step[300/483], loss: 0.8773
 Epoch [6/20], Step[310/483], loss: 0.8467
 Epoch [6/20], Step[320/483], loss: 0.8686
 Epoch [6/20], Step[330/483], loss: 0.8352
 Epoch [6/20], Step[340/483], loss: 0.8451
 Epoch [6/20], Step[350/483], loss: 0.8129
 Epoch [6/20], Step[360/483], loss: 0.6119
 Epoch [6/20], Step[370/483], loss: 0.5500
 Epoch [6/20], Step[380/483], loss: 0.7517
 Epoch [6/20], Step[390/483], loss: 0.8017
 Epoch [6/20], Step[400/483], loss: 0.7905
 Epoch [6/20], Step[410/483], loss: 0.6501
 Epoch [6/20], Step[420/483], loss: 0.7553
 Epoch [6/20], Step[430/483], loss: 0.7965
 Epoch [6/20], Step[440/483], loss: 0.7972
 Epoch [6/20], Step[450/483], loss: 0.6476
 Epoch [6/20], Step[460/483], loss: 0.8822
 Epoch [6/20], Step[470/483], loss: 0.9258
 Epoch [6/20], Step[480/483], loss: 0.5624
 ====> Epoch 6: Training loss: 393.9641
 ====> Epoch 6: Validation loss: 54.5337
 Epoch [7/20], Step[0/483], loss: 0.6907
 Epoch [7/20], Step[10/483], loss: 0.8023
 Epoch [7/20], Step[20/483], loss: 0.8510
 Epoch [7/20], Step[30/483], loss: 0.8076
 Epoch [7/20], Step[40/483], loss: 0.8260
 Epoch [7/20], Step[50/483], loss: 0.8838
 Epoch [7/20], Step[60/483], loss: 0.9458
 Epoch [7/20], Step[70/483], loss: 0.9233
 Epoch [7/20], Step[80/483], loss: 1.0083
 Epoch [7/20], Step[90/483], loss: 0.6871
 Epoch [7/20], Step[100/483], loss: 0.7116
 Epoch [7/20], Step[110/483], loss: 0.8454
 Epoch [7/20], Step[120/483], loss: 0.9061
 Epoch [7/20], Step[130/483], loss: 0.7376
 Epoch [7/20], Step[140/483], loss: 0.8636
 Epoch [7/20], Step[150/483], loss: 0.8762
 Epoch [7/20], Step[160/483], loss: 0.9529
 Epoch [7/20], Step[170/483], loss: 0.6428
 Epoch [7/20], Step[180/483], loss: 0.9178
 Epoch [7/20], Step[190/483], loss: 0.9067
 Epoch [7/20], Step[200/483], loss: 0.6728
 Epoch [7/20], Step[210/483], loss: 0.8125
 Epoch [7/20], Step[220/483], loss: 0.7516
 Epoch [7/20], Step[230/483], loss: 0.6665
 Epoch [7/20], Step[240/483], loss: 0.8130
 Epoch [7/20], Step[250/483], loss: 0.8683
 Epoch [7/20], Step[260/483], loss: 0.5749
 Epoch [7/20], Step[270/483], loss: 0.8189
 Epoch [7/20], Step[280/483], loss: 0.7410
 Epoch [7/20], Step[290/483], loss: 0.6036
 Epoch [7/20], Step[300/483], loss: 0.8404
 Epoch [7/20], Step[310/483], loss: 0.8424
 Epoch [7/20], Step[320/483], loss: 0.8435
 Epoch [7/20], Step[330/483], loss: 0.8230
 Epoch [7/20], Step[340/483], loss: 0.8470
 Epoch [7/20], Step[350/483], loss: 0.7954
 Epoch [7/20], Step[360/483], loss: 0.6015
 Epoch [7/20], Step[370/483], loss: 0.5373
 Epoch [7/20], Step[380/483], loss: 0.7357
 Epoch [7/20], Step[390/483], loss: 0.8082
 Epoch [7/20], Step[400/483], loss: 0.7697
 Epoch [7/20], Step[410/483], loss: 0.6472
 Epoch [7/20], Step[420/483], loss: 0.7375
 Epoch [7/20], Step[430/483], loss: 0.7843
 Epoch [7/20], Step[440/483], loss: 0.7885
 Epoch [7/20], Step[450/483], loss: 0.6428
 Epoch [7/20], Step[460/483], loss: 0.8570
 Epoch [7/20], Step[470/483], loss: 0.9254
 Epoch [7/20], Step[480/483], loss: 0.5616
 ====> Epoch 7: Training loss: 387.3440
 ====> Epoch 7: Validation loss: 54.4461
 Epoch [8/20], Step[0/483], loss: 0.6922
 Epoch [8/20], Step[10/483], loss: 0.8013
 Epoch [8/20], Step[20/483], loss: 0.8538
 Epoch [8/20], Step[30/483], loss: 0.7912
 Epoch [8/20], Step[40/483], loss: 0.8096
 Epoch [8/20], Step[50/483], loss: 0.8621
 Epoch [8/20], Step[60/483], loss: 0.9439
 Epoch [8/20], Step[70/483], loss: 0.9020
 Epoch [8/20], Step[80/483], loss: 0.9836
 Epoch [8/20], Step[90/483], loss: 0.6838
 Epoch [8/20], Step[100/483], loss: 0.7103
 Epoch [8/20], Step[110/483], loss: 0.8066
 Epoch [8/20], Step[120/483], loss: 0.9019
 Epoch [8/20], Step[130/483], loss: 0.7304
 Epoch [8/20], Step[140/483], loss: 0.8727
 Epoch [8/20], Step[150/483], loss: 0.8711
 Epoch [8/20], Step[160/483], loss: 0.9267
 Epoch [8/20], Step[170/483], loss: 0.6424
 Epoch [8/20], Step[180/483], loss: 0.9126
 Epoch [8/20], Step[190/483], loss: 0.9019
 Epoch [8/20], Step[200/483], loss: 0.6473
 Epoch [8/20], Step[210/483], loss: 0.8118
 Epoch [8/20], Step[220/483], loss: 0.7387
 Epoch [8/20], Step[230/483], loss: 0.6478
 Epoch [8/20], Step[240/483], loss: 0.7950
 Epoch [8/20], Step[250/483], loss: 0.8326
 Epoch [8/20], Step[260/483], loss: 0.5671
 Epoch [8/20], Step[270/483], loss: 0.8134
 Epoch [8/20], Step[280/483], loss: 0.7079
 Epoch [8/20], Step[290/483], loss: 0.5807
 Epoch [8/20], Step[300/483], loss: 0.8440
 Epoch [8/20], Step[310/483], loss: 0.8367
 Epoch [8/20], Step[320/483], loss: 0.8306
 Epoch [8/20], Step[330/483], loss: 0.8017
 Epoch [8/20], Step[340/483], loss: 0.8140
 Epoch [8/20], Step[350/483], loss: 0.7792
 Epoch [8/20], Step[360/483], loss: 0.5951
 Epoch [8/20], Step[370/483], loss: 0.5276
 Epoch [8/20], Step[380/483], loss: 0.7291
 Epoch [8/20], Step[390/483], loss: 0.7798
 Epoch [8/20], Step[400/483], loss: 0.7611
 Epoch [8/20], Step[410/483], loss: 0.6465
 Epoch [8/20], Step[420/483], loss: 0.7239
 Epoch [8/20], Step[430/483], loss: 0.7627
 Epoch [8/20], Step[440/483], loss: 0.7534
 Epoch [8/20], Step[450/483], loss: 0.6341
 Epoch [8/20], Step[460/483], loss: 0.8490
 Epoch [8/20], Step[470/483], loss: 0.9076
 Epoch [8/20], Step[480/483], loss: 0.5537
 ====> Epoch 8: Training loss: 381.3815
 ====> Epoch 8: Validation loss: 54.5936
 Epoch [9/20], Step[0/483], loss: 0.6716
 Epoch [9/20], Step[10/483], loss: 0.7711
 Epoch [9/20], Step[20/483], loss: 0.8355
 Epoch [9/20], Step[30/483], loss: 0.7891
 Epoch [9/20], Step[40/483], loss: 0.8117
 Epoch [9/20], Step[50/483], loss: 0.8277
 Epoch [9/20], Step[60/483], loss: 0.9523
 Epoch [9/20], Step[70/483], loss: 0.8668
 Epoch [9/20], Step[80/483], loss: 0.9718
 Epoch [9/20], Step[90/483], loss: 0.6714
 Epoch [9/20], Step[100/483], loss: 0.7076
 Epoch [9/20], Step[110/483], loss: 0.7977
 Epoch [9/20], Step[120/483], loss: 0.8777
 Epoch [9/20], Step[130/483], loss: 0.7220
 Epoch [9/20], Step[140/483], loss: 0.8382
 Epoch [9/20], Step[150/483], loss: 0.8520
 Epoch [9/20], Step[160/483], loss: 0.9229
 Epoch [9/20], Step[170/483], loss: 0.6327
 Epoch [9/20], Step[180/483], loss: 0.8882
 Epoch [9/20], Step[190/483], loss: 0.9061
 Epoch [9/20], Step[200/483], loss: 0.6495
 Epoch [9/20], Step[210/483], loss: 0.8001
 Epoch [9/20], Step[220/483], loss: 0.7400
 Epoch [9/20], Step[230/483], loss: 0.6436
 Epoch [9/20], Step[240/483], loss: 0.7679
 Epoch [9/20], Step[250/483], loss: 0.8200
 Epoch [9/20], Step[260/483], loss: 0.5608
 Epoch [9/20], Step[270/483], loss: 0.7898
 Epoch [9/20], Step[280/483], loss: 0.7096
 Epoch [9/20], Step[290/483], loss: 0.5765
 Epoch [9/20], Step[300/483], loss: 0.8189
 Epoch [9/20], Step[310/483], loss: 0.8038
 Epoch [9/20], Step[320/483], loss: 0.8176
 Epoch [9/20], Step[330/483], loss: 0.8069
 Epoch [9/20], Step[340/483], loss: 0.8176
 Epoch [9/20], Step[350/483], loss: 0.7613
 Epoch [9/20], Step[360/483], loss: 0.5982
 Epoch [9/20], Step[370/483], loss: 0.5258
 Epoch [9/20], Step[380/483], loss: 0.7110
 Epoch [9/20], Step[390/483], loss: 0.7630
 Epoch [9/20], Step[400/483], loss: 0.7594
 Epoch [9/20], Step[410/483], loss: 0.6359
 Epoch [9/20], Step[420/483], loss: 0.7287
 Epoch [9/20], Step[430/483], loss: 0.7398
 Epoch [9/20], Step[440/483], loss: 0.7596
 Epoch [9/20], Step[450/483], loss: 0.6364
 Epoch [9/20], Step[460/483], loss: 0.8278
 Epoch [9/20], Step[470/483], loss: 0.8819
 Epoch [9/20], Step[480/483], loss: 0.5453
 ====> Epoch 9: Training loss: 376.7688
 ====> Epoch 9: Validation loss: 54.7697
 Epoch [10/20], Step[0/483], loss: 0.6695
 Epoch [10/20], Step[10/483], loss: 0.7520
 Epoch [10/20], Step[20/483], loss: 0.8138
 Epoch [10/20], Step[30/483], loss: 0.7949
 Epoch [10/20], Step[40/483], loss: 0.8104
 Epoch [10/20], Step[50/483], loss: 0.8227
 Epoch [10/20], Step[60/483], loss: 0.9335
 Epoch [10/20], Step[70/483], loss: 0.8593
 Epoch [10/20], Step[80/483], loss: 0.9642
 Epoch [10/20], Step[90/483], loss: 0.6587
 Epoch [10/20], Step[100/483], loss: 0.6781
 Epoch [10/20], Step[110/483], loss: 0.8002
 Epoch [10/20], Step[120/483], loss: 0.8705
 Epoch [10/20], Step[130/483], loss: 0.7088
 Epoch [10/20], Step[140/483], loss: 0.8241
 Epoch [10/20], Step[150/483], loss: 0.8379
 Epoch [10/20], Step[160/483], loss: 0.9114
 Epoch [10/20], Step[170/483], loss: 0.6367
 Epoch [10/20], Step[180/483], loss: 0.8907
 Epoch [10/20], Step[190/483], loss: 0.8911
 Epoch [10/20], Step[200/483], loss: 0.6531
 Epoch [10/20], Step[210/483], loss: 0.7985
 Epoch [10/20], Step[220/483], loss: 0.7353
 Epoch [10/20], Step[230/483], loss: 0.6450
 Epoch [10/20], Step[240/483], loss: 0.7589
 Epoch [10/20], Step[250/483], loss: 0.8183
 Epoch [10/20], Step[260/483], loss: 0.5670
 Epoch [10/20], Step[270/483], loss: 0.7893
 Epoch [10/20], Step[280/483], loss: 0.7066
 Epoch [10/20], Step[290/483], loss: 0.5680
 Epoch [10/20], Step[300/483], loss: 0.8068
 Epoch [10/20], Step[310/483], loss: 0.7853
 Epoch [10/20], Step[320/483], loss: 0.8059
 Epoch [10/20], Step[330/483], loss: 0.7912
 Epoch [10/20], Step[340/483], loss: 0.7948
 Epoch [10/20], Step[350/483], loss: 0.7424
 Epoch [10/20], Step[360/483], loss: 0.5892
 Epoch [10/20], Step[370/483], loss: 0.5074
 Epoch [10/20], Step[380/483], loss: 0.7111
 Epoch [10/20], Step[390/483], loss: 0.7660
 Epoch [10/20], Step[400/483], loss: 0.7400
 Epoch [10/20], Step[410/483], loss: 0.6208
 Epoch [10/20], Step[420/483], loss: 0.7289
 Epoch [10/20], Step[430/483], loss: 0.7372
 Epoch [10/20], Step[440/483], loss: 0.7551
 Epoch [10/20], Step[450/483], loss: 0.6380
 Epoch [10/20], Step[460/483], loss: 0.8367
 Epoch [10/20], Step[470/483], loss: 0.8679
 Epoch [10/20], Step[480/483], loss: 0.5403
 ====> Epoch 10: Training loss: 371.9960
 ====> Epoch 10: Validation loss: 54.7456
 Epoch [11/20], Step[0/483], loss: 0.6612
 Epoch [11/20], Step[10/483], loss: 0.7263
 Epoch [11/20], Step[20/483], loss: 0.8217
 Epoch [11/20], Step[30/483], loss: 0.7699
 Epoch [11/20], Step[40/483], loss: 0.7979
 Epoch [11/20], Step[50/483], loss: 0.8246
 Epoch [11/20], Step[60/483], loss: 0.9036
 Epoch [11/20], Step[70/483], loss: 0.8451
 Epoch [11/20], Step[80/483], loss: 0.9483
 Epoch [11/20], Step[90/483], loss: 0.6525
 Epoch [11/20], Step[100/483], loss: 0.6972
 Epoch [11/20], Step[110/483], loss: 0.7985
 Epoch [11/20], Step[120/483], loss: 0.8620
 Epoch [11/20], Step[130/483], loss: 0.6998
 Epoch [11/20], Step[140/483], loss: 0.8301
 Epoch [11/20], Step[150/483], loss: 0.8605
 Epoch [11/20], Step[160/483], loss: 0.8935
 Epoch [11/20], Step[170/483], loss: 0.6123
 Epoch [11/20], Step[180/483], loss: 0.8865
 Epoch [11/20], Step[190/483], loss: 0.8826
 Epoch [11/20], Step[200/483], loss: 0.6466
 Epoch [11/20], Step[210/483], loss: 0.8079
 Epoch [11/20], Step[220/483], loss: 0.7242
 Epoch [11/20], Step[230/483], loss: 0.6368
 Epoch [11/20], Step[240/483], loss: 0.7692
 Epoch [11/20], Step[250/483], loss: 0.7912
 Epoch [11/20], Step[260/483], loss: 0.5565
 Epoch [11/20], Step[270/483], loss: 0.7774
 Epoch [11/20], Step[280/483], loss: 0.7065
 Epoch [11/20], Step[290/483], loss: 0.5759
 Epoch [11/20], Step[300/483], loss: 0.8036
 Epoch [11/20], Step[310/483], loss: 0.7903
 Epoch [11/20], Step[320/483], loss: 0.8029
 Epoch [11/20], Step[330/483], loss: 0.7984
 Epoch [11/20], Step[340/483], loss: 0.7837
 Epoch [11/20], Step[350/483], loss: 0.7343
 Epoch [11/20], Step[360/483], loss: 0.5788
 Epoch [11/20], Step[370/483], loss: 0.5234
 Epoch [11/20], Step[380/483], loss: 0.7034
 Epoch [11/20], Step[390/483], loss: 0.7643
 Epoch [11/20], Step[400/483], loss: 0.7348
 Epoch [11/20], Step[410/483], loss: 0.6245
 Epoch [11/20], Step[420/483], loss: 0.7034
 Epoch [11/20], Step[430/483], loss: 0.7430
 Epoch [11/20], Step[440/483], loss: 0.7673
 Epoch [11/20], Step[450/483], loss: 0.6245
 Epoch [11/20], Step[460/483], loss: 0.8171
 Epoch [11/20], Step[470/483], loss: 0.8971
 Epoch [11/20], Step[480/483], loss: 0.5394
 ====> Epoch 11: Training loss: 369.6732
 ====> Epoch 11: Validation loss: 54.8543
 Epoch [12/20], Step[0/483], loss: 0.6606
 Epoch [12/20], Step[10/483], loss: 0.7315
 Epoch [12/20], Step[20/483], loss: 0.7987
 Epoch [12/20], Step[30/483], loss: 0.7647
 Epoch [12/20], Step[40/483], loss: 0.7647
 Epoch [12/20], Step[50/483], loss: 0.8282
 Epoch [12/20], Step[60/483], loss: 0.8986
 Epoch [12/20], Step[70/483], loss: 0.8345
 Epoch [12/20], Step[80/483], loss: 0.9365
 Epoch [12/20], Step[90/483], loss: 0.6442
 Epoch [12/20], Step[100/483], loss: 0.6753
 Epoch [12/20], Step[110/483], loss: 0.7976
 Epoch [12/20], Step[120/483], loss: 0.8728
 Epoch [12/20], Step[130/483], loss: 0.6988
 Epoch [12/20], Step[140/483], loss: 0.8255
 Epoch [12/20], Step[150/483], loss: 0.8371
 Epoch [12/20], Step[160/483], loss: 0.8645
 Epoch [12/20], Step[170/483], loss: 0.6158
 Epoch [12/20], Step[180/483], loss: 0.8813
 Epoch [12/20], Step[190/483], loss: 0.8840
 Epoch [12/20], Step[200/483], loss: 0.6251
 Epoch [12/20], Step[210/483], loss: 0.7883
 Epoch [12/20], Step[220/483], loss: 0.7276
 Epoch [12/20], Step[230/483], loss: 0.6360
 Epoch [12/20], Step[240/483], loss: 0.7691
 Epoch [12/20], Step[250/483], loss: 0.8229
 Epoch [12/20], Step[260/483], loss: 0.5460
 Epoch [12/20], Step[270/483], loss: 0.7811
 Epoch [12/20], Step[280/483], loss: 0.6866
 Epoch [12/20], Step[290/483], loss: 0.5666
 Epoch [12/20], Step[300/483], loss: 0.7877
 Epoch [12/20], Step[310/483], loss: 0.7963
 Epoch [12/20], Step[320/483], loss: 0.7907
 Epoch [12/20], Step[330/483], loss: 0.7731
 Epoch [12/20], Step[340/483], loss: 0.7754
 Epoch [12/20], Step[350/483], loss: 0.7523
 Epoch [12/20], Step[360/483], loss: 0.5686
 Epoch [12/20], Step[370/483], loss: 0.5155
 Epoch [12/20], Step[380/483], loss: 0.7072
 Epoch [12/20], Step[390/483], loss: 0.7442
 Epoch [12/20], Step[400/483], loss: 0.7330
 Epoch [12/20], Step[410/483], loss: 0.6205
 Epoch [12/20], Step[420/483], loss: 0.6993
 Epoch [12/20], Step[430/483], loss: 0.7481
 Epoch [12/20], Step[440/483], loss: 0.7334
 Epoch [12/20], Step[450/483], loss: 0.6371
 Epoch [12/20], Step[460/483], loss: 0.8250
 Epoch [12/20], Step[470/483], loss: 0.8800
 Epoch [12/20], Step[480/483], loss: 0.5279
 ====> Epoch 12: Training loss: 367.3085
 ====> Epoch 12: Validation loss: 54.9791
 Epoch [13/20], Step[0/483], loss: 0.6526
 Epoch [13/20], Step[10/483], loss: 0.7430
 Epoch [13/20], Step[20/483], loss: 0.8002
 Epoch [13/20], Step[30/483], loss: 0.7638
 Epoch [13/20], Step[40/483], loss: 0.7851
 Epoch [13/20], Step[50/483], loss: 0.8117
 Epoch [13/20], Step[60/483], loss: 0.8920
 Epoch [13/20], Step[70/483], loss: 0.8398
 Epoch [13/20], Step[80/483], loss: 0.9442
 Epoch [13/20], Step[90/483], loss: 0.6427
 Epoch [13/20], Step[100/483], loss: 0.6811
 Epoch [13/20], Step[110/483], loss: 0.7810
 Epoch [13/20], Step[120/483], loss: 0.8379
 Epoch [13/20], Step[130/483], loss: 0.7195
 Epoch [13/20], Step[140/483], loss: 0.8078
 Epoch [13/20], Step[150/483], loss: 0.8457
 Epoch [13/20], Step[160/483], loss: 0.8635
 Epoch [13/20], Step[170/483], loss: 0.6156
 Epoch [13/20], Step[180/483], loss: 0.8655
 Epoch [13/20], Step[190/483], loss: 0.8883
 Epoch [13/20], Step[200/483], loss: 0.6329
 Epoch [13/20], Step[210/483], loss: 0.7851
 Epoch [13/20], Step[220/483], loss: 0.7099
 Epoch [13/20], Step[230/483], loss: 0.6206
 Epoch [13/20], Step[240/483], loss: 0.7434
 Epoch [13/20], Step[250/483], loss: 0.8101
 Epoch [13/20], Step[260/483], loss: 0.5635
 Epoch [13/20], Step[270/483], loss: 0.7713
 Epoch [13/20], Step[280/483], loss: 0.6813
 Epoch [13/20], Step[290/483], loss: 0.5617
 Epoch [13/20], Step[300/483], loss: 0.7824
 Epoch [13/20], Step[310/483], loss: 0.7803
 Epoch [13/20], Step[320/483], loss: 0.7763
 Epoch [13/20], Step[330/483], loss: 0.7875
 Epoch [13/20], Step[340/483], loss: 0.7835
 Epoch [13/20], Step[350/483], loss: 0.7430
 Epoch [13/20], Step[360/483], loss: 0.5739
 Epoch [13/20], Step[370/483], loss: 0.5077
 Epoch [13/20], Step[380/483], loss: 0.6742
 Epoch [13/20], Step[390/483], loss: 0.7309
 Epoch [13/20], Step[400/483], loss: 0.7375
 Epoch [13/20], Step[410/483], loss: 0.6146
 Epoch [13/20], Step[420/483], loss: 0.6949
 Epoch [13/20], Step[430/483], loss: 0.7197
 Epoch [13/20], Step[440/483], loss: 0.7448
 Epoch [13/20], Step[450/483], loss: 0.6198
 Epoch [13/20], Step[460/483], loss: 0.8097
 Epoch [13/20], Step[470/483], loss: 0.8731
 Epoch [13/20], Step[480/483], loss: 0.5231
 ====> Epoch 13: Training loss: 364.6408
 ====> Epoch 13: Validation loss: 54.7338
 Epoch [14/20], Step[0/483], loss: 0.6374
 Epoch [14/20], Step[10/483], loss: 0.7424
 Epoch [14/20], Step[20/483], loss: 0.7885
 Epoch [14/20], Step[30/483], loss: 0.7565
 Epoch [14/20], Step[40/483], loss: 0.7732
 Epoch [14/20], Step[50/483], loss: 0.8278
 Epoch [14/20], Step[60/483], loss: 0.9035
 Epoch [14/20], Step[70/483], loss: 0.8331
 Epoch [14/20], Step[80/483], loss: 0.9068
 Epoch [14/20], Step[90/483], loss: 0.6381
 Epoch [14/20], Step[100/483], loss: 0.6658
 Epoch [14/20], Step[110/483], loss: 0.7557
 Epoch [14/20], Step[120/483], loss: 0.8491
 Epoch [14/20], Step[130/483], loss: 0.7066
 Epoch [14/20], Step[140/483], loss: 0.8102
 Epoch [14/20], Step[150/483], loss: 0.8246
 Epoch [14/20], Step[160/483], loss: 0.8658
 Epoch [14/20], Step[170/483], loss: 0.6024
 Epoch [14/20], Step[180/483], loss: 0.8630
 Epoch [14/20], Step[190/483], loss: 0.8769
 Epoch [14/20], Step[200/483], loss: 0.6218
 Epoch [14/20], Step[210/483], loss: 0.7698
 Epoch [14/20], Step[220/483], loss: 0.6963
 Epoch [14/20], Step[230/483], loss: 0.6207
 Epoch [14/20], Step[240/483], loss: 0.7610
 Epoch [14/20], Step[250/483], loss: 0.8129
 Epoch [14/20], Step[260/483], loss: 0.5443
 Epoch [14/20], Step[270/483], loss: 0.7600
 Epoch [14/20], Step[280/483], loss: 0.6834
 Epoch [14/20], Step[290/483], loss: 0.5549
 Epoch [14/20], Step[300/483], loss: 0.7888
 Epoch [14/20], Step[310/483], loss: 0.7860
 Epoch [14/20], Step[320/483], loss: 0.7616
 Epoch [14/20], Step[330/483], loss: 0.7680
 Epoch [14/20], Step[340/483], loss: 0.7777
 Epoch [14/20], Step[350/483], loss: 0.7395
 Epoch [14/20], Step[360/483], loss: 0.5843
 Epoch [14/20], Step[370/483], loss: 0.5211
 Epoch [14/20], Step[380/483], loss: 0.6804
 Epoch [14/20], Step[390/483], loss: 0.7254
 Epoch [14/20], Step[400/483], loss: 0.7211
 Epoch [14/20], Step[410/483], loss: 0.5983
 Epoch [14/20], Step[420/483], loss: 0.6985
 Epoch [14/20], Step[430/483], loss: 0.7300
 Epoch [14/20], Step[440/483], loss: 0.7211
 Epoch [14/20], Step[450/483], loss: 0.6056
 Epoch [14/20], Step[460/483], loss: 0.8115
 Epoch [14/20], Step[470/483], loss: 0.8662
 Epoch [14/20], Step[480/483], loss: 0.5247
 ====> Epoch 14: Training loss: 361.0825
 ====> Epoch 14: Validation loss: 54.8048
 Epoch [15/20], Step[0/483], loss: 0.6594
 Epoch [15/20], Step[10/483], loss: 0.7212
 Epoch [15/20], Step[20/483], loss: 0.7790
 Epoch [15/20], Step[30/483], loss: 0.7395
 Epoch [15/20], Step[40/483], loss: 0.7913
 Epoch [15/20], Step[50/483], loss: 0.8183
 Epoch [15/20], Step[60/483], loss: 0.9115
 Epoch [15/20], Step[70/483], loss: 0.8132
 Epoch [15/20], Step[80/483], loss: 0.9022
 Epoch [15/20], Step[90/483], loss: 0.6422
 Epoch [15/20], Step[100/483], loss: 0.6662
 Epoch [15/20], Step[110/483], loss: 0.7523
 Epoch [15/20], Step[120/483], loss: 0.8386
 Epoch [15/20], Step[130/483], loss: 0.7062
 Epoch [15/20], Step[140/483], loss: 0.8084
 Epoch [15/20], Step[150/483], loss: 0.8040
 Epoch [15/20], Step[160/483], loss: 0.8661
 Epoch [15/20], Step[170/483], loss: 0.6026
 Epoch [15/20], Step[180/483], loss: 0.8806
 Epoch [15/20], Step[190/483], loss: 0.8689
 Epoch [15/20], Step[200/483], loss: 0.6399
 Epoch [15/20], Step[210/483], loss: 0.7792
 Epoch [15/20], Step[220/483], loss: 0.6989
 Epoch [15/20], Step[230/483], loss: 0.6214
 Epoch [15/20], Step[240/483], loss: 0.7310
 Epoch [15/20], Step[250/483], loss: 0.7975
 Epoch [15/20], Step[260/483], loss: 0.5414
 Epoch [15/20], Step[270/483], loss: 0.7601
 Epoch [15/20], Step[280/483], loss: 0.6765
 Epoch [15/20], Step[290/483], loss: 0.5609
 Epoch [15/20], Step[300/483], loss: 0.7838
 Epoch [15/20], Step[310/483], loss: 0.7700
 Epoch [15/20], Step[320/483], loss: 0.7905
 Epoch [15/20], Step[330/483], loss: 0.7595
 Epoch [15/20], Step[340/483], loss: 0.7642
 Epoch [15/20], Step[350/483], loss: 0.7443
 Epoch [15/20], Step[360/483], loss: 0.5764
 Epoch [15/20], Step[370/483], loss: 0.5086
 Epoch [15/20], Step[380/483], loss: 0.6951
 Epoch [15/20], Step[390/483], loss: 0.7395
 Epoch [15/20], Step[400/483], loss: 0.7298
 Epoch [15/20], Step[410/483], loss: 0.6160
 Epoch [15/20], Step[420/483], loss: 0.6992
 Epoch [15/20], Step[430/483], loss: 0.7269
 Epoch [15/20], Step[440/483], loss: 0.7223
 Epoch [15/20], Step[450/483], loss: 0.6104
 Epoch [15/20], Step[460/483], loss: 0.7996
 Epoch [15/20], Step[470/483], loss: 0.8517
 Epoch [15/20], Step[480/483], loss: 0.5218
 ====> Epoch 15: Training loss: 360.5511
 ====> Epoch 15: Validation loss: 55.1814
 Epoch [16/20], Step[0/483], loss: 0.6540
 Epoch [16/20], Step[10/483], loss: 0.7427
 Epoch [16/20], Step[20/483], loss: 0.7928
 Epoch [16/20], Step[30/483], loss: 0.7394
 Epoch [16/20], Step[40/483], loss: 0.7685
 Epoch [16/20], Step[50/483], loss: 0.8148
 Epoch [16/20], Step[60/483], loss: 0.8801
 Epoch [16/20], Step[70/483], loss: 0.8358
 Epoch [16/20], Step[80/483], loss: 0.9145
 Epoch [16/20], Step[90/483], loss: 0.6422
 Epoch [16/20], Step[100/483], loss: 0.6598
 Epoch [16/20], Step[110/483], loss: 0.7656
 Epoch [16/20], Step[120/483], loss: 0.8212
 Epoch [16/20], Step[130/483], loss: 0.6964
 Epoch [16/20], Step[140/483], loss: 0.8225
 Epoch [16/20], Step[150/483], loss: 0.8062
 Epoch [16/20], Step[160/483], loss: 0.8514
 Epoch [16/20], Step[170/483], loss: 0.5815
 Epoch [16/20], Step[180/483], loss: 0.8631
 Epoch [16/20], Step[190/483], loss: 0.8495
 Epoch [16/20], Step[200/483], loss: 0.6303
 Epoch [16/20], Step[210/483], loss: 0.7679
 Epoch [16/20], Step[220/483], loss: 0.6891
 Epoch [16/20], Step[230/483], loss: 0.6261
 Epoch [16/20], Step[240/483], loss: 0.7307
 Epoch [16/20], Step[250/483], loss: 0.8023
 Epoch [16/20], Step[260/483], loss: 0.5394
 Epoch [16/20], Step[270/483], loss: 0.7634
 Epoch [16/20], Step[280/483], loss: 0.6590
 Epoch [16/20], Step[290/483], loss: 0.5638
 Epoch [16/20], Step[300/483], loss: 0.7762
 Epoch [16/20], Step[310/483], loss: 0.7548
 Epoch [16/20], Step[320/483], loss: 0.7846
 Epoch [16/20], Step[330/483], loss: 0.7633
 Epoch [16/20], Step[340/483], loss: 0.7850
 Epoch [16/20], Step[350/483], loss: 0.7521
 Epoch [16/20], Step[360/483], loss: 0.5708
 Epoch [16/20], Step[370/483], loss: 0.5148
 Epoch [16/20], Step[380/483], loss: 0.6861
 Epoch [16/20], Step[390/483], loss: 0.7088
 Epoch [16/20], Step[400/483], loss: 0.7119
 Epoch [16/20], Step[410/483], loss: 0.6088
 Epoch [16/20], Step[420/483], loss: 0.6756
 Epoch [16/20], Step[430/483], loss: 0.7207
 Epoch [16/20], Step[440/483], loss: 0.7135
 Epoch [16/20], Step[450/483], loss: 0.6250
 Epoch [16/20], Step[460/483], loss: 0.8191
 Epoch [16/20], Step[470/483], loss: 0.8270
 Epoch [16/20], Step[480/483], loss: 0.5298
 ====> Epoch 16: Training loss: 359.2776
 ====> Epoch 16: Validation loss: 55.1260
 Epoch [17/20], Step[0/483], loss: 0.6537
 Epoch [17/20], Step[10/483], loss: 0.7293
 Epoch [17/20], Step[20/483], loss: 0.7825
 Epoch [17/20], Step[30/483], loss: 0.7522
 Epoch [17/20], Step[40/483], loss: 0.7784
 Epoch [17/20], Step[50/483], loss: 0.8162
 Epoch [17/20], Step[60/483], loss: 0.8826
 Epoch [17/20], Step[70/483], loss: 0.8102
 Epoch [17/20], Step[80/483], loss: 0.9165
 Epoch [17/20], Step[90/483], loss: 0.6447
 Epoch [17/20], Step[100/483], loss: 0.6423
 Epoch [17/20], Step[110/483], loss: 0.7645
 Epoch [17/20], Step[120/483], loss: 0.8153
 Epoch [17/20], Step[130/483], loss: 0.7007
 Epoch [17/20], Step[140/483], loss: 0.8111
 Epoch [17/20], Step[150/483], loss: 0.8004
 Epoch [17/20], Step[160/483], loss: 0.8679
 Epoch [17/20], Step[170/483], loss: 0.5910
 Epoch [17/20], Step[180/483], loss: 0.8637
 Epoch [17/20], Step[190/483], loss: 0.8557
 Epoch [17/20], Step[200/483], loss: 0.6276
 Epoch [17/20], Step[210/483], loss: 0.7651
 Epoch [17/20], Step[220/483], loss: 0.6914
 Epoch [17/20], Step[230/483], loss: 0.6331
 Epoch [17/20], Step[240/483], loss: 0.7626
 Epoch [17/20], Step[250/483], loss: 0.7785
 Epoch [17/20], Step[260/483], loss: 0.5501
 Epoch [17/20], Step[270/483], loss: 0.7452
 Epoch [17/20], Step[280/483], loss: 0.6733
 Epoch [17/20], Step[290/483], loss: 0.5692
 Epoch [17/20], Step[300/483], loss: 0.7705
 Epoch [17/20], Step[310/483], loss: 0.7640
 Epoch [17/20], Step[320/483], loss: 0.7912
 Epoch [17/20], Step[330/483], loss: 0.7632
 Epoch [17/20], Step[340/483], loss: 0.7375
 Epoch [17/20], Step[350/483], loss: 0.7322
 Epoch [17/20], Step[360/483], loss: 0.5681
 Epoch [17/20], Step[370/483], loss: 0.5119
 Epoch [17/20], Step[380/483], loss: 0.6914
 Epoch [17/20], Step[390/483], loss: 0.7368
 Epoch [17/20], Step[400/483], loss: 0.7071
 Epoch [17/20], Step[410/483], loss: 0.5987
 Epoch [17/20], Step[420/483], loss: 0.6872
 Epoch [17/20], Step[430/483], loss: 0.7269
 Epoch [17/20], Step[440/483], loss: 0.7089
 Epoch [17/20], Step[450/483], loss: 0.6195
 Epoch [17/20], Step[460/483], loss: 0.7904
 Epoch [17/20], Step[470/483], loss: 0.8429
 Epoch [17/20], Step[480/483], loss: 0.5334
 ====> Epoch 17: Training loss: 357.7433
 ====> Epoch 17: Validation loss: 54.8486
 Epoch [18/20], Step[0/483], loss: 0.6414
 Epoch [18/20], Step[10/483], loss: 0.7174
 Epoch [18/20], Step[20/483], loss: 0.7909
 Epoch [18/20], Step[30/483], loss: 0.7696
 Epoch [18/20], Step[40/483], loss: 0.7499
 Epoch [18/20], Step[50/483], loss: 0.8130
 Epoch [18/20], Step[60/483], loss: 0.8744
 Epoch [18/20], Step[70/483], loss: 0.8218
 Epoch [18/20], Step[80/483], loss: 0.9196
 Epoch [18/20], Step[90/483], loss: 0.6351
 Epoch [18/20], Step[100/483], loss: 0.6485
 Epoch [18/20], Step[110/483], loss: 0.7641
 Epoch [18/20], Step[120/483], loss: 0.8163
 Epoch [18/20], Step[130/483], loss: 0.7028
 Epoch [18/20], Step[140/483], loss: 0.7909
 Epoch [18/20], Step[150/483], loss: 0.8034
 Epoch [18/20], Step[160/483], loss: 0.8880
 Epoch [18/20], Step[170/483], loss: 0.5958
 Epoch [18/20], Step[180/483], loss: 0.8757
 Epoch [18/20], Step[190/483], loss: 0.8510
 Epoch [18/20], Step[200/483], loss: 0.6121
 Epoch [18/20], Step[210/483], loss: 0.7483
 Epoch [18/20], Step[220/483], loss: 0.6788
 Epoch [18/20], Step[230/483], loss: 0.6206
 Epoch [18/20], Step[240/483], loss: 0.7418
 Epoch [18/20], Step[250/483], loss: 0.7835
 Epoch [18/20], Step[260/483], loss: 0.5319
 Epoch [18/20], Step[270/483], loss: 0.7334
 Epoch [18/20], Step[280/483], loss: 0.6698
 Epoch [18/20], Step[290/483], loss: 0.5566
 Epoch [18/20], Step[300/483], loss: 0.7886
 Epoch [18/20], Step[310/483], loss: 0.7678
 Epoch [18/20], Step[320/483], loss: 0.7657
 Epoch [18/20], Step[330/483], loss: 0.7743
 Epoch [18/20], Step[340/483], loss: 0.7545
 Epoch [18/20], Step[350/483], loss: 0.7459
 Epoch [18/20], Step[360/483], loss: 0.5799
 Epoch [18/20], Step[370/483], loss: 0.5075
 Epoch [18/20], Step[380/483], loss: 0.6756
 Epoch [18/20], Step[390/483], loss: 0.7168
 Epoch [18/20], Step[400/483], loss: 0.7134
 Epoch [18/20], Step[410/483], loss: 0.5983
 Epoch [18/20], Step[420/483], loss: 0.6796
 Epoch [18/20], Step[430/483], loss: 0.7133
 Epoch [18/20], Step[440/483], loss: 0.7047
 Epoch [18/20], Step[450/483], loss: 0.6070
 Epoch [18/20], Step[460/483], loss: 0.8073
 Epoch [18/20], Step[470/483], loss: 0.8399
 Epoch [18/20], Step[480/483], loss: 0.5215
 ====> Epoch 18: Training loss: 356.1614
 ====> Epoch 18: Validation loss: 55.2982
 Epoch [19/20], Step[0/483], loss: 0.6649
 Epoch [19/20], Step[10/483], loss: 0.7020
 Epoch [19/20], Step[20/483], loss: 0.7644
 Epoch [19/20], Step[30/483], loss: 0.7424
 Epoch [19/20], Step[40/483], loss: 0.7814
 Epoch [19/20], Step[50/483], loss: 0.7917
 Epoch [19/20], Step[60/483], loss: 0.8792
 Epoch [19/20], Step[70/483], loss: 0.8168
 Epoch [19/20], Step[80/483], loss: 0.8967
 Epoch [19/20], Step[90/483], loss: 0.6336
 Epoch [19/20], Step[100/483], loss: 0.6485
 Epoch [19/20], Step[110/483], loss: 0.7519
 Epoch [19/20], Step[120/483], loss: 0.8222
 Epoch [19/20], Step[130/483], loss: 0.6885
 Epoch [19/20], Step[140/483], loss: 0.8032
 Epoch [19/20], Step[150/483], loss: 0.7907
 Epoch [19/20], Step[160/483], loss: 0.8521
 Epoch [19/20], Step[170/483], loss: 0.6053
 Epoch [19/20], Step[180/483], loss: 0.8605
 Epoch [19/20], Step[190/483], loss: 0.8349
 Epoch [19/20], Step[200/483], loss: 0.6269
 Epoch [19/20], Step[210/483], loss: 0.7711
 Epoch [19/20], Step[220/483], loss: 0.6943
 Epoch [19/20], Step[230/483], loss: 0.6184
 Epoch [19/20], Step[240/483], loss: 0.7441
 Epoch [19/20], Step[250/483], loss: 0.7823
 Epoch [19/20], Step[260/483], loss: 0.5481
 Epoch [19/20], Step[270/483], loss: 0.7392
 Epoch [19/20], Step[280/483], loss: 0.6636
 Epoch [19/20], Step[290/483], loss: 0.5434
 Epoch [19/20], Step[300/483], loss: 0.7748
 Epoch [19/20], Step[310/483], loss: 0.7717
 Epoch [19/20], Step[320/483], loss: 0.7981
 Epoch [19/20], Step[330/483], loss: 0.7883
 Epoch [19/20], Step[340/483], loss: 0.7417
 Epoch [19/20], Step[350/483], loss: 0.7328
 Epoch [19/20], Step[360/483], loss: 0.5794
 Epoch [19/20], Step[370/483], loss: 0.5069
 Epoch [19/20], Step[380/483], loss: 0.6972
 Epoch [19/20], Step[390/483], loss: 0.7250
 Epoch [19/20], Step[400/483], loss: 0.7161
 Epoch [19/20], Step[410/483], loss: 0.5949
 Epoch [19/20], Step[420/483], loss: 0.6858
 Epoch [19/20], Step[430/483], loss: 0.7137
 Epoch [19/20], Step[440/483], loss: 0.6992
 Epoch [19/20], Step[450/483], loss: 0.5967
 Epoch [19/20], Step[460/483], loss: 0.8095
 Epoch [19/20], Step[470/483], loss: 0.8349
 Epoch [19/20], Step[480/483], loss: 0.5207
 ====> Epoch 19: Training loss: 354.7916
 ====> Epoch 19: Validation loss: 55.2729
 Epoch [20/20], Step[0/483], loss: 0.6427
 Epoch [20/20], Step[10/483], loss: 0.7162
 Epoch [20/20], Step[20/483], loss: 0.7500
 Epoch [20/20], Step[30/483], loss: 0.7443
 Epoch [20/20], Step[40/483], loss: 0.7574
 Epoch [20/20], Step[50/483], loss: 0.8155
 Epoch [20/20], Step[60/483], loss: 0.8839
 Epoch [20/20], Step[70/483], loss: 0.8029
 Epoch [20/20], Step[80/483], loss: 0.8771
 Epoch [20/20], Step[90/483], loss: 0.6422
 Epoch [20/20], Step[100/483], loss: 0.6573
 Epoch [20/20], Step[110/483], loss: 0.7707
 Epoch [20/20], Step[120/483], loss: 0.8110
 Epoch [20/20], Step[130/483], loss: 0.7013
 Epoch [20/20], Step[140/483], loss: 0.8002
 Epoch [20/20], Step[150/483], loss: 0.7806
 Epoch [20/20], Step[160/483], loss: 0.8658
 Epoch [20/20], Step[170/483], loss: 0.6034
 Epoch [20/20], Step[180/483], loss: 0.8340
 Epoch [20/20], Step[190/483], loss: 0.8466
 Epoch [20/20], Step[200/483], loss: 0.6248
 Epoch [20/20], Step[210/483], loss: 0.7566
 Epoch [20/20], Step[220/483], loss: 0.6712
 Epoch [20/20], Step[230/483], loss: 0.6105
 Epoch [20/20], Step[240/483], loss: 0.7274
 Epoch [20/20], Step[250/483], loss: 0.7615
 Epoch [20/20], Step[260/483], loss: 0.5369
 Epoch [20/20], Step[270/483], loss: 0.7409
 Epoch [20/20], Step[280/483], loss: 0.6576
 Epoch [20/20], Step[290/483], loss: 0.5536
 Epoch [20/20], Step[300/483], loss: 0.7545
 Epoch [20/20], Step[310/483], loss: 0.7530
 Epoch [20/20], Step[320/483], loss: 0.7669
 Epoch [20/20], Step[330/483], loss: 0.7825
 Epoch [20/20], Step[340/483], loss: 0.7283
 Epoch [20/20], Step[350/483], loss: 0.7305
 Epoch [20/20], Step[360/483], loss: 0.5726
 Epoch [20/20], Step[370/483], loss: 0.5161
 Epoch [20/20], Step[380/483], loss: 0.6752
 Epoch [20/20], Step[390/483], loss: 0.7181
 Epoch [20/20], Step[400/483], loss: 0.7029
 Epoch [20/20], Step[410/483], loss: 0.5966
 Epoch [20/20], Step[420/483], loss: 0.6585
 Epoch [20/20], Step[430/483], loss: 0.7299
 Epoch [20/20], Step[440/483], loss: 0.6950
 Epoch [20/20], Step[450/483], loss: 0.5969
 Epoch [20/20], Step[460/483], loss: 0.7837
 Epoch [20/20], Step[470/483], loss: 0.8099
 Epoch [20/20], Step[480/483], loss: 0.5187
 ====> Epoch 20: Training loss: 352.8825
 ====> Epoch 20: Validation loss: 55.2586
 Saved model to models/s0210
.pth
