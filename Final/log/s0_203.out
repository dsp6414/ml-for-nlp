 Loading feature files...
 <s> = 1
 </s> = 2
 All scenes loaded.
 Hyperparameters:Namespace(LR=0.01, alternatives=1, batch_size=100, dec='LSTM', dropout=0.5, epochs=40, hidden_sz=50, load=None, log_interval=10, model='s0', no_cuda=False, save=None, seed=1)
 Speaker0: Speaker0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=50)
  )
  (string_decoder): LSTMStringDecoder(
    (embedding): Embedding(1063, 50)
    (lstm): LSTM(50, 50, num_layers=2, batch_first=True, dropout=0.5)
    (linear): Linear(in_features=50, out_features=1063)
    (dropout): Dropout(p=0.5)
  )
)
 Training Speaker0...
 Epoch [1/40], Step[0/483], loss: 7.0265
 Epoch [1/40], Step[10/483], loss: 3.6799
 Epoch [1/40], Step[20/483], loss: 3.0814
 Epoch [1/40], Step[30/483], loss: 2.4404
 Epoch [1/40], Step[40/483], loss: 2.3219
 Epoch [1/40], Step[50/483], loss: 2.4094
 Epoch [1/40], Step[60/483], loss: 2.2620
 Epoch [1/40], Step[70/483], loss: 2.1338
 Epoch [1/40], Step[80/483], loss: 2.3123
 Epoch [1/40], Step[90/483], loss: 1.6147
 Epoch [1/40], Step[100/483], loss: 1.5370
 Epoch [1/40], Step[110/483], loss: 1.7441
 Epoch [1/40], Step[120/483], loss: 1.9104
 Epoch [1/40], Step[130/483], loss: 1.5919
 Epoch [1/40], Step[140/483], loss: 1.7721
 Epoch [1/40], Step[150/483], loss: 1.7943
 Epoch [1/40], Step[160/483], loss: 1.9157
 Epoch [1/40], Step[170/483], loss: 1.2525
 Epoch [1/40], Step[180/483], loss: 1.7716
 Epoch [1/40], Step[190/483], loss: 1.7957
 Epoch [1/40], Step[200/483], loss: 1.2123
 Epoch [1/40], Step[210/483], loss: 1.5156
 Epoch [1/40], Step[220/483], loss: 1.3580
 Epoch [1/40], Step[230/483], loss: 1.2349
 Epoch [1/40], Step[240/483], loss: 1.5249
 Epoch [1/40], Step[250/483], loss: 1.6253
 Epoch [1/40], Step[260/483], loss: 0.9835
 Epoch [1/40], Step[270/483], loss: 1.5440
 Epoch [1/40], Step[280/483], loss: 1.2136
 Epoch [1/40], Step[290/483], loss: 1.0606
 Epoch [1/40], Step[300/483], loss: 1.4949
 Epoch [1/40], Step[310/483], loss: 1.5034
 Epoch [1/40], Step[320/483], loss: 1.6193
 Epoch [1/40], Step[330/483], loss: 1.4077
 Epoch [1/40], Step[340/483], loss: 1.5648
 Epoch [1/40], Step[350/483], loss: 1.4379
 Epoch [1/40], Step[360/483], loss: 1.0972
 Epoch [1/40], Step[370/483], loss: 0.9525
 Epoch [1/40], Step[380/483], loss: 1.2859
 Epoch [1/40], Step[390/483], loss: 1.3795
 Epoch [1/40], Step[400/483], loss: 1.3957
 Epoch [1/40], Step[410/483], loss: 1.0628
 Epoch [1/40], Step[420/483], loss: 1.2927
 Epoch [1/40], Step[430/483], loss: 1.2640
 Epoch [1/40], Step[440/483], loss: 1.3902
 Epoch [1/40], Step[450/483], loss: 1.1066
 Epoch [1/40], Step[460/483], loss: 1.4577
 Epoch [1/40], Step[470/483], loss: 1.6109
 Epoch [1/40], Step[480/483], loss: 0.8919
 ====> Epoch 1: Training loss: 818.5500
 ====> Epoch 1: Validation loss: 80.7612
 Epoch [2/40], Step[0/483], loss: 1.1685
 Epoch [2/40], Step[10/483], loss: 1.3557
 Epoch [2/40], Step[20/483], loss: 1.4268
 Epoch [2/40], Step[30/483], loss: 1.3354
 Epoch [2/40], Step[40/483], loss: 1.4063
 Epoch [2/40], Step[50/483], loss: 1.4868
 Epoch [2/40], Step[60/483], loss: 1.6077
 Epoch [2/40], Step[70/483], loss: 1.4345
 Epoch [2/40], Step[80/483], loss: 1.6389
 Epoch [2/40], Step[90/483], loss: 1.1433
 Epoch [2/40], Step[100/483], loss: 1.1360
 Epoch [2/40], Step[110/483], loss: 1.3380
 Epoch [2/40], Step[120/483], loss: 1.3835
 Epoch [2/40], Step[130/483], loss: 1.2026
 Epoch [2/40], Step[140/483], loss: 1.3975
 Epoch [2/40], Step[150/483], loss: 1.4464
 Epoch [2/40], Step[160/483], loss: 1.5887
 Epoch [2/40], Step[170/483], loss: 1.0447
 Epoch [2/40], Step[180/483], loss: 1.4749
 Epoch [2/40], Step[190/483], loss: 1.4476
 Epoch [2/40], Step[200/483], loss: 1.0438
 Epoch [2/40], Step[210/483], loss: 1.2681
 Epoch [2/40], Step[220/483], loss: 1.1626
 Epoch [2/40], Step[230/483], loss: 1.0718
 Epoch [2/40], Step[240/483], loss: 1.3252
 Epoch [2/40], Step[250/483], loss: 1.3830
 Epoch [2/40], Step[260/483], loss: 0.8701
 Epoch [2/40], Step[270/483], loss: 1.3257
 Epoch [2/40], Step[280/483], loss: 1.0936
 Epoch [2/40], Step[290/483], loss: 0.9355
 Epoch [2/40], Step[300/483], loss: 1.3156
 Epoch [2/40], Step[310/483], loss: 1.3146
 Epoch [2/40], Step[320/483], loss: 1.4574
 Epoch [2/40], Step[330/483], loss: 1.2602
 Epoch [2/40], Step[340/483], loss: 1.3783
 Epoch [2/40], Step[350/483], loss: 1.3193
 Epoch [2/40], Step[360/483], loss: 0.9497
 Epoch [2/40], Step[370/483], loss: 0.8425
 Epoch [2/40], Step[380/483], loss: 1.1638
 Epoch [2/40], Step[390/483], loss: 1.2828
 Epoch [2/40], Step[400/483], loss: 1.2460
 Epoch [2/40], Step[410/483], loss: 0.9718
 Epoch [2/40], Step[420/483], loss: 1.1692
 Epoch [2/40], Step[430/483], loss: 1.1764
 Epoch [2/40], Step[440/483], loss: 1.2915
 Epoch [2/40], Step[450/483], loss: 1.0170
 Epoch [2/40], Step[460/483], loss: 1.3499
 Epoch [2/40], Step[470/483], loss: 1.4906
 Epoch [2/40], Step[480/483], loss: 0.8148
 ====> Epoch 2: Training loss: 625.4986
 ====> Epoch 2: Validation loss: 75.3126
 Epoch [3/40], Step[0/483], loss: 1.0394
 Epoch [3/40], Step[10/483], loss: 1.2590
 Epoch [3/40], Step[20/483], loss: 1.3275
 Epoch [3/40], Step[30/483], loss: 1.2556
 Epoch [3/40], Step[40/483], loss: 1.3153
 Epoch [3/40], Step[50/483], loss: 1.4031
 Epoch [3/40], Step[60/483], loss: 1.4862
 Epoch [3/40], Step[70/483], loss: 1.3258
 Epoch [3/40], Step[80/483], loss: 1.5429
 Epoch [3/40], Step[90/483], loss: 1.0619
 Epoch [3/40], Step[100/483], loss: 1.1085
 Epoch [3/40], Step[110/483], loss: 1.2707
 Epoch [3/40], Step[120/483], loss: 1.3690
 Epoch [3/40], Step[130/483], loss: 1.1218
 Epoch [3/40], Step[140/483], loss: 1.3273
 Epoch [3/40], Step[150/483], loss: 1.3647
 Epoch [3/40], Step[160/483], loss: 1.5036
 Epoch [3/40], Step[170/483], loss: 0.9923
 Epoch [3/40], Step[180/483], loss: 1.3808
 Epoch [3/40], Step[190/483], loss: 1.3561
 Epoch [3/40], Step[200/483], loss: 0.9875
 Epoch [3/40], Step[210/483], loss: 1.2026
 Epoch [3/40], Step[220/483], loss: 1.0905
 Epoch [3/40], Step[230/483], loss: 1.0095
 Epoch [3/40], Step[240/483], loss: 1.2807
 Epoch [3/40], Step[250/483], loss: 1.3287
 Epoch [3/40], Step[260/483], loss: 0.8490
 Epoch [3/40], Step[270/483], loss: 1.3007
 Epoch [3/40], Step[280/483], loss: 1.0289
 Epoch [3/40], Step[290/483], loss: 0.8834
 Epoch [3/40], Step[300/483], loss: 1.2521
 Epoch [3/40], Step[310/483], loss: 1.2660
 Epoch [3/40], Step[320/483], loss: 1.3738
 Epoch [3/40], Step[330/483], loss: 1.2466
 Epoch [3/40], Step[340/483], loss: 1.3153
 Epoch [3/40], Step[350/483], loss: 1.2326
 Epoch [3/40], Step[360/483], loss: 0.9322
 Epoch [3/40], Step[370/483], loss: 0.8214
 Epoch [3/40], Step[380/483], loss: 1.1046
 Epoch [3/40], Step[390/483], loss: 1.2195
 Epoch [3/40], Step[400/483], loss: 1.2117
 Epoch [3/40], Step[410/483], loss: 0.9639
 Epoch [3/40], Step[420/483], loss: 1.1354
 Epoch [3/40], Step[430/483], loss: 1.1430
 Epoch [3/40], Step[440/483], loss: 1.2061
 Epoch [3/40], Step[450/483], loss: 0.9798
 Epoch [3/40], Step[460/483], loss: 1.2930
 Epoch [3/40], Step[470/483], loss: 1.4377
 Epoch [3/40], Step[480/483], loss: 0.8044
 ====> Epoch 3: Training loss: 595.6883
 ====> Epoch 3: Validation loss: 72.8785
 Epoch [4/40], Step[0/483], loss: 1.0360
 Epoch [4/40], Step[10/483], loss: 1.2021
 Epoch [4/40], Step[20/483], loss: 1.2792
 Epoch [4/40], Step[30/483], loss: 1.2241
 Epoch [4/40], Step[40/483], loss: 1.2644
 Epoch [4/40], Step[50/483], loss: 1.3729
 Epoch [4/40], Step[60/483], loss: 1.4918
 Epoch [4/40], Step[70/483], loss: 1.2784
 Epoch [4/40], Step[80/483], loss: 1.5271
 Epoch [4/40], Step[90/483], loss: 1.0382
 Epoch [4/40], Step[100/483], loss: 1.0233
 Epoch [4/40], Step[110/483], loss: 1.2386
 Epoch [4/40], Step[120/483], loss: 1.3319
 Epoch [4/40], Step[130/483], loss: 1.1004
 Epoch [4/40], Step[140/483], loss: 1.2659
 Epoch [4/40], Step[150/483], loss: 1.3531
 Epoch [4/40], Step[160/483], loss: 1.4430
 Epoch [4/40], Step[170/483], loss: 0.9537
 Epoch [4/40], Step[180/483], loss: 1.3635
 Epoch [4/40], Step[190/483], loss: 1.3576
 Epoch [4/40], Step[200/483], loss: 0.9621
 Epoch [4/40], Step[210/483], loss: 1.2263
 Epoch [4/40], Step[220/483], loss: 1.0761
 Epoch [4/40], Step[230/483], loss: 0.9909
 Epoch [4/40], Step[240/483], loss: 1.2543
 Epoch [4/40], Step[250/483], loss: 1.2982
 Epoch [4/40], Step[260/483], loss: 0.8084
 Epoch [4/40], Step[270/483], loss: 1.2688
 Epoch [4/40], Step[280/483], loss: 1.0358
 Epoch [4/40], Step[290/483], loss: 0.8776
 Epoch [4/40], Step[300/483], loss: 1.2496
 Epoch [4/40], Step[310/483], loss: 1.2221
 Epoch [4/40], Step[320/483], loss: 1.3452
 Epoch [4/40], Step[330/483], loss: 1.2162
 Epoch [4/40], Step[340/483], loss: 1.2815
 Epoch [4/40], Step[350/483], loss: 1.2027
 Epoch [4/40], Step[360/483], loss: 0.9304
 Epoch [4/40], Step[370/483], loss: 0.8062
 Epoch [4/40], Step[380/483], loss: 1.1066
 Epoch [4/40], Step[390/483], loss: 1.2047
 Epoch [4/40], Step[400/483], loss: 1.1631
 Epoch [4/40], Step[410/483], loss: 0.9324
 Epoch [4/40], Step[420/483], loss: 1.1197
 Epoch [4/40], Step[430/483], loss: 1.0881
 Epoch [4/40], Step[440/483], loss: 1.1898
 Epoch [4/40], Step[450/483], loss: 0.9569
 Epoch [4/40], Step[460/483], loss: 1.2910
 Epoch [4/40], Step[470/483], loss: 1.4257
 Epoch [4/40], Step[480/483], loss: 0.7910
 ====> Epoch 4: Training loss: 581.3076
 ====> Epoch 4: Validation loss: 71.7035
 Epoch [5/40], Step[0/483], loss: 1.0032
 Epoch [5/40], Step[10/483], loss: 1.1907
 Epoch [5/40], Step[20/483], loss: 1.2605
 Epoch [5/40], Step[30/483], loss: 1.1964
 Epoch [5/40], Step[40/483], loss: 1.2175
 Epoch [5/40], Step[50/483], loss: 1.3196
 Epoch [5/40], Step[60/483], loss: 1.4201
 Epoch [5/40], Step[70/483], loss: 1.2808
 Epoch [5/40], Step[80/483], loss: 1.4851
 Epoch [5/40], Step[90/483], loss: 1.0069
 Epoch [5/40], Step[100/483], loss: 1.0085
 Epoch [5/40], Step[110/483], loss: 1.2044
 Epoch [5/40], Step[120/483], loss: 1.3118
 Epoch [5/40], Step[130/483], loss: 1.0783
 Epoch [5/40], Step[140/483], loss: 1.2452
 Epoch [5/40], Step[150/483], loss: 1.3081
 Epoch [5/40], Step[160/483], loss: 1.4153
 Epoch [5/40], Step[170/483], loss: 0.9345
 Epoch [5/40], Step[180/483], loss: 1.3554
 Epoch [5/40], Step[190/483], loss: 1.3312
 Epoch [5/40], Step[200/483], loss: 0.9581
 Epoch [5/40], Step[210/483], loss: 1.1715
 Epoch [5/40], Step[220/483], loss: 1.0541
 Epoch [5/40], Step[230/483], loss: 0.9697
 Epoch [5/40], Step[240/483], loss: 1.2207
 Epoch [5/40], Step[250/483], loss: 1.2481
 Epoch [5/40], Step[260/483], loss: 0.7835
 Epoch [5/40], Step[270/483], loss: 1.2201
 Epoch [5/40], Step[280/483], loss: 1.0073
 Epoch [5/40], Step[290/483], loss: 0.8481
 Epoch [5/40], Step[300/483], loss: 1.2253
 Epoch [5/40], Step[310/483], loss: 1.2232
 Epoch [5/40], Step[320/483], loss: 1.2942
 Epoch [5/40], Step[330/483], loss: 1.1893
 Epoch [5/40], Step[340/483], loss: 1.2665
 Epoch [5/40], Step[350/483], loss: 1.2039
 Epoch [5/40], Step[360/483], loss: 0.9240
 Epoch [5/40], Step[370/483], loss: 0.7813
 Epoch [5/40], Step[380/483], loss: 1.0813
 Epoch [5/40], Step[390/483], loss: 1.1933
 Epoch [5/40], Step[400/483], loss: 1.1808
 Epoch [5/40], Step[410/483], loss: 0.9180
 Epoch [5/40], Step[420/483], loss: 1.1271
 Epoch [5/40], Step[430/483], loss: 1.1058
 Epoch [5/40], Step[440/483], loss: 1.1909
 Epoch [5/40], Step[450/483], loss: 0.9395
 Epoch [5/40], Step[460/483], loss: 1.2855
 Epoch [5/40], Step[470/483], loss: 1.3997
 Epoch [5/40], Step[480/483], loss: 0.7695
 ====> Epoch 5: Training loss: 571.7683
 ====> Epoch 5: Validation loss: 71.0284
 Epoch [6/40], Step[0/483], loss: 1.0219
 Epoch [6/40], Step[10/483], loss: 1.1617
 Epoch [6/40], Step[20/483], loss: 1.2445
 Epoch [6/40], Step[30/483], loss: 1.2092
 Epoch [6/40], Step[40/483], loss: 1.2115
 Epoch [6/40], Step[50/483], loss: 1.3401
 Epoch [6/40], Step[60/483], loss: 1.4481
 Epoch [6/40], Step[70/483], loss: 1.2623
 Epoch [6/40], Step[80/483], loss: 1.4574
 Epoch [6/40], Step[90/483], loss: 0.9974
 Epoch [6/40], Step[100/483], loss: 1.0316
 Epoch [6/40], Step[110/483], loss: 1.2059
 Epoch [6/40], Step[120/483], loss: 1.2933
 Epoch [6/40], Step[130/483], loss: 1.0819
 Epoch [6/40], Step[140/483], loss: 1.2573
 Epoch [6/40], Step[150/483], loss: 1.2905
 Epoch [6/40], Step[160/483], loss: 1.4042
 Epoch [6/40], Step[170/483], loss: 0.9601
 Epoch [6/40], Step[180/483], loss: 1.3391
 Epoch [6/40], Step[190/483], loss: 1.3378
 Epoch [6/40], Step[200/483], loss: 0.9457
 Epoch [6/40], Step[210/483], loss: 1.1733
 Epoch [6/40], Step[220/483], loss: 1.0476
 Epoch [6/40], Step[230/483], loss: 0.9676
 Epoch [6/40], Step[240/483], loss: 1.2027
 Epoch [6/40], Step[250/483], loss: 1.2470
 Epoch [6/40], Step[260/483], loss: 0.7735
 Epoch [6/40], Step[270/483], loss: 1.1927
 Epoch [6/40], Step[280/483], loss: 1.0265
 Epoch [6/40], Step[290/483], loss: 0.8541
 Epoch [6/40], Step[300/483], loss: 1.1880
 Epoch [6/40], Step[310/483], loss: 1.2172
 Epoch [6/40], Step[320/483], loss: 1.2989
 Epoch [6/40], Step[330/483], loss: 1.1853
 Epoch [6/40], Step[340/483], loss: 1.2576
 Epoch [6/40], Step[350/483], loss: 1.1866
 Epoch [6/40], Step[360/483], loss: 0.9166
 Epoch [6/40], Step[370/483], loss: 0.7790
 Epoch [6/40], Step[380/483], loss: 1.0664
 Epoch [6/40], Step[390/483], loss: 1.1852
 Epoch [6/40], Step[400/483], loss: 1.1628
 Epoch [6/40], Step[410/483], loss: 0.9287
 Epoch [6/40], Step[420/483], loss: 1.0941
 Epoch [6/40], Step[430/483], loss: 1.1067
 Epoch [6/40], Step[440/483], loss: 1.1556
 Epoch [6/40], Step[450/483], loss: 0.9515
 Epoch [6/40], Step[460/483], loss: 1.2787
 Epoch [6/40], Step[470/483], loss: 1.4378
 Epoch [6/40], Step[480/483], loss: 0.7686
 ====> Epoch 6: Training loss: 566.6867
 ====> Epoch 6: Validation loss: 70.3865
 Epoch [7/40], Step[0/483], loss: 0.9978
 Epoch [7/40], Step[10/483], loss: 1.1383
 Epoch [7/40], Step[20/483], loss: 1.2766
 Epoch [7/40], Step[30/483], loss: 1.1569
 Epoch [7/40], Step[40/483], loss: 1.2005
 Epoch [7/40], Step[50/483], loss: 1.3043
 Epoch [7/40], Step[60/483], loss: 1.4147
 Epoch [7/40], Step[70/483], loss: 1.2650
 Epoch [7/40], Step[80/483], loss: 1.4574
 Epoch [7/40], Step[90/483], loss: 0.9953
 Epoch [7/40], Step[100/483], loss: 1.0034
 Epoch [7/40], Step[110/483], loss: 1.2043
 Epoch [7/40], Step[120/483], loss: 1.2644
 Epoch [7/40], Step[130/483], loss: 1.0740
 Epoch [7/40], Step[140/483], loss: 1.2292
 Epoch [7/40], Step[150/483], loss: 1.2561
 Epoch [7/40], Step[160/483], loss: 1.4084
 Epoch [7/40], Step[170/483], loss: 0.9309
 Epoch [7/40], Step[180/483], loss: 1.3375
 Epoch [7/40], Step[190/483], loss: 1.3089
 Epoch [7/40], Step[200/483], loss: 0.9440
 Epoch [7/40], Step[210/483], loss: 1.1710
 Epoch [7/40], Step[220/483], loss: 1.0176
 Epoch [7/40], Step[230/483], loss: 0.9380
 Epoch [7/40], Step[240/483], loss: 1.2217
 Epoch [7/40], Step[250/483], loss: 1.2484
 Epoch [7/40], Step[260/483], loss: 0.7799
 Epoch [7/40], Step[270/483], loss: 1.2018
 Epoch [7/40], Step[280/483], loss: 1.0098
 Epoch [7/40], Step[290/483], loss: 0.8460
 Epoch [7/40], Step[300/483], loss: 1.2030
 Epoch [7/40], Step[310/483], loss: 1.1865
 Epoch [7/40], Step[320/483], loss: 1.3244
 Epoch [7/40], Step[330/483], loss: 1.1427
 Epoch [7/40], Step[340/483], loss: 1.2019
 Epoch [7/40], Step[350/483], loss: 1.1562
 Epoch [7/40], Step[360/483], loss: 0.9050
 Epoch [7/40], Step[370/483], loss: 0.7843
 Epoch [7/40], Step[380/483], loss: 1.0637
 Epoch [7/40], Step[390/483], loss: 1.1587
 Epoch [7/40], Step[400/483], loss: 1.1405
 Epoch [7/40], Step[410/483], loss: 0.8853
 Epoch [7/40], Step[420/483], loss: 1.0845
 Epoch [7/40], Step[430/483], loss: 1.0874
 Epoch [7/40], Step[440/483], loss: 1.1684
 Epoch [7/40], Step[450/483], loss: 0.9322
 Epoch [7/40], Step[460/483], loss: 1.2556
 Epoch [7/40], Step[470/483], loss: 1.3925
 Epoch [7/40], Step[480/483], loss: 0.7611
 ====> Epoch 7: Training loss: 561.6364
 ====> Epoch 7: Validation loss: 70.1084
 Epoch [8/40], Step[0/483], loss: 0.9781
 Epoch [8/40], Step[10/483], loss: 1.1582
 Epoch [8/40], Step[20/483], loss: 1.2280
 Epoch [8/40], Step[30/483], loss: 1.1619
 Epoch [8/40], Step[40/483], loss: 1.1909
 Epoch [8/40], Step[50/483], loss: 1.3158
 Epoch [8/40], Step[60/483], loss: 1.4128
 Epoch [8/40], Step[70/483], loss: 1.2459
 Epoch [8/40], Step[80/483], loss: 1.4394
 Epoch [8/40], Step[90/483], loss: 1.0120
 Epoch [8/40], Step[100/483], loss: 1.0144
 Epoch [8/40], Step[110/483], loss: 1.1883
 Epoch [8/40], Step[120/483], loss: 1.2663
 Epoch [8/40], Step[130/483], loss: 1.0616
 Epoch [8/40], Step[140/483], loss: 1.2217
 Epoch [8/40], Step[150/483], loss: 1.2652
 Epoch [8/40], Step[160/483], loss: 1.4211
 Epoch [8/40], Step[170/483], loss: 0.9233
 Epoch [8/40], Step[180/483], loss: 1.3040
 Epoch [8/40], Step[190/483], loss: 1.2960
 Epoch [8/40], Step[200/483], loss: 0.9289
 Epoch [8/40], Step[210/483], loss: 1.1478
 Epoch [8/40], Step[220/483], loss: 1.0186
 Epoch [8/40], Step[230/483], loss: 0.9237
 Epoch [8/40], Step[240/483], loss: 1.1956
 Epoch [8/40], Step[250/483], loss: 1.2285
 Epoch [8/40], Step[260/483], loss: 0.7771
 Epoch [8/40], Step[270/483], loss: 1.2155
 Epoch [8/40], Step[280/483], loss: 1.0195
 Epoch [8/40], Step[290/483], loss: 0.8368
 Epoch [8/40], Step[300/483], loss: 1.1953
 Epoch [8/40], Step[310/483], loss: 1.1836
 Epoch [8/40], Step[320/483], loss: 1.2853
 Epoch [8/40], Step[330/483], loss: 1.1622
 Epoch [8/40], Step[340/483], loss: 1.2216
 Epoch [8/40], Step[350/483], loss: 1.1703
 Epoch [8/40], Step[360/483], loss: 0.9020
 Epoch [8/40], Step[370/483], loss: 0.7671
 Epoch [8/40], Step[380/483], loss: 1.0525
 Epoch [8/40], Step[390/483], loss: 1.1628
 Epoch [8/40], Step[400/483], loss: 1.1636
 Epoch [8/40], Step[410/483], loss: 0.9060
 Epoch [8/40], Step[420/483], loss: 1.0796
 Epoch [8/40], Step[430/483], loss: 1.0701
 Epoch [8/40], Step[440/483], loss: 1.1554
 Epoch [8/40], Step[450/483], loss: 0.9376
 Epoch [8/40], Step[460/483], loss: 1.2362
 Epoch [8/40], Step[470/483], loss: 1.3515
 Epoch [8/40], Step[480/483], loss: 0.7692
 ====> Epoch 8: Training loss: 559.3340
 ====> Epoch 8: Validation loss: 69.7216
 Epoch [9/40], Step[0/483], loss: 0.9585
 Epoch [9/40], Step[10/483], loss: 1.1484
 Epoch [9/40], Step[20/483], loss: 1.2188
 Epoch [9/40], Step[30/483], loss: 1.1801
 Epoch [9/40], Step[40/483], loss: 1.2023
 Epoch [9/40], Step[50/483], loss: 1.2961
 Epoch [9/40], Step[60/483], loss: 1.3780
 Epoch [9/40], Step[70/483], loss: 1.2497
 Epoch [9/40], Step[80/483], loss: 1.4579
 Epoch [9/40], Step[90/483], loss: 0.9799
 Epoch [9/40], Step[100/483], loss: 1.0026
 Epoch [9/40], Step[110/483], loss: 1.1781
 Epoch [9/40], Step[120/483], loss: 1.2465
 Epoch [9/40], Step[130/483], loss: 1.0641
 Epoch [9/40], Step[140/483], loss: 1.2231
 Epoch [9/40], Step[150/483], loss: 1.2497
 Epoch [9/40], Step[160/483], loss: 1.3410
 Epoch [9/40], Step[170/483], loss: 0.9114
 Epoch [9/40], Step[180/483], loss: 1.3093
 Epoch [9/40], Step[190/483], loss: 1.2899
 Epoch [9/40], Step[200/483], loss: 0.9206
 Epoch [9/40], Step[210/483], loss: 1.1216
 Epoch [9/40], Step[220/483], loss: 1.0154
 Epoch [9/40], Step[230/483], loss: 0.9143
 Epoch [9/40], Step[240/483], loss: 1.1883
 Epoch [9/40], Step[250/483], loss: 1.2367
 Epoch [9/40], Step[260/483], loss: 0.7819
 Epoch [9/40], Step[270/483], loss: 1.2138
 Epoch [9/40], Step[280/483], loss: 1.0230
 Epoch [9/40], Step[290/483], loss: 0.8171
 Epoch [9/40], Step[300/483], loss: 1.2157
 Epoch [9/40], Step[310/483], loss: 1.2050
 Epoch [9/40], Step[320/483], loss: 1.2855
 Epoch [9/40], Step[330/483], loss: 1.1422
 Epoch [9/40], Step[340/483], loss: 1.1933
 Epoch [9/40], Step[350/483], loss: 1.1829
 Epoch [9/40], Step[360/483], loss: 0.8922
 Epoch [9/40], Step[370/483], loss: 0.7719
 Epoch [9/40], Step[380/483], loss: 1.0512
 Epoch [9/40], Step[390/483], loss: 1.1564
 Epoch [9/40], Step[400/483], loss: 1.1235
 Epoch [9/40], Step[410/483], loss: 0.9048
 Epoch [9/40], Step[420/483], loss: 1.0908
 Epoch [9/40], Step[430/483], loss: 1.0555
 Epoch [9/40], Step[440/483], loss: 1.1619
 Epoch [9/40], Step[450/483], loss: 0.9354
 Epoch [9/40], Step[460/483], loss: 1.2581
 Epoch [9/40], Step[470/483], loss: 1.3580
 Epoch [9/40], Step[480/483], loss: 0.7699
 ====> Epoch 9: Training loss: 556.7263
 ====> Epoch 9: Validation loss: 69.5951
 Epoch [10/40], Step[0/483], loss: 0.9773
 Epoch [10/40], Step[10/483], loss: 1.1299
 Epoch [10/40], Step[20/483], loss: 1.2130
 Epoch [10/40], Step[30/483], loss: 1.1259
 Epoch [10/40], Step[40/483], loss: 1.1647
 Epoch [10/40], Step[50/483], loss: 1.2974
 Epoch [10/40], Step[60/483], loss: 1.4174
 Epoch [10/40], Step[70/483], loss: 1.2224
 Epoch [10/40], Step[80/483], loss: 1.4682
 Epoch [10/40], Step[90/483], loss: 0.9917
 Epoch [10/40], Step[100/483], loss: 1.0053
 Epoch [10/40], Step[110/483], loss: 1.1774
 Epoch [10/40], Step[120/483], loss: 1.2945
 Epoch [10/40], Step[130/483], loss: 1.0451
 Epoch [10/40], Step[140/483], loss: 1.1940
 Epoch [10/40], Step[150/483], loss: 1.2711
 Epoch [10/40], Step[160/483], loss: 1.3864
 Epoch [10/40], Step[170/483], loss: 0.9141
 Epoch [10/40], Step[180/483], loss: 1.3077
 Epoch [10/40], Step[190/483], loss: 1.2979
 Epoch [10/40], Step[200/483], loss: 0.9300
 Epoch [10/40], Step[210/483], loss: 1.1158
 Epoch [10/40], Step[220/483], loss: 1.0174
 Epoch [10/40], Step[230/483], loss: 0.9526
 Epoch [10/40], Step[240/483], loss: 1.1753
 Epoch [10/40], Step[250/483], loss: 1.2291
 Epoch [10/40], Step[260/483], loss: 0.7727
 Epoch [10/40], Step[270/483], loss: 1.1848
 Epoch [10/40], Step[280/483], loss: 1.0009
 Epoch [10/40], Step[290/483], loss: 0.8454
 Epoch [10/40], Step[300/483], loss: 1.1751
 Epoch [10/40], Step[310/483], loss: 1.1675
 Epoch [10/40], Step[320/483], loss: 1.2845
 Epoch [10/40], Step[330/483], loss: 1.1533
 Epoch [10/40], Step[340/483], loss: 1.2068
 Epoch [10/40], Step[350/483], loss: 1.1760
 Epoch [10/40], Step[360/483], loss: 0.8878
 Epoch [10/40], Step[370/483], loss: 0.7702
 Epoch [10/40], Step[380/483], loss: 1.0569
 Epoch [10/40], Step[390/483], loss: 1.1611
 Epoch [10/40], Step[400/483], loss: 1.1438
 Epoch [10/40], Step[410/483], loss: 0.8834
 Epoch [10/40], Step[420/483], loss: 1.0915
 Epoch [10/40], Step[430/483], loss: 1.0706
 Epoch [10/40], Step[440/483], loss: 1.1478
 Epoch [10/40], Step[450/483], loss: 0.9063
 Epoch [10/40], Step[460/483], loss: 1.2260
 Epoch [10/40], Step[470/483], loss: 1.3792
 Epoch [10/40], Step[480/483], loss: 0.7707
 ====> Epoch 10: Training loss: 554.7716
 ====> Epoch 10: Validation loss: 69.3167
 Epoch [11/40], Step[0/483], loss: 0.9703
 Epoch [11/40], Step[10/483], loss: 1.1170
 Epoch [11/40], Step[20/483], loss: 1.2198
 Epoch [11/40], Step[30/483], loss: 1.1199
 Epoch [11/40], Step[40/483], loss: 1.1769
 Epoch [11/40], Step[50/483], loss: 1.2635
 Epoch [11/40], Step[60/483], loss: 1.3801
 Epoch [11/40], Step[70/483], loss: 1.2351
 Epoch [11/40], Step[80/483], loss: 1.4401
 Epoch [11/40], Step[90/483], loss: 0.9667
 Epoch [11/40], Step[100/483], loss: 0.9865
 Epoch [11/40], Step[110/483], loss: 1.1574
 Epoch [11/40], Step[120/483], loss: 1.2954
 Epoch [11/40], Step[130/483], loss: 1.0382
 Epoch [11/40], Step[140/483], loss: 1.2045
 Epoch [11/40], Step[150/483], loss: 1.2597
 Epoch [11/40], Step[160/483], loss: 1.3763
 Epoch [11/40], Step[170/483], loss: 0.9185
 Epoch [11/40], Step[180/483], loss: 1.2993
 Epoch [11/40], Step[190/483], loss: 1.3173
 Epoch [11/40], Step[200/483], loss: 0.9195
 Epoch [11/40], Step[210/483], loss: 1.1264
 Epoch [11/40], Step[220/483], loss: 1.0122
 Epoch [11/40], Step[230/483], loss: 0.9354
 Epoch [11/40], Step[240/483], loss: 1.1962
 Epoch [11/40], Step[250/483], loss: 1.2195
 Epoch [11/40], Step[260/483], loss: 0.7652
 Epoch [11/40], Step[270/483], loss: 1.2005
 Epoch [11/40], Step[280/483], loss: 0.9801
 Epoch [11/40], Step[290/483], loss: 0.8323
 Epoch [11/40], Step[300/483], loss: 1.1802
 Epoch [11/40], Step[310/483], loss: 1.1936
 Epoch [11/40], Step[320/483], loss: 1.2596
 Epoch [11/40], Step[330/483], loss: 1.1416
 Epoch [11/40], Step[340/483], loss: 1.2046
 Epoch [11/40], Step[350/483], loss: 1.1783
 Epoch [11/40], Step[360/483], loss: 0.8970
 Epoch [11/40], Step[370/483], loss: 0.7804
 Epoch [11/40], Step[380/483], loss: 1.0449
 Epoch [11/40], Step[390/483], loss: 1.1592
 Epoch [11/40], Step[400/483], loss: 1.1350
 Epoch [11/40], Step[410/483], loss: 0.8959
 Epoch [11/40], Step[420/483], loss: 1.0719
 Epoch [11/40], Step[430/483], loss: 1.0849
 Epoch [11/40], Step[440/483], loss: 1.1602
 Epoch [11/40], Step[450/483], loss: 0.9287
 Epoch [11/40], Step[460/483], loss: 1.2481
 Epoch [11/40], Step[470/483], loss: 1.3493
 Epoch [11/40], Step[480/483], loss: 0.7446
 ====> Epoch 11: Training loss: 552.6367
 ====> Epoch 11: Validation loss: 69.2834
 Epoch [12/40], Step[0/483], loss: 0.9649
 Epoch [12/40], Step[10/483], loss: 1.1213
 Epoch [12/40], Step[20/483], loss: 1.2013
 Epoch [12/40], Step[30/483], loss: 1.1280
 Epoch [12/40], Step[40/483], loss: 1.2081
 Epoch [12/40], Step[50/483], loss: 1.2886
 Epoch [12/40], Step[60/483], loss: 1.3824
 Epoch [12/40], Step[70/483], loss: 1.2423
 Epoch [12/40], Step[80/483], loss: 1.4326
 Epoch [12/40], Step[90/483], loss: 1.0160
 Epoch [12/40], Step[100/483], loss: 0.9725
 Epoch [12/40], Step[110/483], loss: 1.1774
 Epoch [12/40], Step[120/483], loss: 1.2611
 Epoch [12/40], Step[130/483], loss: 1.0739
 Epoch [12/40], Step[140/483], loss: 1.2100
 Epoch [12/40], Step[150/483], loss: 1.2411
 Epoch [12/40], Step[160/483], loss: 1.3662
 Epoch [12/40], Step[170/483], loss: 0.9153
 Epoch [12/40], Step[180/483], loss: 1.2928
 Epoch [12/40], Step[190/483], loss: 1.3232
 Epoch [12/40], Step[200/483], loss: 0.9210
 Epoch [12/40], Step[210/483], loss: 1.1444
 Epoch [12/40], Step[220/483], loss: 1.0233
 Epoch [12/40], Step[230/483], loss: 0.9107
 Epoch [12/40], Step[240/483], loss: 1.2082
 Epoch [12/40], Step[250/483], loss: 1.2241
 Epoch [12/40], Step[260/483], loss: 0.7726
 Epoch [12/40], Step[270/483], loss: 1.1689
 Epoch [12/40], Step[280/483], loss: 0.9831
 Epoch [12/40], Step[290/483], loss: 0.8279
 Epoch [12/40], Step[300/483], loss: 1.1934
 Epoch [12/40], Step[310/483], loss: 1.1434
 Epoch [12/40], Step[320/483], loss: 1.2887
 Epoch [12/40], Step[330/483], loss: 1.1118
 Epoch [12/40], Step[340/483], loss: 1.1939
 Epoch [12/40], Step[350/483], loss: 1.1586
 Epoch [12/40], Step[360/483], loss: 0.8977
 Epoch [12/40], Step[370/483], loss: 0.7688
 Epoch [12/40], Step[380/483], loss: 1.0343
 Epoch [12/40], Step[390/483], loss: 1.1420
 Epoch [12/40], Step[400/483], loss: 1.0989
 Epoch [12/40], Step[410/483], loss: 0.8922
 Epoch [12/40], Step[420/483], loss: 1.0573
 Epoch [12/40], Step[430/483], loss: 1.0644
 Epoch [12/40], Step[440/483], loss: 1.1355
 Epoch [12/40], Step[450/483], loss: 0.9452
 Epoch [12/40], Step[460/483], loss: 1.2188
 Epoch [12/40], Step[470/483], loss: 1.3605
 Epoch [12/40], Step[480/483], loss: 0.7505
 ====> Epoch 12: Training loss: 550.7474
 ====> Epoch 12: Validation loss: 68.9541
 Epoch [13/40], Step[0/483], loss: 0.9726
 Epoch [13/40], Step[10/483], loss: 1.1305
 Epoch [13/40], Step[20/483], loss: 1.2003
 Epoch [13/40], Step[30/483], loss: 1.1358
 Epoch [13/40], Step[40/483], loss: 1.1820
 Epoch [13/40], Step[50/483], loss: 1.2853
 Epoch [13/40], Step[60/483], loss: 1.3946
 Epoch [13/40], Step[70/483], loss: 1.2438
 Epoch [13/40], Step[80/483], loss: 1.4451
 Epoch [13/40], Step[90/483], loss: 0.9608
 Epoch [13/40], Step[100/483], loss: 0.9769
 Epoch [13/40], Step[110/483], loss: 1.1855
 Epoch [13/40], Step[120/483], loss: 1.2690
 Epoch [13/40], Step[130/483], loss: 1.0691
 Epoch [13/40], Step[140/483], loss: 1.2146
 Epoch [13/40], Step[150/483], loss: 1.2440
 Epoch [13/40], Step[160/483], loss: 1.3386
 Epoch [13/40], Step[170/483], loss: 0.8910
 Epoch [13/40], Step[180/483], loss: 1.3227
 Epoch [13/40], Step[190/483], loss: 1.2710
 Epoch [13/40], Step[200/483], loss: 0.9017
 Epoch [13/40], Step[210/483], loss: 1.1518
 Epoch [13/40], Step[220/483], loss: 0.9973
 Epoch [13/40], Step[230/483], loss: 0.9119
 Epoch [13/40], Step[240/483], loss: 1.1625
 Epoch [13/40], Step[250/483], loss: 1.2077
 Epoch [13/40], Step[260/483], loss: 0.7809
 Epoch [13/40], Step[270/483], loss: 1.1660
 Epoch [13/40], Step[280/483], loss: 0.9815
 Epoch [13/40], Step[290/483], loss: 0.8125
 Epoch [13/40], Step[300/483], loss: 1.1695
 Epoch [13/40], Step[310/483], loss: 1.1654
 Epoch [13/40], Step[320/483], loss: 1.2905
 Epoch [13/40], Step[330/483], loss: 1.1296
 Epoch [13/40], Step[340/483], loss: 1.1890
 Epoch [13/40], Step[350/483], loss: 1.1562
 Epoch [13/40], Step[360/483], loss: 0.9164
 Epoch [13/40], Step[370/483], loss: 0.7731
 Epoch [13/40], Step[380/483], loss: 1.0678
 Epoch [13/40], Step[390/483], loss: 1.1356
 Epoch [13/40], Step[400/483], loss: 1.1372
 Epoch [13/40], Step[410/483], loss: 0.8834
 Epoch [13/40], Step[420/483], loss: 1.0818
 Epoch [13/40], Step[430/483], loss: 1.0792
 Epoch [13/40], Step[440/483], loss: 1.1102
 Epoch [13/40], Step[450/483], loss: 0.9359
 Epoch [13/40], Step[460/483], loss: 1.2413
 Epoch [13/40], Step[470/483], loss: 1.3648
 Epoch [13/40], Step[480/483], loss: 0.7500
 ====> Epoch 13: Training loss: 550.5773
 ====> Epoch 13: Validation loss: 68.9885
 Epoch [14/40], Step[0/483], loss: 0.9756
 Epoch [14/40], Step[10/483], loss: 1.1239
 Epoch [14/40], Step[20/483], loss: 1.2285
 Epoch [14/40], Step[30/483], loss: 1.1270
 Epoch [14/40], Step[40/483], loss: 1.1588
 Epoch [14/40], Step[50/483], loss: 1.2749
 Epoch [14/40], Step[60/483], loss: 1.3546
 Epoch [14/40], Step[70/483], loss: 1.2109
 Epoch [14/40], Step[80/483], loss: 1.4583
 Epoch [14/40], Step[90/483], loss: 0.9515
 Epoch [14/40], Step[100/483], loss: 0.9758
 Epoch [14/40], Step[110/483], loss: 1.1939
 Epoch [14/40], Step[120/483], loss: 1.2789
 Epoch [14/40], Step[130/483], loss: 1.0775
 Epoch [14/40], Step[140/483], loss: 1.1897
 Epoch [14/40], Step[150/483], loss: 1.2462
 Epoch [14/40], Step[160/483], loss: 1.3731
 Epoch [14/40], Step[170/483], loss: 0.9139
 Epoch [14/40], Step[180/483], loss: 1.2848
 Epoch [14/40], Step[190/483], loss: 1.2813
 Epoch [14/40], Step[200/483], loss: 0.9115
 Epoch [14/40], Step[210/483], loss: 1.1297
 Epoch [14/40], Step[220/483], loss: 1.0064
 Epoch [14/40], Step[230/483], loss: 0.9288
 Epoch [14/40], Step[240/483], loss: 1.1886
 Epoch [14/40], Step[250/483], loss: 1.2525
 Epoch [14/40], Step[260/483], loss: 0.7577
 Epoch [14/40], Step[270/483], loss: 1.1711
 Epoch [14/40], Step[280/483], loss: 0.9811
 Epoch [14/40], Step[290/483], loss: 0.8296
 Epoch [14/40], Step[300/483], loss: 1.1658
 Epoch [14/40], Step[310/483], loss: 1.1765
 Epoch [14/40], Step[320/483], loss: 1.2669
 Epoch [14/40], Step[330/483], loss: 1.1217
 Epoch [14/40], Step[340/483], loss: 1.2207
 Epoch [14/40], Step[350/483], loss: 1.1801
 Epoch [14/40], Step[360/483], loss: 0.8983
 Epoch [14/40], Step[370/483], loss: 0.7646
 Epoch [14/40], Step[380/483], loss: 1.0356
 Epoch [14/40], Step[390/483], loss: 1.1159
 Epoch [14/40], Step[400/483], loss: 1.1453
 Epoch [14/40], Step[410/483], loss: 0.8942
 Epoch [14/40], Step[420/483], loss: 1.0520
 Epoch [14/40], Step[430/483], loss: 1.0626
 Epoch [14/40], Step[440/483], loss: 1.1428
 Epoch [14/40], Step[450/483], loss: 0.9095
 Epoch [14/40], Step[460/483], loss: 1.2487
 Epoch [14/40], Step[470/483], loss: 1.3444
 Epoch [14/40], Step[480/483], loss: 0.7436
 ====> Epoch 14: Training loss: 548.8223
 ====> Epoch 14: Validation loss: 68.6684
 Epoch [15/40], Step[0/483], loss: 0.9648
 Epoch [15/40], Step[10/483], loss: 1.1159
 Epoch [15/40], Step[20/483], loss: 1.2063
 Epoch [15/40], Step[30/483], loss: 1.1341
 Epoch [15/40], Step[40/483], loss: 1.1617
 Epoch [15/40], Step[50/483], loss: 1.2768
 Epoch [15/40], Step[60/483], loss: 1.3794
 Epoch [15/40], Step[70/483], loss: 1.2337
 Epoch [15/40], Step[80/483], loss: 1.3883
 Epoch [15/40], Step[90/483], loss: 0.9631
 Epoch [15/40], Step[100/483], loss: 0.9910
 Epoch [15/40], Step[110/483], loss: 1.1658
 Epoch [15/40], Step[120/483], loss: 1.2652
 Epoch [15/40], Step[130/483], loss: 1.0598
 Epoch [15/40], Step[140/483], loss: 1.2127
 Epoch [15/40], Step[150/483], loss: 1.2468
 Epoch [15/40], Step[160/483], loss: 1.3507
 Epoch [15/40], Step[170/483], loss: 0.9069
 Epoch [15/40], Step[180/483], loss: 1.2620
 Epoch [15/40], Step[190/483], loss: 1.2756
 Epoch [15/40], Step[200/483], loss: 0.9045
 Epoch [15/40], Step[210/483], loss: 1.1483
 Epoch [15/40], Step[220/483], loss: 1.0158
 Epoch [15/40], Step[230/483], loss: 0.9246
 Epoch [15/40], Step[240/483], loss: 1.2073
 Epoch [15/40], Step[250/483], loss: 1.2019
 Epoch [15/40], Step[260/483], loss: 0.7665
 Epoch [15/40], Step[270/483], loss: 1.1514
 Epoch [15/40], Step[280/483], loss: 0.9862
 Epoch [15/40], Step[290/483], loss: 0.8243
 Epoch [15/40], Step[300/483], loss: 1.1783
 Epoch [15/40], Step[310/483], loss: 1.1518
 Epoch [15/40], Step[320/483], loss: 1.2515
 Epoch [15/40], Step[330/483], loss: 1.1051
 Epoch [15/40], Step[340/483], loss: 1.1931
 Epoch [15/40], Step[350/483], loss: 1.1330
 Epoch [15/40], Step[360/483], loss: 0.8799
 Epoch [15/40], Step[370/483], loss: 0.7698
 Epoch [15/40], Step[380/483], loss: 1.0440
 Epoch [15/40], Step[390/483], loss: 1.1546
 Epoch [15/40], Step[400/483], loss: 1.1151
 Epoch [15/40], Step[410/483], loss: 0.8725
 Epoch [15/40], Step[420/483], loss: 1.0749
 Epoch [15/40], Step[430/483], loss: 1.0835
 Epoch [15/40], Step[440/483], loss: 1.1296
 Epoch [15/40], Step[450/483], loss: 0.8846
 Epoch [15/40], Step[460/483], loss: 1.2330
 Epoch [15/40], Step[470/483], loss: 1.3461
 Epoch [15/40], Step[480/483], loss: 0.7560
 ====> Epoch 15: Training loss: 548.4118
 ====> Epoch 15: Validation loss: 68.6898
 Epoch [16/40], Step[0/483], loss: 0.9722
 Epoch [16/40], Step[10/483], loss: 1.1381
 Epoch [16/40], Step[20/483], loss: 1.2080
 Epoch [16/40], Step[30/483], loss: 1.1274
 Epoch [16/40], Step[40/483], loss: 1.1848
 Epoch [16/40], Step[50/483], loss: 1.2389
 Epoch [16/40], Step[60/483], loss: 1.3567
 Epoch [16/40], Step[70/483], loss: 1.2393
 Epoch [16/40], Step[80/483], loss: 1.4398
 Epoch [16/40], Step[90/483], loss: 0.9733
 Epoch [16/40], Step[100/483], loss: 0.9843
 Epoch [16/40], Step[110/483], loss: 1.1735
 Epoch [16/40], Step[120/483], loss: 1.2556
 Epoch [16/40], Step[130/483], loss: 1.0484
 Epoch [16/40], Step[140/483], loss: 1.2160
 Epoch [16/40], Step[150/483], loss: 1.2773
 Epoch [16/40], Step[160/483], loss: 1.3651
 Epoch [16/40], Step[170/483], loss: 0.8949
 Epoch [16/40], Step[180/483], loss: 1.2705
 Epoch [16/40], Step[190/483], loss: 1.2554
 Epoch [16/40], Step[200/483], loss: 0.8868
 Epoch [16/40], Step[210/483], loss: 1.1255
 Epoch [16/40], Step[220/483], loss: 1.0281
 Epoch [16/40], Step[230/483], loss: 0.9108
 Epoch [16/40], Step[240/483], loss: 1.1736
 Epoch [16/40], Step[250/483], loss: 1.1960
 Epoch [16/40], Step[260/483], loss: 0.7512
 Epoch [16/40], Step[270/483], loss: 1.1478
 Epoch [16/40], Step[280/483], loss: 0.9608
 Epoch [16/40], Step[290/483], loss: 0.8288
 Epoch [16/40], Step[300/483], loss: 1.1556
 Epoch [16/40], Step[310/483], loss: 1.1506
 Epoch [16/40], Step[320/483], loss: 1.2498
 Epoch [16/40], Step[330/483], loss: 1.1401
 Epoch [16/40], Step[340/483], loss: 1.2184
 Epoch [16/40], Step[350/483], loss: 1.1610
 Epoch [16/40], Step[360/483], loss: 0.8839
 Epoch [16/40], Step[370/483], loss: 0.7643
 Epoch [16/40], Step[380/483], loss: 1.0369
 Epoch [16/40], Step[390/483], loss: 1.1319
 Epoch [16/40], Step[400/483], loss: 1.1221
 Epoch [16/40], Step[410/483], loss: 0.8892
 Epoch [16/40], Step[420/483], loss: 1.0677
 Epoch [16/40], Step[430/483], loss: 1.0392
 Epoch [16/40], Step[440/483], loss: 1.1458
 Epoch [16/40], Step[450/483], loss: 0.9324
 Epoch [16/40], Step[460/483], loss: 1.2354
 Epoch [16/40], Step[470/483], loss: 1.3429
 Epoch [16/40], Step[480/483], loss: 0.7708
 ====> Epoch 16: Training loss: 547.0650
 ====> Epoch 16: Validation loss: 68.7010
 Epoch [17/40], Step[0/483], loss: 0.9756
 Epoch [17/40], Step[10/483], loss: 1.0830
 Epoch [17/40], Step[20/483], loss: 1.1882
 Epoch [17/40], Step[30/483], loss: 1.1309
 Epoch [17/40], Step[40/483], loss: 1.1656
 Epoch [17/40], Step[50/483], loss: 1.2487
 Epoch [17/40], Step[60/483], loss: 1.3624
 Epoch [17/40], Step[70/483], loss: 1.2142
 Epoch [17/40], Step[80/483], loss: 1.4051
 Epoch [17/40], Step[90/483], loss: 0.9848
 Epoch [17/40], Step[100/483], loss: 0.9896
 Epoch [17/40], Step[110/483], loss: 1.1583
 Epoch [17/40], Step[120/483], loss: 1.2687
 Epoch [17/40], Step[130/483], loss: 1.0346
 Epoch [17/40], Step[140/483], loss: 1.2266
 Epoch [17/40], Step[150/483], loss: 1.2618
 Epoch [17/40], Step[160/483], loss: 1.3573
 Epoch [17/40], Step[170/483], loss: 0.8913
 Epoch [17/40], Step[180/483], loss: 1.2830
 Epoch [17/40], Step[190/483], loss: 1.2947
 Epoch [17/40], Step[200/483], loss: 0.8829
 Epoch [17/40], Step[210/483], loss: 1.1251
 Epoch [17/40], Step[220/483], loss: 1.0080
 Epoch [17/40], Step[230/483], loss: 0.9045
 Epoch [17/40], Step[240/483], loss: 1.1684
 Epoch [17/40], Step[250/483], loss: 1.1833
 Epoch [17/40], Step[260/483], loss: 0.7455
 Epoch [17/40], Step[270/483], loss: 1.1476
 Epoch [17/40], Step[280/483], loss: 0.9877
 Epoch [17/40], Step[290/483], loss: 0.8182
 Epoch [17/40], Step[300/483], loss: 1.1600
 Epoch [17/40], Step[310/483], loss: 1.1902
 Epoch [17/40], Step[320/483], loss: 1.2288
 Epoch [17/40], Step[330/483], loss: 1.1445
 Epoch [17/40], Step[340/483], loss: 1.1961
 Epoch [17/40], Step[350/483], loss: 1.1495
 Epoch [17/40], Step[360/483], loss: 0.8958
 Epoch [17/40], Step[370/483], loss: 0.7735
 Epoch [17/40], Step[380/483], loss: 1.0492
 Epoch [17/40], Step[390/483], loss: 1.1284
 Epoch [17/40], Step[400/483], loss: 1.1192
 Epoch [17/40], Step[410/483], loss: 0.8988
 Epoch [17/40], Step[420/483], loss: 1.0700
 Epoch [17/40], Step[430/483], loss: 1.0535
 Epoch [17/40], Step[440/483], loss: 1.1510
 Epoch [17/40], Step[450/483], loss: 0.9300
 Epoch [17/40], Step[460/483], loss: 1.2079
 Epoch [17/40], Step[470/483], loss: 1.3351
 Epoch [17/40], Step[480/483], loss: 0.7608
 ====> Epoch 17: Training loss: 546.1672
 ====> Epoch 17: Validation loss: 68.6093
 Epoch [18/40], Step[0/483], loss: 0.9904
 Epoch [18/40], Step[10/483], loss: 1.1090
 Epoch [18/40], Step[20/483], loss: 1.2045
 Epoch [18/40], Step[30/483], loss: 1.1379
 Epoch [18/40], Step[40/483], loss: 1.1646
 Epoch [18/40], Step[50/483], loss: 1.2831
 Epoch [18/40], Step[60/483], loss: 1.3510
 Epoch [18/40], Step[70/483], loss: 1.2445
 Epoch [18/40], Step[80/483], loss: 1.4147
 Epoch [18/40], Step[90/483], loss: 0.9600
 Epoch [18/40], Step[100/483], loss: 0.9590
 Epoch [18/40], Step[110/483], loss: 1.1829
 Epoch [18/40], Step[120/483], loss: 1.2637
 Epoch [18/40], Step[130/483], loss: 1.0560
 Epoch [18/40], Step[140/483], loss: 1.2228
 Epoch [18/40], Step[150/483], loss: 1.2789
 Epoch [18/40], Step[160/483], loss: 1.3734
 Epoch [18/40], Step[170/483], loss: 0.8770
 Epoch [18/40], Step[180/483], loss: 1.2898
 Epoch [18/40], Step[190/483], loss: 1.2779
 Epoch [18/40], Step[200/483], loss: 0.8973
 Epoch [18/40], Step[210/483], loss: 1.1240
 Epoch [18/40], Step[220/483], loss: 1.0147
 Epoch [18/40], Step[230/483], loss: 0.9130
 Epoch [18/40], Step[240/483], loss: 1.1692
 Epoch [18/40], Step[250/483], loss: 1.2522
 Epoch [18/40], Step[260/483], loss: 0.7786
 Epoch [18/40], Step[270/483], loss: 1.1644
 Epoch [18/40], Step[280/483], loss: 0.9535
 Epoch [18/40], Step[290/483], loss: 0.8241
 Epoch [18/40], Step[300/483], loss: 1.1801
 Epoch [18/40], Step[310/483], loss: 1.1327
 Epoch [18/40], Step[320/483], loss: 1.2468
 Epoch [18/40], Step[330/483], loss: 1.1190
 Epoch [18/40], Step[340/483], loss: 1.1823
 Epoch [18/40], Step[350/483], loss: 1.1178
 Epoch [18/40], Step[360/483], loss: 0.8910
 Epoch [18/40], Step[370/483], loss: 0.7663
 Epoch [18/40], Step[380/483], loss: 1.0440
 Epoch [18/40], Step[390/483], loss: 1.1567
 Epoch [18/40], Step[400/483], loss: 1.1059
 Epoch [18/40], Step[410/483], loss: 0.8760
 Epoch [18/40], Step[420/483], loss: 1.0620
 Epoch [18/40], Step[430/483], loss: 1.0687
 Epoch [18/40], Step[440/483], loss: 1.1047
 Epoch [18/40], Step[450/483], loss: 0.9099
 Epoch [18/40], Step[460/483], loss: 1.2310
 Epoch [18/40], Step[470/483], loss: 1.3542
 Epoch [18/40], Step[480/483], loss: 0.7485
 ====> Epoch 18: Training loss: 545.9854
 ====> Epoch 18: Validation loss: 68.3530
 Epoch [19/40], Step[0/483], loss: 0.9574
 Epoch [19/40], Step[10/483], loss: 1.1095
 Epoch [19/40], Step[20/483], loss: 1.2057
 Epoch [19/40], Step[30/483], loss: 1.1306
 Epoch [19/40], Step[40/483], loss: 1.1600
 Epoch [19/40], Step[50/483], loss: 1.2512
 Epoch [19/40], Step[60/483], loss: 1.3413
 Epoch [19/40], Step[70/483], loss: 1.2326
 Epoch [19/40], Step[80/483], loss: 1.3881
 Epoch [19/40], Step[90/483], loss: 0.9702
 Epoch [19/40], Step[100/483], loss: 0.9774
 Epoch [19/40], Step[110/483], loss: 1.1701
 Epoch [19/40], Step[120/483], loss: 1.2451
 Epoch [19/40], Step[130/483], loss: 1.0480
 Epoch [19/40], Step[140/483], loss: 1.2069
 Epoch [19/40], Step[150/483], loss: 1.2541
 Epoch [19/40], Step[160/483], loss: 1.3533
 Epoch [19/40], Step[170/483], loss: 0.8715
 Epoch [19/40], Step[180/483], loss: 1.2913
 Epoch [19/40], Step[190/483], loss: 1.3115
 Epoch [19/40], Step[200/483], loss: 0.9087
 Epoch [19/40], Step[210/483], loss: 1.1080
 Epoch [19/40], Step[220/483], loss: 0.9904
 Epoch [19/40], Step[230/483], loss: 0.9212
 Epoch [19/40], Step[240/483], loss: 1.1891
 Epoch [19/40], Step[250/483], loss: 1.1969
 Epoch [19/40], Step[260/483], loss: 0.7493
 Epoch [19/40], Step[270/483], loss: 1.1503
 Epoch [19/40], Step[280/483], loss: 0.9935
 Epoch [19/40], Step[290/483], loss: 0.8078
 Epoch [19/40], Step[300/483], loss: 1.1671
 Epoch [19/40], Step[310/483], loss: 1.1434
 Epoch [19/40], Step[320/483], loss: 1.2594
 Epoch [19/40], Step[330/483], loss: 1.1246
 Epoch [19/40], Step[340/483], loss: 1.1970
 Epoch [19/40], Step[350/483], loss: 1.1364
 Epoch [19/40], Step[360/483], loss: 0.8976
 Epoch [19/40], Step[370/483], loss: 0.7828
 Epoch [19/40], Step[380/483], loss: 1.0450
 Epoch [19/40], Step[390/483], loss: 1.1240
 Epoch [19/40], Step[400/483], loss: 1.1076
 Epoch [19/40], Step[410/483], loss: 0.8793
 Epoch [19/40], Step[420/483], loss: 1.0440
 Epoch [19/40], Step[430/483], loss: 1.0604
 Epoch [19/40], Step[440/483], loss: 1.1164
 Epoch [19/40], Step[450/483], loss: 0.9415
 Epoch [19/40], Step[460/483], loss: 1.2210
 Epoch [19/40], Step[470/483], loss: 1.3295
 Epoch [19/40], Step[480/483], loss: 0.7526
 ====> Epoch 19: Training loss: 545.2996
 ====> Epoch 19: Validation loss: 68.3169
 Epoch [20/40], Step[0/483], loss: 0.9813
 Epoch [20/40], Step[10/483], loss: 1.1249
 Epoch [20/40], Step[20/483], loss: 1.2000
 Epoch [20/40], Step[30/483], loss: 1.1068
 Epoch [20/40], Step[40/483], loss: 1.1726
 Epoch [20/40], Step[50/483], loss: 1.2831
 Epoch [20/40], Step[60/483], loss: 1.3874
 Epoch [20/40], Step[70/483], loss: 1.2243
 Epoch [20/40], Step[80/483], loss: 1.4168
 Epoch [20/40], Step[90/483], loss: 0.9667
 Epoch [20/40], Step[100/483], loss: 0.9641
 Epoch [20/40], Step[110/483], loss: 1.1664
 Epoch [20/40], Step[120/483], loss: 1.2535
 Epoch [20/40], Step[130/483], loss: 1.0627
 Epoch [20/40], Step[140/483], loss: 1.2109
 Epoch [20/40], Step[150/483], loss: 1.2390
 Epoch [20/40], Step[160/483], loss: 1.3525
 Epoch [20/40], Step[170/483], loss: 0.8938
 Epoch [20/40], Step[180/483], loss: 1.2778
 Epoch [20/40], Step[190/483], loss: 1.2592
 Epoch [20/40], Step[200/483], loss: 0.9088
 Epoch [20/40], Step[210/483], loss: 1.1191
 Epoch [20/40], Step[220/483], loss: 1.0011
 Epoch [20/40], Step[230/483], loss: 0.8898
 Epoch [20/40], Step[240/483], loss: 1.1572
 Epoch [20/40], Step[250/483], loss: 1.1698
 Epoch [20/40], Step[260/483], loss: 0.7576
 Epoch [20/40], Step[270/483], loss: 1.1566
 Epoch [20/40], Step[280/483], loss: 0.9833
 Epoch [20/40], Step[290/483], loss: 0.8256
 Epoch [20/40], Step[300/483], loss: 1.1662
 Epoch [20/40], Step[310/483], loss: 1.1485
 Epoch [20/40], Step[320/483], loss: 1.2266
 Epoch [20/40], Step[330/483], loss: 1.1332
 Epoch [20/40], Step[340/483], loss: 1.2051
 Epoch [20/40], Step[350/483], loss: 1.1527
 Epoch [20/40], Step[360/483], loss: 0.8896
 Epoch [20/40], Step[370/483], loss: 0.7789
 Epoch [20/40], Step[380/483], loss: 1.0338
 Epoch [20/40], Step[390/483], loss: 1.1271
 Epoch [20/40], Step[400/483], loss: 1.1498
 Epoch [20/40], Step[410/483], loss: 0.8815
 Epoch [20/40], Step[420/483], loss: 1.0629
 Epoch [20/40], Step[430/483], loss: 1.0880
 Epoch [20/40], Step[440/483], loss: 1.1394
 Epoch [20/40], Step[450/483], loss: 0.9025
 Epoch [20/40], Step[460/483], loss: 1.2367
 Epoch [20/40], Step[470/483], loss: 1.3485
 Epoch [20/40], Step[480/483], loss: 0.7504
 ====> Epoch 20: Training loss: 544.4918
 ====> Epoch 20: Validation loss: 68.5363
 Epoch [21/40], Step[0/483], loss: 0.9350
 Epoch [21/40], Step[10/483], loss: 1.1043
 Epoch [21/40], Step[20/483], loss: 1.2347
 Epoch [21/40], Step[30/483], loss: 1.1333
 Epoch [21/40], Step[40/483], loss: 1.1415
 Epoch [21/40], Step[50/483], loss: 1.2689
 Epoch [21/40], Step[60/483], loss: 1.3795
 Epoch [21/40], Step[70/483], loss: 1.1982
 Epoch [21/40], Step[80/483], loss: 1.4016
 Epoch [21/40], Step[90/483], loss: 0.9473
 Epoch [21/40], Step[100/483], loss: 0.9774
 Epoch [21/40], Step[110/483], loss: 1.1530
 Epoch [21/40], Step[120/483], loss: 1.2445
 Epoch [21/40], Step[130/483], loss: 1.0544
 Epoch [21/40], Step[140/483], loss: 1.2141
 Epoch [21/40], Step[150/483], loss: 1.2623
 Epoch [21/40], Step[160/483], loss: 1.3457
 Epoch [21/40], Step[170/483], loss: 0.9135
 Epoch [21/40], Step[180/483], loss: 1.2718
 Epoch [21/40], Step[190/483], loss: 1.2571
 Epoch [21/40], Step[200/483], loss: 0.9013
 Epoch [21/40], Step[210/483], loss: 1.1096
 Epoch [21/40], Step[220/483], loss: 1.0010
 Epoch [21/40], Step[230/483], loss: 0.9131
 Epoch [21/40], Step[240/483], loss: 1.1792
 Epoch [21/40], Step[250/483], loss: 1.1875
 Epoch [21/40], Step[260/483], loss: 0.7718
 Epoch [21/40], Step[270/483], loss: 1.1525
 Epoch [21/40], Step[280/483], loss: 0.9768
 Epoch [21/40], Step[290/483], loss: 0.8161
 Epoch [21/40], Step[300/483], loss: 1.1590
 Epoch [21/40], Step[310/483], loss: 1.1384
 Epoch [21/40], Step[320/483], loss: 1.2769
 Epoch [21/40], Step[330/483], loss: 1.1503
 Epoch [21/40], Step[340/483], loss: 1.1600
 Epoch [21/40], Step[350/483], loss: 1.1430
 Epoch [21/40], Step[360/483], loss: 0.8771
 Epoch [21/40], Step[370/483], loss: 0.7537
 Epoch [21/40], Step[380/483], loss: 1.0318
 Epoch [21/40], Step[390/483], loss: 1.1192
 Epoch [21/40], Step[400/483], loss: 1.1243
 Epoch [21/40], Step[410/483], loss: 0.8978
 Epoch [21/40], Step[420/483], loss: 1.0622
 Epoch [21/40], Step[430/483], loss: 1.0683
 Epoch [21/40], Step[440/483], loss: 1.1056
 Epoch [21/40], Step[450/483], loss: 0.9201
 Epoch [21/40], Step[460/483], loss: 1.2259
 Epoch [21/40], Step[470/483], loss: 1.3082
 Epoch [21/40], Step[480/483], loss: 0.7327
 ====> Epoch 21: Training loss: 544.1084
 ====> Epoch 21: Validation loss: 68.7889
 Epoch [22/40], Step[0/483], loss: 0.9582
 Epoch [22/40], Step[10/483], loss: 1.1064
 Epoch [22/40], Step[20/483], loss: 1.1960
 Epoch [22/40], Step[30/483], loss: 1.1288
 Epoch [22/40], Step[40/483], loss: 1.1978
 Epoch [22/40], Step[50/483], loss: 1.2755
 Epoch [22/40], Step[60/483], loss: 1.3551
 Epoch [22/40], Step[70/483], loss: 1.2053
 Epoch [22/40], Step[80/483], loss: 1.4109
 Epoch [22/40], Step[90/483], loss: 0.9462
 Epoch [22/40], Step[100/483], loss: 0.9651
 Epoch [22/40], Step[110/483], loss: 1.1639
 Epoch [22/40], Step[120/483], loss: 1.2670
 Epoch [22/40], Step[130/483], loss: 1.0691
 Epoch [22/40], Step[140/483], loss: 1.2058
 Epoch [22/40], Step[150/483], loss: 1.2251
 Epoch [22/40], Step[160/483], loss: 1.3487
 Epoch [22/40], Step[170/483], loss: 0.9126
 Epoch [22/40], Step[180/483], loss: 1.2582
 Epoch [22/40], Step[190/483], loss: 1.2693
 Epoch [22/40], Step[200/483], loss: 0.9066
 Epoch [22/40], Step[210/483], loss: 1.1099
 Epoch [22/40], Step[220/483], loss: 1.0042
 Epoch [22/40], Step[230/483], loss: 0.9055
 Epoch [22/40], Step[240/483], loss: 1.1709
 Epoch [22/40], Step[250/483], loss: 1.1933
 Epoch [22/40], Step[260/483], loss: 0.7579
 Epoch [22/40], Step[270/483], loss: 1.1507
 Epoch [22/40], Step[280/483], loss: 0.9436
 Epoch [22/40], Step[290/483], loss: 0.8109
 Epoch [22/40], Step[300/483], loss: 1.1573
 Epoch [22/40], Step[310/483], loss: 1.1808
 Epoch [22/40], Step[320/483], loss: 1.2231
 Epoch [22/40], Step[330/483], loss: 1.1330
 Epoch [22/40], Step[340/483], loss: 1.2309
 Epoch [22/40], Step[350/483], loss: 1.1481
 Epoch [22/40], Step[360/483], loss: 0.8686
 Epoch [22/40], Step[370/483], loss: 0.7573
 Epoch [22/40], Step[380/483], loss: 1.0414
 Epoch [22/40], Step[390/483], loss: 1.1343
 Epoch [22/40], Step[400/483], loss: 1.1560
 Epoch [22/40], Step[410/483], loss: 0.8742
 Epoch [22/40], Step[420/483], loss: 1.0740
 Epoch [22/40], Step[430/483], loss: 1.0501
 Epoch [22/40], Step[440/483], loss: 1.1247
 Epoch [22/40], Step[450/483], loss: 0.8933
 Epoch [22/40], Step[460/483], loss: 1.2014
 Epoch [22/40], Step[470/483], loss: 1.3372
 Epoch [22/40], Step[480/483], loss: 0.7564
 ====> Epoch 22: Training loss: 543.6841
 ====> Epoch 22: Validation loss: 68.5182
 Epoch [23/40], Step[0/483], loss: 0.9372
 Epoch [23/40], Step[10/483], loss: 1.1127
 Epoch [23/40], Step[20/483], loss: 1.2038
 Epoch [23/40], Step[30/483], loss: 1.1111
 Epoch [23/40], Step[40/483], loss: 1.1737
 Epoch [23/40], Step[50/483], loss: 1.2492
 Epoch [23/40], Step[60/483], loss: 1.3957
 Epoch [23/40], Step[70/483], loss: 1.1973
 Epoch [23/40], Step[80/483], loss: 1.3858
 Epoch [23/40], Step[90/483], loss: 0.9452
 Epoch [23/40], Step[100/483], loss: 0.9754
 Epoch [23/40], Step[110/483], loss: 1.1686
 Epoch [23/40], Step[120/483], loss: 1.2168
 Epoch [23/40], Step[130/483], loss: 1.0359
 Epoch [23/40], Step[140/483], loss: 1.2004
 Epoch [23/40], Step[150/483], loss: 1.2417
 Epoch [23/40], Step[160/483], loss: 1.3502
 Epoch [23/40], Step[170/483], loss: 0.8983
 Epoch [23/40], Step[180/483], loss: 1.2870
 Epoch [23/40], Step[190/483], loss: 1.2761
 Epoch [23/40], Step[200/483], loss: 0.9163
 Epoch [23/40], Step[210/483], loss: 1.1277
 Epoch [23/40], Step[220/483], loss: 0.9852
 Epoch [23/40], Step[230/483], loss: 0.9334
 Epoch [23/40], Step[240/483], loss: 1.1514
 Epoch [23/40], Step[250/483], loss: 1.2006
 Epoch [23/40], Step[260/483], loss: 0.7821
 Epoch [23/40], Step[270/483], loss: 1.1489
 Epoch [23/40], Step[280/483], loss: 0.9554
 Epoch [23/40], Step[290/483], loss: 0.8156
 Epoch [23/40], Step[300/483], loss: 1.1849
 Epoch [23/40], Step[310/483], loss: 1.1540
 Epoch [23/40], Step[320/483], loss: 1.2564
 Epoch [23/40], Step[330/483], loss: 1.1338
 Epoch [23/40], Step[340/483], loss: 1.1877
 Epoch [23/40], Step[350/483], loss: 1.1159
 Epoch [23/40], Step[360/483], loss: 0.8990
 Epoch [23/40], Step[370/483], loss: 0.7444
 Epoch [23/40], Step[380/483], loss: 1.0159
 Epoch [23/40], Step[390/483], loss: 1.1044
 Epoch [23/40], Step[400/483], loss: 1.1003
 Epoch [23/40], Step[410/483], loss: 0.8537
 Epoch [23/40], Step[420/483], loss: 1.0719
 Epoch [23/40], Step[430/483], loss: 1.0325
 Epoch [23/40], Step[440/483], loss: 1.1149
 Epoch [23/40], Step[450/483], loss: 0.9315
 Epoch [23/40], Step[460/483], loss: 1.2462
 Epoch [23/40], Step[470/483], loss: 1.3649
 Epoch [23/40], Step[480/483], loss: 0.7434
 ====> Epoch 23: Training loss: 542.8786
 ====> Epoch 23: Validation loss: 68.2513
 Epoch [24/40], Step[0/483], loss: 0.9616
 Epoch [24/40], Step[10/483], loss: 1.1014
 Epoch [24/40], Step[20/483], loss: 1.1784
 Epoch [24/40], Step[30/483], loss: 1.1174
 Epoch [24/40], Step[40/483], loss: 1.1566
 Epoch [24/40], Step[50/483], loss: 1.2700
 Epoch [24/40], Step[60/483], loss: 1.3315
 Epoch [24/40], Step[70/483], loss: 1.2245
 Epoch [24/40], Step[80/483], loss: 1.3820
 Epoch [24/40], Step[90/483], loss: 0.9776
 Epoch [24/40], Step[100/483], loss: 0.9759
 Epoch [24/40], Step[110/483], loss: 1.1616
 Epoch [24/40], Step[120/483], loss: 1.2496
 Epoch [24/40], Step[130/483], loss: 1.0453
 Epoch [24/40], Step[140/483], loss: 1.1977
 Epoch [24/40], Step[150/483], loss: 1.2425
 Epoch [24/40], Step[160/483], loss: 1.3409
 Epoch [24/40], Step[170/483], loss: 0.8963
 Epoch [24/40], Step[180/483], loss: 1.2688
 Epoch [24/40], Step[190/483], loss: 1.2516
 Epoch [24/40], Step[200/483], loss: 0.8988
 Epoch [24/40], Step[210/483], loss: 1.1177
 Epoch [24/40], Step[220/483], loss: 1.0046
 Epoch [24/40], Step[230/483], loss: 0.8855
 Epoch [24/40], Step[240/483], loss: 1.1876
 Epoch [24/40], Step[250/483], loss: 1.1969
 Epoch [24/40], Step[260/483], loss: 0.7724
 Epoch [24/40], Step[270/483], loss: 1.1352
 Epoch [24/40], Step[280/483], loss: 0.9644
 Epoch [24/40], Step[290/483], loss: 0.8123
 Epoch [24/40], Step[300/483], loss: 1.1530
 Epoch [24/40], Step[310/483], loss: 1.1572
 Epoch [24/40], Step[320/483], loss: 1.2623
 Epoch [24/40], Step[330/483], loss: 1.1336
 Epoch [24/40], Step[340/483], loss: 1.1859
 Epoch [24/40], Step[350/483], loss: 1.1378
 Epoch [24/40], Step[360/483], loss: 0.8914
 Epoch [24/40], Step[370/483], loss: 0.7570
 Epoch [24/40], Step[380/483], loss: 1.0310
 Epoch [24/40], Step[390/483], loss: 1.1391
 Epoch [24/40], Step[400/483], loss: 1.1177
 Epoch [24/40], Step[410/483], loss: 0.8925
 Epoch [24/40], Step[420/483], loss: 1.0775
 Epoch [24/40], Step[430/483], loss: 1.0648
 Epoch [24/40], Step[440/483], loss: 1.1319
 Epoch [24/40], Step[450/483], loss: 0.9127
 Epoch [24/40], Step[460/483], loss: 1.2399
 Epoch [24/40], Step[470/483], loss: 1.3229
 Epoch [24/40], Step[480/483], loss: 0.7473
 ====> Epoch 24: Training loss: 542.7997
 ====> Epoch 24: Validation loss: 68.4530
 Epoch [25/40], Step[0/483], loss: 0.9645
 Epoch [25/40], Step[10/483], loss: 1.1239
 Epoch [25/40], Step[20/483], loss: 1.1717
 Epoch [25/40], Step[30/483], loss: 1.1091
 Epoch [25/40], Step[40/483], loss: 1.1570
 Epoch [25/40], Step[50/483], loss: 1.2571
 Epoch [25/40], Step[60/483], loss: 1.3482
 Epoch [25/40], Step[70/483], loss: 1.2057
 Epoch [25/40], Step[80/483], loss: 1.3980
 Epoch [25/40], Step[90/483], loss: 0.9632
 Epoch [25/40], Step[100/483], loss: 0.9780
 Epoch [25/40], Step[110/483], loss: 1.1704
 Epoch [25/40], Step[120/483], loss: 1.2382
 Epoch [25/40], Step[130/483], loss: 1.0630
 Epoch [25/40], Step[140/483], loss: 1.1786
 Epoch [25/40], Step[150/483], loss: 1.2565
 Epoch [25/40], Step[160/483], loss: 1.3690
 Epoch [25/40], Step[170/483], loss: 0.8932
 Epoch [25/40], Step[180/483], loss: 1.2520
 Epoch [25/40], Step[190/483], loss: 1.2555
 Epoch [25/40], Step[200/483], loss: 0.9026
 Epoch [25/40], Step[210/483], loss: 1.1235
 Epoch [25/40], Step[220/483], loss: 1.0112
 Epoch [25/40], Step[230/483], loss: 0.9202
 Epoch [25/40], Step[240/483], loss: 1.1538
 Epoch [25/40], Step[250/483], loss: 1.2079
 Epoch [25/40], Step[260/483], loss: 0.7539
 Epoch [25/40], Step[270/483], loss: 1.1851
 Epoch [25/40], Step[280/483], loss: 0.9613
 Epoch [25/40], Step[290/483], loss: 0.8162
 Epoch [25/40], Step[300/483], loss: 1.1844
 Epoch [25/40], Step[310/483], loss: 1.1674
 Epoch [25/40], Step[320/483], loss: 1.2440
 Epoch [25/40], Step[330/483], loss: 1.1092
 Epoch [25/40], Step[340/483], loss: 1.1807
 Epoch [25/40], Step[350/483], loss: 1.1290
 Epoch [25/40], Step[360/483], loss: 0.8868
 Epoch [25/40], Step[370/483], loss: 0.7542
 Epoch [25/40], Step[380/483], loss: 1.0350
 Epoch [25/40], Step[390/483], loss: 1.1256
 Epoch [25/40], Step[400/483], loss: 1.1133
 Epoch [25/40], Step[410/483], loss: 0.8688
 Epoch [25/40], Step[420/483], loss: 1.0460
 Epoch [25/40], Step[430/483], loss: 1.0332
 Epoch [25/40], Step[440/483], loss: 1.1057
 Epoch [25/40], Step[450/483], loss: 0.9274
 Epoch [25/40], Step[460/483], loss: 1.2147
 Epoch [25/40], Step[470/483], loss: 1.3625
 Epoch [25/40], Step[480/483], loss: 0.7239
 ====> Epoch 25: Training loss: 542.5304
 ====> Epoch 25: Validation loss: 68.3084
 Epoch [26/40], Step[0/483], loss: 0.9616
 Epoch [26/40], Step[10/483], loss: 1.1150
 Epoch [26/40], Step[20/483], loss: 1.2144
 Epoch [26/40], Step[30/483], loss: 1.1238
 Epoch [26/40], Step[40/483], loss: 1.1547
 Epoch [26/40], Step[50/483], loss: 1.2638
 Epoch [26/40], Step[60/483], loss: 1.3674
 Epoch [26/40], Step[70/483], loss: 1.2329
 Epoch [26/40], Step[80/483], loss: 1.4309
 Epoch [26/40], Step[90/483], loss: 0.9737
 Epoch [26/40], Step[100/483], loss: 0.9820
 Epoch [26/40], Step[110/483], loss: 1.1933
 Epoch [26/40], Step[120/483], loss: 1.2525
 Epoch [26/40], Step[130/483], loss: 1.0378
 Epoch [26/40], Step[140/483], loss: 1.2006
 Epoch [26/40], Step[150/483], loss: 1.2404
 Epoch [26/40], Step[160/483], loss: 1.3416
 Epoch [26/40], Step[170/483], loss: 0.8840
 Epoch [26/40], Step[180/483], loss: 1.2531
 Epoch [26/40], Step[190/483], loss: 1.2445
 Epoch [26/40], Step[200/483], loss: 0.9172
 Epoch [26/40], Step[210/483], loss: 1.1340
 Epoch [26/40], Step[220/483], loss: 1.0087
 Epoch [26/40], Step[230/483], loss: 0.8779
 Epoch [26/40], Step[240/483], loss: 1.1480
 Epoch [26/40], Step[250/483], loss: 1.2346
 Epoch [26/40], Step[260/483], loss: 0.7490
 Epoch [26/40], Step[270/483], loss: 1.1484
 Epoch [26/40], Step[280/483], loss: 0.9486
 Epoch [26/40], Step[290/483], loss: 0.8107
 Epoch [26/40], Step[300/483], loss: 1.1796
 Epoch [26/40], Step[310/483], loss: 1.1451
 Epoch [26/40], Step[320/483], loss: 1.2291
 Epoch [26/40], Step[330/483], loss: 1.1334
 Epoch [26/40], Step[340/483], loss: 1.1892
 Epoch [26/40], Step[350/483], loss: 1.1289
 Epoch [26/40], Step[360/483], loss: 0.8848
 Epoch [26/40], Step[370/483], loss: 0.7468
 Epoch [26/40], Step[380/483], loss: 1.0166
 Epoch [26/40], Step[390/483], loss: 1.1255
 Epoch [26/40], Step[400/483], loss: 1.1333
 Epoch [26/40], Step[410/483], loss: 0.8627
 Epoch [26/40], Step[420/483], loss: 1.0623
 Epoch [26/40], Step[430/483], loss: 1.0412
 Epoch [26/40], Step[440/483], loss: 1.1180
 Epoch [26/40], Step[450/483], loss: 0.9238
 Epoch [26/40], Step[460/483], loss: 1.2466
 Epoch [26/40], Step[470/483], loss: 1.3198
 Epoch [26/40], Step[480/483], loss: 0.7251
 ====> Epoch 26: Training loss: 542.0058
 ====> Epoch 26: Validation loss: 68.1578
 Epoch [27/40], Step[0/483], loss: 0.9586
 Epoch [27/40], Step[10/483], loss: 1.1304
 Epoch [27/40], Step[20/483], loss: 1.1976
 Epoch [27/40], Step[30/483], loss: 1.1491
 Epoch [27/40], Step[40/483], loss: 1.1542
 Epoch [27/40], Step[50/483], loss: 1.2407
 Epoch [27/40], Step[60/483], loss: 1.3569
 Epoch [27/40], Step[70/483], loss: 1.2307
 Epoch [27/40], Step[80/483], loss: 1.4160
 Epoch [27/40], Step[90/483], loss: 0.9526
 Epoch [27/40], Step[100/483], loss: 0.9652
 Epoch [27/40], Step[110/483], loss: 1.1616
 Epoch [27/40], Step[120/483], loss: 1.2357
 Epoch [27/40], Step[130/483], loss: 1.0542
 Epoch [27/40], Step[140/483], loss: 1.2193
 Epoch [27/40], Step[150/483], loss: 1.2247
 Epoch [27/40], Step[160/483], loss: 1.3571
 Epoch [27/40], Step[170/483], loss: 0.8941
 Epoch [27/40], Step[180/483], loss: 1.2899
 Epoch [27/40], Step[190/483], loss: 1.2641
 Epoch [27/40], Step[200/483], loss: 0.9027
 Epoch [27/40], Step[210/483], loss: 1.1074
 Epoch [27/40], Step[220/483], loss: 0.9753
 Epoch [27/40], Step[230/483], loss: 0.8992
 Epoch [27/40], Step[240/483], loss: 1.1563
 Epoch [27/40], Step[250/483], loss: 1.1865
 Epoch [27/40], Step[260/483], loss: 0.7665
 Epoch [27/40], Step[270/483], loss: 1.1533
 Epoch [27/40], Step[280/483], loss: 0.9739
 Epoch [27/40], Step[290/483], loss: 0.7844
 Epoch [27/40], Step[300/483], loss: 1.1557
 Epoch [27/40], Step[310/483], loss: 1.1388
 Epoch [27/40], Step[320/483], loss: 1.2202
 Epoch [27/40], Step[330/483], loss: 1.1223
 Epoch [27/40], Step[340/483], loss: 1.1932
 Epoch [27/40], Step[350/483], loss: 1.1124
 Epoch [27/40], Step[360/483], loss: 0.8678
 Epoch [27/40], Step[370/483], loss: 0.7561
 Epoch [27/40], Step[380/483], loss: 1.0444
 Epoch [27/40], Step[390/483], loss: 1.1193
 Epoch [27/40], Step[400/483], loss: 1.1191
 Epoch [27/40], Step[410/483], loss: 0.8692
 Epoch [27/40], Step[420/483], loss: 1.0744
 Epoch [27/40], Step[430/483], loss: 1.0455
 Epoch [27/40], Step[440/483], loss: 1.1404
 Epoch [27/40], Step[450/483], loss: 0.9086
 Epoch [27/40], Step[460/483], loss: 1.2026
 Epoch [27/40], Step[470/483], loss: 1.3268
 Epoch [27/40], Step[480/483], loss: 0.7403
 ====> Epoch 27: Training loss: 541.4317
 ====> Epoch 27: Validation loss: 68.1321
 Epoch [28/40], Step[0/483], loss: 0.9374
 Epoch [28/40], Step[10/483], loss: 1.1172
 Epoch [28/40], Step[20/483], loss: 1.1844
 Epoch [28/40], Step[30/483], loss: 1.1131
 Epoch [28/40], Step[40/483], loss: 1.1543
 Epoch [28/40], Step[50/483], loss: 1.2874
 Epoch [28/40], Step[60/483], loss: 1.3274
 Epoch [28/40], Step[70/483], loss: 1.2056
 Epoch [28/40], Step[80/483], loss: 1.4258
 Epoch [28/40], Step[90/483], loss: 0.9597
 Epoch [28/40], Step[100/483], loss: 0.9756
 Epoch [28/40], Step[110/483], loss: 1.1610
 Epoch [28/40], Step[120/483], loss: 1.2354
 Epoch [28/40], Step[130/483], loss: 1.0696
 Epoch [28/40], Step[140/483], loss: 1.2106
 Epoch [28/40], Step[150/483], loss: 1.2440
 Epoch [28/40], Step[160/483], loss: 1.3766
 Epoch [28/40], Step[170/483], loss: 0.9236
 Epoch [28/40], Step[180/483], loss: 1.2748
 Epoch [28/40], Step[190/483], loss: 1.2448
 Epoch [28/40], Step[200/483], loss: 0.8956
 Epoch [28/40], Step[210/483], loss: 1.1269
 Epoch [28/40], Step[220/483], loss: 1.0066
 Epoch [28/40], Step[230/483], loss: 0.9058
 Epoch [28/40], Step[240/483], loss: 1.1563
 Epoch [28/40], Step[250/483], loss: 1.2054
 Epoch [28/40], Step[260/483], loss: 0.7435
 Epoch [28/40], Step[270/483], loss: 1.1411
 Epoch [28/40], Step[280/483], loss: 0.9763
 Epoch [28/40], Step[290/483], loss: 0.8031
 Epoch [28/40], Step[300/483], loss: 1.1669
 Epoch [28/40], Step[310/483], loss: 1.1388
 Epoch [28/40], Step[320/483], loss: 1.2289
 Epoch [28/40], Step[330/483], loss: 1.1207
 Epoch [28/40], Step[340/483], loss: 1.2090
 Epoch [28/40], Step[350/483], loss: 1.1255
 Epoch [28/40], Step[360/483], loss: 0.8886
 Epoch [28/40], Step[370/483], loss: 0.7692
 Epoch [28/40], Step[380/483], loss: 1.0458
 Epoch [28/40], Step[390/483], loss: 1.1329
 Epoch [28/40], Step[400/483], loss: 1.1146
 Epoch [28/40], Step[410/483], loss: 0.8577
 Epoch [28/40], Step[420/483], loss: 1.0324
 Epoch [28/40], Step[430/483], loss: 1.0651
 Epoch [28/40], Step[440/483], loss: 1.1290
 Epoch [28/40], Step[450/483], loss: 0.9291
 Epoch [28/40], Step[460/483], loss: 1.2328
 Epoch [28/40], Step[470/483], loss: 1.3168
 Epoch [28/40], Step[480/483], loss: 0.7385
 ====> Epoch 28: Training loss: 541.4522
 ====> Epoch 28: Validation loss: 68.2485
 Epoch [29/40], Step[0/483], loss: 0.9552
 Epoch [29/40], Step[10/483], loss: 1.0842
 Epoch [29/40], Step[20/483], loss: 1.1820
 Epoch [29/40], Step[30/483], loss: 1.1205
 Epoch [29/40], Step[40/483], loss: 1.1768
 Epoch [29/40], Step[50/483], loss: 1.2451
 Epoch [29/40], Step[60/483], loss: 1.3819
 Epoch [29/40], Step[70/483], loss: 1.1950
 Epoch [29/40], Step[80/483], loss: 1.3846
 Epoch [29/40], Step[90/483], loss: 0.9678
 Epoch [29/40], Step[100/483], loss: 0.9804
 Epoch [29/40], Step[110/483], loss: 1.1093
 Epoch [29/40], Step[120/483], loss: 1.2677
 Epoch [29/40], Step[130/483], loss: 1.0487
 Epoch [29/40], Step[140/483], loss: 1.1824
 Epoch [29/40], Step[150/483], loss: 1.2650
 Epoch [29/40], Step[160/483], loss: 1.3090
 Epoch [29/40], Step[170/483], loss: 0.8730
 Epoch [29/40], Step[180/483], loss: 1.2556
 Epoch [29/40], Step[190/483], loss: 1.2618
 Epoch [29/40], Step[200/483], loss: 0.9001
 Epoch [29/40], Step[210/483], loss: 1.1387
 Epoch [29/40], Step[220/483], loss: 1.0151
 Epoch [29/40], Step[230/483], loss: 0.9112
 Epoch [29/40], Step[240/483], loss: 1.1687
 Epoch [29/40], Step[250/483], loss: 1.1978
 Epoch [29/40], Step[260/483], loss: 0.7449
 Epoch [29/40], Step[270/483], loss: 1.1551
 Epoch [29/40], Step[280/483], loss: 0.9699
 Epoch [29/40], Step[290/483], loss: 0.8055
 Epoch [29/40], Step[300/483], loss: 1.1686
 Epoch [29/40], Step[310/483], loss: 1.1443
 Epoch [29/40], Step[320/483], loss: 1.2577
 Epoch [29/40], Step[330/483], loss: 1.1187
 Epoch [29/40], Step[340/483], loss: 1.1880
 Epoch [29/40], Step[350/483], loss: 1.1358
 Epoch [29/40], Step[360/483], loss: 0.8781
 Epoch [29/40], Step[370/483], loss: 0.7434
 Epoch [29/40], Step[380/483], loss: 1.0360
 Epoch [29/40], Step[390/483], loss: 1.1286
 Epoch [29/40], Step[400/483], loss: 1.0931
 Epoch [29/40], Step[410/483], loss: 0.8960
 Epoch [29/40], Step[420/483], loss: 1.0362
 Epoch [29/40], Step[430/483], loss: 1.0319
 Epoch [29/40], Step[440/483], loss: 1.1492
 Epoch [29/40], Step[450/483], loss: 0.9081
 Epoch [29/40], Step[460/483], loss: 1.2171
 Epoch [29/40], Step[470/483], loss: 1.3308
 Epoch [29/40], Step[480/483], loss: 0.7407
 ====> Epoch 29: Training loss: 541.0050
 ====> Epoch 29: Validation loss: 68.1477
 Epoch [30/40], Step[0/483], loss: 0.9307
 Epoch [30/40], Step[10/483], loss: 1.1163
 Epoch [30/40], Step[20/483], loss: 1.1803
 Epoch [30/40], Step[30/483], loss: 1.1180
 Epoch [30/40], Step[40/483], loss: 1.1519
 Epoch [30/40], Step[50/483], loss: 1.2421
 Epoch [30/40], Step[60/483], loss: 1.3476
 Epoch [30/40], Step[70/483], loss: 1.2235
 Epoch [30/40], Step[80/483], loss: 1.3870
 Epoch [30/40], Step[90/483], loss: 0.9619
 Epoch [30/40], Step[100/483], loss: 0.9685
 Epoch [30/40], Step[110/483], loss: 1.1444
 Epoch [30/40], Step[120/483], loss: 1.2348
 Epoch [30/40], Step[130/483], loss: 1.0448
 Epoch [30/40], Step[140/483], loss: 1.1907
 Epoch [30/40], Step[150/483], loss: 1.2239
 Epoch [30/40], Step[160/483], loss: 1.3491
 Epoch [30/40], Step[170/483], loss: 0.8934
 Epoch [30/40], Step[180/483], loss: 1.2749
 Epoch [30/40], Step[190/483], loss: 1.2618
 Epoch [30/40], Step[200/483], loss: 0.8893
 Epoch [30/40], Step[210/483], loss: 1.1426
 Epoch [30/40], Step[220/483], loss: 0.9932
 Epoch [30/40], Step[230/483], loss: 0.9006
 Epoch [30/40], Step[240/483], loss: 1.1641
 Epoch [30/40], Step[250/483], loss: 1.2176
 Epoch [30/40], Step[260/483], loss: 0.7363
 Epoch [30/40], Step[270/483], loss: 1.1554
 Epoch [30/40], Step[280/483], loss: 0.9583
 Epoch [30/40], Step[290/483], loss: 0.8085
 Epoch [30/40], Step[300/483], loss: 1.1922
 Epoch [30/40], Step[310/483], loss: 1.1325
 Epoch [30/40], Step[320/483], loss: 1.2260
 Epoch [30/40], Step[330/483], loss: 1.1375
 Epoch [30/40], Step[340/483], loss: 1.1929
 Epoch [30/40], Step[350/483], loss: 1.1536
 Epoch [30/40], Step[360/483], loss: 0.8911
 Epoch [30/40], Step[370/483], loss: 0.7479
 Epoch [30/40], Step[380/483], loss: 1.0174
 Epoch [30/40], Step[390/483], loss: 1.1348
 Epoch [30/40], Step[400/483], loss: 1.1174
 Epoch [30/40], Step[410/483], loss: 0.8819
 Epoch [30/40], Step[420/483], loss: 1.0452
 Epoch [30/40], Step[430/483], loss: 1.0327
 Epoch [30/40], Step[440/483], loss: 1.1133
 Epoch [30/40], Step[450/483], loss: 0.9042
 Epoch [30/40], Step[460/483], loss: 1.2174
 Epoch [30/40], Step[470/483], loss: 1.3126
 Epoch [30/40], Step[480/483], loss: 0.7348
 ====> Epoch 30: Training loss: 541.0280
 ====> Epoch 30: Validation loss: 68.0358
 Epoch [31/40], Step[0/483], loss: 0.9542
 Epoch [31/40], Step[10/483], loss: 1.1124
 Epoch [31/40], Step[20/483], loss: 1.1845
 Epoch [31/40], Step[30/483], loss: 1.1312
 Epoch [31/40], Step[40/483], loss: 1.1522
 Epoch [31/40], Step[50/483], loss: 1.2871
 Epoch [31/40], Step[60/483], loss: 1.3451
 Epoch [31/40], Step[70/483], loss: 1.1969
 Epoch [31/40], Step[80/483], loss: 1.3954
 Epoch [31/40], Step[90/483], loss: 0.9389
 Epoch [31/40], Step[100/483], loss: 0.9747
 Epoch [31/40], Step[110/483], loss: 1.1575
 Epoch [31/40], Step[120/483], loss: 1.2596
 Epoch [31/40], Step[130/483], loss: 1.0370
 Epoch [31/40], Step[140/483], loss: 1.1900
 Epoch [31/40], Step[150/483], loss: 1.2576
 Epoch [31/40], Step[160/483], loss: 1.3205
 Epoch [31/40], Step[170/483], loss: 0.8781
 Epoch [31/40], Step[180/483], loss: 1.2578
 Epoch [31/40], Step[190/483], loss: 1.3033
 Epoch [31/40], Step[200/483], loss: 0.9049
 Epoch [31/40], Step[210/483], loss: 1.0836
 Epoch [31/40], Step[220/483], loss: 1.0017
 Epoch [31/40], Step[230/483], loss: 0.9287
 Epoch [31/40], Step[240/483], loss: 1.1205
 Epoch [31/40], Step[250/483], loss: 1.2002
 Epoch [31/40], Step[260/483], loss: 0.7488
 Epoch [31/40], Step[270/483], loss: 1.1567
 Epoch [31/40], Step[280/483], loss: 0.9666
 Epoch [31/40], Step[290/483], loss: 0.8292
 Epoch [31/40], Step[300/483], loss: 1.1596
 Epoch [31/40], Step[310/483], loss: 1.1479
 Epoch [31/40], Step[320/483], loss: 1.2517
 Epoch [31/40], Step[330/483], loss: 1.1208
 Epoch [31/40], Step[340/483], loss: 1.1733
 Epoch [31/40], Step[350/483], loss: 1.1262
 Epoch [31/40], Step[360/483], loss: 0.8896
 Epoch [31/40], Step[370/483], loss: 0.7574
 Epoch [31/40], Step[380/483], loss: 1.0221
 Epoch [31/40], Step[390/483], loss: 1.1183
 Epoch [31/40], Step[400/483], loss: 1.1226
 Epoch [31/40], Step[410/483], loss: 0.8761
 Epoch [31/40], Step[420/483], loss: 1.0751
 Epoch [31/40], Step[430/483], loss: 1.0538
 Epoch [31/40], Step[440/483], loss: 1.1238
 Epoch [31/40], Step[450/483], loss: 0.9003
 Epoch [31/40], Step[460/483], loss: 1.1833
 Epoch [31/40], Step[470/483], loss: 1.3281
 Epoch [31/40], Step[480/483], loss: 0.7281
 ====> Epoch 31: Training loss: 540.4101
 ====> Epoch 31: Validation loss: 68.1655
 Epoch [32/40], Step[0/483], loss: 0.9448
 Epoch [32/40], Step[10/483], loss: 1.0825
 Epoch [32/40], Step[20/483], loss: 1.1907
 Epoch [32/40], Step[30/483], loss: 1.1216
 Epoch [32/40], Step[40/483], loss: 1.1601
 Epoch [32/40], Step[50/483], loss: 1.2622
 Epoch [32/40], Step[60/483], loss: 1.3396
 Epoch [32/40], Step[70/483], loss: 1.2013
 Epoch [32/40], Step[80/483], loss: 1.4136
 Epoch [32/40], Step[90/483], loss: 0.9602
 Epoch [32/40], Step[100/483], loss: 0.9932
 Epoch [32/40], Step[110/483], loss: 1.1570
 Epoch [32/40], Step[120/483], loss: 1.2572
 Epoch [32/40], Step[130/483], loss: 1.0401
 Epoch [32/40], Step[140/483], loss: 1.1867
 Epoch [32/40], Step[150/483], loss: 1.2470
 Epoch [32/40], Step[160/483], loss: 1.3458
 Epoch [32/40], Step[170/483], loss: 0.9079
 Epoch [32/40], Step[180/483], loss: 1.2189
 Epoch [32/40], Step[190/483], loss: 1.2362
 Epoch [32/40], Step[200/483], loss: 0.9151
 Epoch [32/40], Step[210/483], loss: 1.1286
 Epoch [32/40], Step[220/483], loss: 1.0170
 Epoch [32/40], Step[230/483], loss: 0.9051
 Epoch [32/40], Step[240/483], loss: 1.1404
 Epoch [32/40], Step[250/483], loss: 1.2157
 Epoch [32/40], Step[260/483], loss: 0.7568
 Epoch [32/40], Step[270/483], loss: 1.1525
 Epoch [32/40], Step[280/483], loss: 0.9806
 Epoch [32/40], Step[290/483], loss: 0.8307
 Epoch [32/40], Step[300/483], loss: 1.1548
 Epoch [32/40], Step[310/483], loss: 1.1510
 Epoch [32/40], Step[320/483], loss: 1.2636
 Epoch [32/40], Step[330/483], loss: 1.1386
 Epoch [32/40], Step[340/483], loss: 1.1851
 Epoch [32/40], Step[350/483], loss: 1.1359
 Epoch [32/40], Step[360/483], loss: 0.8744
 Epoch [32/40], Step[370/483], loss: 0.7537
 Epoch [32/40], Step[380/483], loss: 1.0396
 Epoch [32/40], Step[390/483], loss: 1.1232
 Epoch [32/40], Step[400/483], loss: 1.0837
 Epoch [32/40], Step[410/483], loss: 0.8733
 Epoch [32/40], Step[420/483], loss: 1.0513
 Epoch [32/40], Step[430/483], loss: 1.0528
 Epoch [32/40], Step[440/483], loss: 1.1277
 Epoch [32/40], Step[450/483], loss: 0.9176
 Epoch [32/40], Step[460/483], loss: 1.1979
 Epoch [32/40], Step[470/483], loss: 1.3651
 Epoch [32/40], Step[480/483], loss: 0.7328
 ====> Epoch 32: Training loss: 540.4881
 ====> Epoch 32: Validation loss: 68.0433
 Epoch [33/40], Step[0/483], loss: 0.9320
 Epoch [33/40], Step[10/483], loss: 1.0722
 Epoch [33/40], Step[20/483], loss: 1.1858
 Epoch [33/40], Step[30/483], loss: 1.1290
 Epoch [33/40], Step[40/483], loss: 1.1761
 Epoch [33/40], Step[50/483], loss: 1.2543
 Epoch [33/40], Step[60/483], loss: 1.3427
 Epoch [33/40], Step[70/483], loss: 1.2087
 Epoch [33/40], Step[80/483], loss: 1.3904
 Epoch [33/40], Step[90/483], loss: 0.9598
 Epoch [33/40], Step[100/483], loss: 0.9748
 Epoch [33/40], Step[110/483], loss: 1.1357
 Epoch [33/40], Step[120/483], loss: 1.2534
 Epoch [33/40], Step[130/483], loss: 1.0136
 Epoch [33/40], Step[140/483], loss: 1.1967
 Epoch [33/40], Step[150/483], loss: 1.2297
 Epoch [33/40], Step[160/483], loss: 1.3579
 Epoch [33/40], Step[170/483], loss: 0.8819
 Epoch [33/40], Step[180/483], loss: 1.2688
 Epoch [33/40], Step[190/483], loss: 1.2626
 Epoch [33/40], Step[200/483], loss: 0.8809
 Epoch [33/40], Step[210/483], loss: 1.1418
 Epoch [33/40], Step[220/483], loss: 0.9751
 Epoch [33/40], Step[230/483], loss: 0.8937
 Epoch [33/40], Step[240/483], loss: 1.1599
 Epoch [33/40], Step[250/483], loss: 1.1961
 Epoch [33/40], Step[260/483], loss: 0.7624
 Epoch [33/40], Step[270/483], loss: 1.1368
 Epoch [33/40], Step[280/483], loss: 0.9517
 Epoch [33/40], Step[290/483], loss: 0.7921
 Epoch [33/40], Step[300/483], loss: 1.1668
 Epoch [33/40], Step[310/483], loss: 1.1246
 Epoch [33/40], Step[320/483], loss: 1.2465
 Epoch [33/40], Step[330/483], loss: 1.1339
 Epoch [33/40], Step[340/483], loss: 1.1699
 Epoch [33/40], Step[350/483], loss: 1.1494
 Epoch [33/40], Step[360/483], loss: 0.8786
 Epoch [33/40], Step[370/483], loss: 0.7535
 Epoch [33/40], Step[380/483], loss: 1.0343
 Epoch [33/40], Step[390/483], loss: 1.1341
 Epoch [33/40], Step[400/483], loss: 1.1054
 Epoch [33/40], Step[410/483], loss: 0.8746
 Epoch [33/40], Step[420/483], loss: 1.0247
 Epoch [33/40], Step[430/483], loss: 1.0227
 Epoch [33/40], Step[440/483], loss: 1.1217
 Epoch [33/40], Step[450/483], loss: 0.9048
 Epoch [33/40], Step[460/483], loss: 1.1960
 Epoch [33/40], Step[470/483], loss: 1.3035
 Epoch [33/40], Step[480/483], loss: 0.7375
 ====> Epoch 33: Training loss: 539.9706
 ====> Epoch 33: Validation loss: 68.2315
 Epoch [34/40], Step[0/483], loss: 0.9648
 Epoch [34/40], Step[10/483], loss: 1.0992
 Epoch [34/40], Step[20/483], loss: 1.1796
 Epoch [34/40], Step[30/483], loss: 1.1261
 Epoch [34/40], Step[40/483], loss: 1.1769
 Epoch [34/40], Step[50/483], loss: 1.2763
 Epoch [34/40], Step[60/483], loss: 1.3382
 Epoch [34/40], Step[70/483], loss: 1.1683
 Epoch [34/40], Step[80/483], loss: 1.4166
 Epoch [34/40], Step[90/483], loss: 0.9644
 Epoch [34/40], Step[100/483], loss: 0.9784
 Epoch [34/40], Step[110/483], loss: 1.1543
 Epoch [34/40], Step[120/483], loss: 1.2360
 Epoch [34/40], Step[130/483], loss: 1.0413
 Epoch [34/40], Step[140/483], loss: 1.1816
 Epoch [34/40], Step[150/483], loss: 1.2253
 Epoch [34/40], Step[160/483], loss: 1.3176
 Epoch [34/40], Step[170/483], loss: 0.8969
 Epoch [34/40], Step[180/483], loss: 1.2500
 Epoch [34/40], Step[190/483], loss: 1.2594
 Epoch [34/40], Step[200/483], loss: 0.8915
 Epoch [34/40], Step[210/483], loss: 1.1329
 Epoch [34/40], Step[220/483], loss: 0.9928
 Epoch [34/40], Step[230/483], loss: 0.8835
 Epoch [34/40], Step[240/483], loss: 1.1513
 Epoch [34/40], Step[250/483], loss: 1.1780
 Epoch [34/40], Step[260/483], loss: 0.7579
 Epoch [34/40], Step[270/483], loss: 1.1545
 Epoch [34/40], Step[280/483], loss: 0.9654
 Epoch [34/40], Step[290/483], loss: 0.8127
 Epoch [34/40], Step[300/483], loss: 1.1649
 Epoch [34/40], Step[310/483], loss: 1.1341
 Epoch [34/40], Step[320/483], loss: 1.2198
 Epoch [34/40], Step[330/483], loss: 1.1300
 Epoch [34/40], Step[340/483], loss: 1.1960
 Epoch [34/40], Step[350/483], loss: 1.1242
 Epoch [34/40], Step[360/483], loss: 0.8809
 Epoch [34/40], Step[370/483], loss: 0.7515
 Epoch [34/40], Step[380/483], loss: 1.0105
 Epoch [34/40], Step[390/483], loss: 1.1432
 Epoch [34/40], Step[400/483], loss: 1.1207
 Epoch [34/40], Step[410/483], loss: 0.8738
 Epoch [34/40], Step[420/483], loss: 1.0558
 Epoch [34/40], Step[430/483], loss: 1.0371
 Epoch [34/40], Step[440/483], loss: 1.1155
 Epoch [34/40], Step[450/483], loss: 0.9101
 Epoch [34/40], Step[460/483], loss: 1.2545
 Epoch [34/40], Step[470/483], loss: 1.3403
 Epoch [34/40], Step[480/483], loss: 0.7233
 ====> Epoch 34: Training loss: 539.6388
 ====> Epoch 34: Validation loss: 68.0926
 Epoch [35/40], Step[0/483], loss: 0.9766
 Epoch [35/40], Step[10/483], loss: 1.1128
 Epoch [35/40], Step[20/483], loss: 1.2022
 Epoch [35/40], Step[30/483], loss: 1.1121
 Epoch [35/40], Step[40/483], loss: 1.1609
 Epoch [35/40], Step[50/483], loss: 1.2662
 Epoch [35/40], Step[60/483], loss: 1.3408
 Epoch [35/40], Step[70/483], loss: 1.2034
 Epoch [35/40], Step[80/483], loss: 1.4005
 Epoch [35/40], Step[90/483], loss: 0.9457
 Epoch [35/40], Step[100/483], loss: 0.9551
 Epoch [35/40], Step[110/483], loss: 1.1696
 Epoch [35/40], Step[120/483], loss: 1.2073
 Epoch [35/40], Step[130/483], loss: 1.0266
 Epoch [35/40], Step[140/483], loss: 1.1947
 Epoch [35/40], Step[150/483], loss: 1.2171
 Epoch [35/40], Step[160/483], loss: 1.3192
 Epoch [35/40], Step[170/483], loss: 0.8981
 Epoch [35/40], Step[180/483], loss: 1.2635
 Epoch [35/40], Step[190/483], loss: 1.2678
 Epoch [35/40], Step[200/483], loss: 0.8798
 Epoch [35/40], Step[210/483], loss: 1.1165
 Epoch [35/40], Step[220/483], loss: 1.0057
 Epoch [35/40], Step[230/483], loss: 0.8904
 Epoch [35/40], Step[240/483], loss: 1.1683
 Epoch [35/40], Step[250/483], loss: 1.1835
 Epoch [35/40], Step[260/483], loss: 0.7558
 Epoch [35/40], Step[270/483], loss: 1.1071
 Epoch [35/40], Step[280/483], loss: 0.9720
 Epoch [35/40], Step[290/483], loss: 0.7944
 Epoch [35/40], Step[300/483], loss: 1.1526
 Epoch [35/40], Step[310/483], loss: 1.1538
 Epoch [35/40], Step[320/483], loss: 1.2387
 Epoch [35/40], Step[330/483], loss: 1.1328
 Epoch [35/40], Step[340/483], loss: 1.1878
 Epoch [35/40], Step[350/483], loss: 1.1322
 Epoch [35/40], Step[360/483], loss: 0.8912
 Epoch [35/40], Step[370/483], loss: 0.7754
 Epoch [35/40], Step[380/483], loss: 1.0240
 Epoch [35/40], Step[390/483], loss: 1.1388
 Epoch [35/40], Step[400/483], loss: 1.1092
 Epoch [35/40], Step[410/483], loss: 0.8868
 Epoch [35/40], Step[420/483], loss: 1.0530
 Epoch [35/40], Step[430/483], loss: 1.0576
 Epoch [35/40], Step[440/483], loss: 1.1299
 Epoch [35/40], Step[450/483], loss: 0.9030
 Epoch [35/40], Step[460/483], loss: 1.2225
 Epoch [35/40], Step[470/483], loss: 1.3538
 Epoch [35/40], Step[480/483], loss: 0.7406
 ====> Epoch 35: Training loss: 540.0747
 ====> Epoch 35: Validation loss: 68.1083
 Epoch [36/40], Step[0/483], loss: 0.9572
 Epoch [36/40], Step[10/483], loss: 1.1127
 Epoch [36/40], Step[20/483], loss: 1.1969
 Epoch [36/40], Step[30/483], loss: 1.1181
 Epoch [36/40], Step[40/483], loss: 1.1483
 Epoch [36/40], Step[50/483], loss: 1.2666
 Epoch [36/40], Step[60/483], loss: 1.3369
 Epoch [36/40], Step[70/483], loss: 1.1929
 Epoch [36/40], Step[80/483], loss: 1.3726
 Epoch [36/40], Step[90/483], loss: 0.9731
 Epoch [36/40], Step[100/483], loss: 0.9583
 Epoch [36/40], Step[110/483], loss: 1.1637
 Epoch [36/40], Step[120/483], loss: 1.2465
 Epoch [36/40], Step[130/483], loss: 1.0405
 Epoch [36/40], Step[140/483], loss: 1.1952
 Epoch [36/40], Step[150/483], loss: 1.2396
 Epoch [36/40], Step[160/483], loss: 1.3150
 Epoch [36/40], Step[170/483], loss: 0.8804
 Epoch [36/40], Step[180/483], loss: 1.2305
 Epoch [36/40], Step[190/483], loss: 1.2947
 Epoch [36/40], Step[200/483], loss: 0.8963
 Epoch [36/40], Step[210/483], loss: 1.1231
 Epoch [36/40], Step[220/483], loss: 1.0014
 Epoch [36/40], Step[230/483], loss: 0.8962
 Epoch [36/40], Step[240/483], loss: 1.1561
 Epoch [36/40], Step[250/483], loss: 1.1962
 Epoch [36/40], Step[260/483], loss: 0.7544
 Epoch [36/40], Step[270/483], loss: 1.1757
 Epoch [36/40], Step[280/483], loss: 0.9601
 Epoch [36/40], Step[290/483], loss: 0.8028
 Epoch [36/40], Step[300/483], loss: 1.1676
 Epoch [36/40], Step[310/483], loss: 1.1499
 Epoch [36/40], Step[320/483], loss: 1.2367
 Epoch [36/40], Step[330/483], loss: 1.1137
 Epoch [36/40], Step[340/483], loss: 1.1678
 Epoch [36/40], Step[350/483], loss: 1.1693
 Epoch [36/40], Step[360/483], loss: 0.8898
 Epoch [36/40], Step[370/483], loss: 0.7633
 Epoch [36/40], Step[380/483], loss: 1.0456
 Epoch [36/40], Step[390/483], loss: 1.1091
 Epoch [36/40], Step[400/483], loss: 1.1150
 Epoch [36/40], Step[410/483], loss: 0.8796
 Epoch [36/40], Step[420/483], loss: 1.0440
 Epoch [36/40], Step[430/483], loss: 1.0424
 Epoch [36/40], Step[440/483], loss: 1.1127
 Epoch [36/40], Step[450/483], loss: 0.8949
 Epoch [36/40], Step[460/483], loss: 1.2198
 Epoch [36/40], Step[470/483], loss: 1.3126
 Epoch [36/40], Step[480/483], loss: 0.7439
 ====> Epoch 36: Training loss: 539.8898
 ====> Epoch 36: Validation loss: 67.9897
 Epoch [37/40], Step[0/483], loss: 0.9421
 Epoch [37/40], Step[10/483], loss: 1.0810
 Epoch [37/40], Step[20/483], loss: 1.1795
 Epoch [37/40], Step[30/483], loss: 1.1203
 Epoch [37/40], Step[40/483], loss: 1.1526
 Epoch [37/40], Step[50/483], loss: 1.2361
 Epoch [37/40], Step[60/483], loss: 1.3723
 Epoch [37/40], Step[70/483], loss: 1.1893
 Epoch [37/40], Step[80/483], loss: 1.4027
 Epoch [37/40], Step[90/483], loss: 0.9350
 Epoch [37/40], Step[100/483], loss: 0.9794
 Epoch [37/40], Step[110/483], loss: 1.1412
 Epoch [37/40], Step[120/483], loss: 1.2333
 Epoch [37/40], Step[130/483], loss: 1.0493
 Epoch [37/40], Step[140/483], loss: 1.2190
 Epoch [37/40], Step[150/483], loss: 1.2177
 Epoch [37/40], Step[160/483], loss: 1.2832
 Epoch [37/40], Step[170/483], loss: 0.8815
 Epoch [37/40], Step[180/483], loss: 1.2584
 Epoch [37/40], Step[190/483], loss: 1.2669
 Epoch [37/40], Step[200/483], loss: 0.8890
 Epoch [37/40], Step[210/483], loss: 1.1334
 Epoch [37/40], Step[220/483], loss: 0.9824
 Epoch [37/40], Step[230/483], loss: 0.8835
 Epoch [37/40], Step[240/483], loss: 1.1676
 Epoch [37/40], Step[250/483], loss: 1.1867
 Epoch [37/40], Step[260/483], loss: 0.7638
 Epoch [37/40], Step[270/483], loss: 1.1291
 Epoch [37/40], Step[280/483], loss: 0.9540
 Epoch [37/40], Step[290/483], loss: 0.8052
 Epoch [37/40], Step[300/483], loss: 1.1612
 Epoch [37/40], Step[310/483], loss: 1.1065
 Epoch [37/40], Step[320/483], loss: 1.2172
 Epoch [37/40], Step[330/483], loss: 1.0964
 Epoch [37/40], Step[340/483], loss: 1.1692
 Epoch [37/40], Step[350/483], loss: 1.1524
 Epoch [37/40], Step[360/483], loss: 0.8754
 Epoch [37/40], Step[370/483], loss: 0.7441
 Epoch [37/40], Step[380/483], loss: 1.0021
 Epoch [37/40], Step[390/483], loss: 1.1279
 Epoch [37/40], Step[400/483], loss: 1.1080
 Epoch [37/40], Step[410/483], loss: 0.8825
 Epoch [37/40], Step[420/483], loss: 1.0494
 Epoch [37/40], Step[430/483], loss: 1.0470
 Epoch [37/40], Step[440/483], loss: 1.1196
 Epoch [37/40], Step[450/483], loss: 0.9099
 Epoch [37/40], Step[460/483], loss: 1.2087
 Epoch [37/40], Step[470/483], loss: 1.3023
 Epoch [37/40], Step[480/483], loss: 0.7339
 ====> Epoch 37: Training loss: 539.1981
 ====> Epoch 37: Validation loss: 68.1817
 Epoch [38/40], Step[0/483], loss: 0.9640
 Epoch [38/40], Step[10/483], loss: 1.1218
 Epoch [38/40], Step[20/483], loss: 1.1959
 Epoch [38/40], Step[30/483], loss: 1.1153
 Epoch [38/40], Step[40/483], loss: 1.1683
 Epoch [38/40], Step[50/483], loss: 1.2524
 Epoch [38/40], Step[60/483], loss: 1.3455
 Epoch [38/40], Step[70/483], loss: 1.2084
 Epoch [38/40], Step[80/483], loss: 1.3845
 Epoch [38/40], Step[90/483], loss: 0.9463
 Epoch [38/40], Step[100/483], loss: 0.9843
 Epoch [38/40], Step[110/483], loss: 1.1616
 Epoch [38/40], Step[120/483], loss: 1.2120
 Epoch [38/40], Step[130/483], loss: 1.0453
 Epoch [38/40], Step[140/483], loss: 1.1825
 Epoch [38/40], Step[150/483], loss: 1.2319
 Epoch [38/40], Step[160/483], loss: 1.3376
 Epoch [38/40], Step[170/483], loss: 0.8984
 Epoch [38/40], Step[180/483], loss: 1.2703
 Epoch [38/40], Step[190/483], loss: 1.2718
 Epoch [38/40], Step[200/483], loss: 0.8982
 Epoch [38/40], Step[210/483], loss: 1.1257
 Epoch [38/40], Step[220/483], loss: 1.0194
 Epoch [38/40], Step[230/483], loss: 0.8872
 Epoch [38/40], Step[240/483], loss: 1.1438
 Epoch [38/40], Step[250/483], loss: 1.2083
 Epoch [38/40], Step[260/483], loss: 0.7472
 Epoch [38/40], Step[270/483], loss: 1.1180
 Epoch [38/40], Step[280/483], loss: 0.9607
 Epoch [38/40], Step[290/483], loss: 0.8055
 Epoch [38/40], Step[300/483], loss: 1.1621
 Epoch [38/40], Step[310/483], loss: 1.1262
 Epoch [38/40], Step[320/483], loss: 1.2476
 Epoch [38/40], Step[330/483], loss: 1.1180
 Epoch [38/40], Step[340/483], loss: 1.1817
 Epoch [38/40], Step[350/483], loss: 1.1483
 Epoch [38/40], Step[360/483], loss: 0.8665
 Epoch [38/40], Step[370/483], loss: 0.7631
 Epoch [38/40], Step[380/483], loss: 1.0399
 Epoch [38/40], Step[390/483], loss: 1.1445
 Epoch [38/40], Step[400/483], loss: 1.0788
 Epoch [38/40], Step[410/483], loss: 0.8832
 Epoch [38/40], Step[420/483], loss: 1.0350
 Epoch [38/40], Step[430/483], loss: 1.0453
 Epoch [38/40], Step[440/483], loss: 1.1029
 Epoch [38/40], Step[450/483], loss: 0.9127
 Epoch [38/40], Step[460/483], loss: 1.2382
 Epoch [38/40], Step[470/483], loss: 1.3399
 Epoch [38/40], Step[480/483], loss: 0.7552
 ====> Epoch 38: Training loss: 538.9404
 ====> Epoch 38: Validation loss: 67.9944
 Epoch [39/40], Step[0/483], loss: 0.9773
 Epoch [39/40], Step[10/483], loss: 1.0921
 Epoch [39/40], Step[20/483], loss: 1.1777
 Epoch [39/40], Step[30/483], loss: 1.1124
 Epoch [39/40], Step[40/483], loss: 1.1639
 Epoch [39/40], Step[50/483], loss: 1.2843
 Epoch [39/40], Step[60/483], loss: 1.3326
 Epoch [39/40], Step[70/483], loss: 1.2153
 Epoch [39/40], Step[80/483], loss: 1.4119
 Epoch [39/40], Step[90/483], loss: 0.9516
 Epoch [39/40], Step[100/483], loss: 0.9647
 Epoch [39/40], Step[110/483], loss: 1.1406
 Epoch [39/40], Step[120/483], loss: 1.2388
 Epoch [39/40], Step[130/483], loss: 1.0396
 Epoch [39/40], Step[140/483], loss: 1.1840
 Epoch [39/40], Step[150/483], loss: 1.2313
 Epoch [39/40], Step[160/483], loss: 1.3118
 Epoch [39/40], Step[170/483], loss: 0.8921
 Epoch [39/40], Step[180/483], loss: 1.2581
 Epoch [39/40], Step[190/483], loss: 1.2317
 Epoch [39/40], Step[200/483], loss: 0.8873
 Epoch [39/40], Step[210/483], loss: 1.0982
 Epoch [39/40], Step[220/483], loss: 1.0247
 Epoch [39/40], Step[230/483], loss: 0.8913
 Epoch [39/40], Step[240/483], loss: 1.1335
 Epoch [39/40], Step[250/483], loss: 1.2094
 Epoch [39/40], Step[260/483], loss: 0.7409
 Epoch [39/40], Step[270/483], loss: 1.1585
 Epoch [39/40], Step[280/483], loss: 0.9822
 Epoch [39/40], Step[290/483], loss: 0.8003
 Epoch [39/40], Step[300/483], loss: 1.1671
 Epoch [39/40], Step[310/483], loss: 1.1438
 Epoch [39/40], Step[320/483], loss: 1.2251
 Epoch [39/40], Step[330/483], loss: 1.1331
 Epoch [39/40], Step[340/483], loss: 1.1805
 Epoch [39/40], Step[350/483], loss: 1.1307
 Epoch [39/40], Step[360/483], loss: 0.8812
 Epoch [39/40], Step[370/483], loss: 0.7553
 Epoch [39/40], Step[380/483], loss: 1.0119
 Epoch [39/40], Step[390/483], loss: 1.1222
 Epoch [39/40], Step[400/483], loss: 1.0819
 Epoch [39/40], Step[410/483], loss: 0.8629
 Epoch [39/40], Step[420/483], loss: 1.0251
 Epoch [39/40], Step[430/483], loss: 1.0584
 Epoch [39/40], Step[440/483], loss: 1.1379
 Epoch [39/40], Step[450/483], loss: 0.9218
 Epoch [39/40], Step[460/483], loss: 1.2207
 Epoch [39/40], Step[470/483], loss: 1.3394
 Epoch [39/40], Step[480/483], loss: 0.7451
 ====> Epoch 39: Training loss: 538.7274
 ====> Epoch 39: Validation loss: 67.8778
 Epoch [40/40], Step[0/483], loss: 0.9711
 Epoch [40/40], Step[10/483], loss: 1.1071
 Epoch [40/40], Step[20/483], loss: 1.2041
 Epoch [40/40], Step[30/483], loss: 1.1127
 Epoch [40/40], Step[40/483], loss: 1.1583
 Epoch [40/40], Step[50/483], loss: 1.2568
 Epoch [40/40], Step[60/483], loss: 1.3555
 Epoch [40/40], Step[70/483], loss: 1.2284
 Epoch [40/40], Step[80/483], loss: 1.4078
 Epoch [40/40], Step[90/483], loss: 0.9628
 Epoch [40/40], Step[100/483], loss: 0.9724
 Epoch [40/40], Step[110/483], loss: 1.1842
 Epoch [40/40], Step[120/483], loss: 1.2720
