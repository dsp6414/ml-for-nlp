 Loading feature files...
 <s> = 1
 </s> = 2
 All scenes loaded.
 Hyperparameters:Namespace(LR=0.01, alternatives=1, batch_size=100, dec='LSTM', dropout=0.0, epochs=20, hidden_sz=200, load=None, log_interval=10, model='s0', no_cuda=False, save=None, seed=1)
 Speaker0: Speaker0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=200)
  )
  (string_decoder): LSTMStringDecoder(
    (embedding): Embedding(1063, 200)
    (lstm): LSTM(200, 200, num_layers=2, batch_first=True)
    (linear): Linear(in_features=200, out_features=1063)
    (dropout): Dropout(p=0.0)
  )
)
 Training Speaker0...
 Epoch [1/20], Step[0/483], loss: 6.9029
 Epoch [1/20], Step[10/483], loss: 2.0363
 Epoch [1/20], Step[20/483], loss: 1.9628
 Epoch [1/20], Step[30/483], loss: 1.6426
 Epoch [1/20], Step[40/483], loss: 1.6397
 Epoch [1/20], Step[50/483], loss: 1.6471
 Epoch [1/20], Step[60/483], loss: 1.6950
 Epoch [1/20], Step[70/483], loss: 1.4124
 Epoch [1/20], Step[80/483], loss: 1.6254
 Epoch [1/20], Step[90/483], loss: 1.1042
 Epoch [1/20], Step[100/483], loss: 1.0770
 Epoch [1/20], Step[110/483], loss: 1.2715
 Epoch [1/20], Step[120/483], loss: 1.3167
 Epoch [1/20], Step[130/483], loss: 1.0891
 Epoch [1/20], Step[140/483], loss: 1.2601
 Epoch [1/20], Step[150/483], loss: 1.3121
 Epoch [1/20], Step[160/483], loss: 1.4362
 Epoch [1/20], Step[170/483], loss: 0.9383
 Epoch [1/20], Step[180/483], loss: 1.2819
 Epoch [1/20], Step[190/483], loss: 1.2501
 Epoch [1/20], Step[200/483], loss: 0.8925
 Epoch [1/20], Step[210/483], loss: 1.1346
 Epoch [1/20], Step[220/483], loss: 1.0026
 Epoch [1/20], Step[230/483], loss: 0.8816
 Epoch [1/20], Step[240/483], loss: 1.1363
 Epoch [1/20], Step[250/483], loss: 1.1530
 Epoch [1/20], Step[260/483], loss: 0.7520
 Epoch [1/20], Step[270/483], loss: 1.0989
 Epoch [1/20], Step[280/483], loss: 0.9408
 Epoch [1/20], Step[290/483], loss: 0.8074
 Epoch [1/20], Step[300/483], loss: 1.1380
 Epoch [1/20], Step[310/483], loss: 1.1145
 Epoch [1/20], Step[320/483], loss: 1.1723
 Epoch [1/20], Step[330/483], loss: 1.0647
 Epoch [1/20], Step[340/483], loss: 1.0926
 Epoch [1/20], Step[350/483], loss: 1.0801
 Epoch [1/20], Step[360/483], loss: 0.8196
 Epoch [1/20], Step[370/483], loss: 0.7056
 Epoch [1/20], Step[380/483], loss: 0.9284
 Epoch [1/20], Step[390/483], loss: 1.0605
 Epoch [1/20], Step[400/483], loss: 0.9826
 Epoch [1/20], Step[410/483], loss: 0.7882
 Epoch [1/20], Step[420/483], loss: 0.9877
 Epoch [1/20], Step[430/483], loss: 0.9898
 Epoch [1/20], Step[440/483], loss: 0.9939
 Epoch [1/20], Step[450/483], loss: 0.8292
 Epoch [1/20], Step[460/483], loss: 1.1128
 Epoch [1/20], Step[470/483], loss: 1.1620
 Epoch [1/20], Step[480/483], loss: 0.6649
 ====> Epoch 1: Training loss: 589.1711
 ====> Epoch 1: Validation loss: 60.4017
 Epoch [2/20], Step[0/483], loss: 0.8536
 Epoch [2/20], Step[10/483], loss: 0.9708
 Epoch [2/20], Step[20/483], loss: 1.0608
 Epoch [2/20], Step[30/483], loss: 1.0077
 Epoch [2/20], Step[40/483], loss: 1.0466
 Epoch [2/20], Step[50/483], loss: 1.1128
 Epoch [2/20], Step[60/483], loss: 1.2125
 Epoch [2/20], Step[70/483], loss: 1.0754
 Epoch [2/20], Step[80/483], loss: 1.2308
 Epoch [2/20], Step[90/483], loss: 0.8264
 Epoch [2/20], Step[100/483], loss: 0.8443
 Epoch [2/20], Step[110/483], loss: 1.0273
 Epoch [2/20], Step[120/483], loss: 1.0896
 Epoch [2/20], Step[130/483], loss: 0.9031
 Epoch [2/20], Step[140/483], loss: 1.0374
 Epoch [2/20], Step[150/483], loss: 1.0195
 Epoch [2/20], Step[160/483], loss: 1.1789
 Epoch [2/20], Step[170/483], loss: 0.7821
 Epoch [2/20], Step[180/483], loss: 1.0771
 Epoch [2/20], Step[190/483], loss: 1.0599
 Epoch [2/20], Step[200/483], loss: 0.7622
 Epoch [2/20], Step[210/483], loss: 0.9704
 Epoch [2/20], Step[220/483], loss: 0.8553
 Epoch [2/20], Step[230/483], loss: 0.7598
 Epoch [2/20], Step[240/483], loss: 0.9581
 Epoch [2/20], Step[250/483], loss: 0.9791
 Epoch [2/20], Step[260/483], loss: 0.6329
 Epoch [2/20], Step[270/483], loss: 0.9328
 Epoch [2/20], Step[280/483], loss: 0.8178
 Epoch [2/20], Step[290/483], loss: 0.6763
 Epoch [2/20], Step[300/483], loss: 0.9673
 Epoch [2/20], Step[310/483], loss: 0.9665
 Epoch [2/20], Step[320/483], loss: 1.0256
 Epoch [2/20], Step[330/483], loss: 0.9313
 Epoch [2/20], Step[340/483], loss: 0.9545
 Epoch [2/20], Step[350/483], loss: 0.9175
 Epoch [2/20], Step[360/483], loss: 0.6949
 Epoch [2/20], Step[370/483], loss: 0.6205
 Epoch [2/20], Step[380/483], loss: 0.8285
 Epoch [2/20], Step[390/483], loss: 0.9387
 Epoch [2/20], Step[400/483], loss: 0.8674
 Epoch [2/20], Step[410/483], loss: 0.7056
 Epoch [2/20], Step[420/483], loss: 0.8640
 Epoch [2/20], Step[430/483], loss: 0.8868
 Epoch [2/20], Step[440/483], loss: 0.8596
 Epoch [2/20], Step[450/483], loss: 0.7268
 Epoch [2/20], Step[460/483], loss: 1.0067
 Epoch [2/20], Step[470/483], loss: 1.0251
 Epoch [2/20], Step[480/483], loss: 0.6027
 ====> Epoch 2: Training loss: 456.0157
 ====> Epoch 2: Validation loss: 56.0518
 Epoch [3/20], Step[0/483], loss: 0.7595
 Epoch [3/20], Step[10/483], loss: 0.8529
 Epoch [3/20], Step[20/483], loss: 0.9470
 Epoch [3/20], Step[30/483], loss: 0.9139
 Epoch [3/20], Step[40/483], loss: 0.9333
 Epoch [3/20], Step[50/483], loss: 0.9871
 Epoch [3/20], Step[60/483], loss: 1.0842
 Epoch [3/20], Step[70/483], loss: 0.9693
 Epoch [3/20], Step[80/483], loss: 1.1048
 Epoch [3/20], Step[90/483], loss: 0.7603
 Epoch [3/20], Step[100/483], loss: 0.7791
 Epoch [3/20], Step[110/483], loss: 0.9379
 Epoch [3/20], Step[120/483], loss: 0.9831
 Epoch [3/20], Step[130/483], loss: 0.8277
 Epoch [3/20], Step[140/483], loss: 0.9500
 Epoch [3/20], Step[150/483], loss: 0.9288
 Epoch [3/20], Step[160/483], loss: 1.0678
 Epoch [3/20], Step[170/483], loss: 0.7161
 Epoch [3/20], Step[180/483], loss: 0.9851
 Epoch [3/20], Step[190/483], loss: 0.9892
 Epoch [3/20], Step[200/483], loss: 0.7048
 Epoch [3/20], Step[210/483], loss: 0.8912
 Epoch [3/20], Step[220/483], loss: 0.7889
 Epoch [3/20], Step[230/483], loss: 0.7247
 Epoch [3/20], Step[240/483], loss: 0.8773
 Epoch [3/20], Step[250/483], loss: 0.9260
 Epoch [3/20], Step[260/483], loss: 0.5844
 Epoch [3/20], Step[270/483], loss: 0.8794
 Epoch [3/20], Step[280/483], loss: 0.7738
 Epoch [3/20], Step[290/483], loss: 0.6354
 Epoch [3/20], Step[300/483], loss: 0.9032
 Epoch [3/20], Step[310/483], loss: 0.8942
 Epoch [3/20], Step[320/483], loss: 0.9516
 Epoch [3/20], Step[330/483], loss: 0.8786
 Epoch [3/20], Step[340/483], loss: 0.8650
 Epoch [3/20], Step[350/483], loss: 0.8529
 Epoch [3/20], Step[360/483], loss: 0.6420
 Epoch [3/20], Step[370/483], loss: 0.5730
 Epoch [3/20], Step[380/483], loss: 0.7723
 Epoch [3/20], Step[390/483], loss: 0.8711
 Epoch [3/20], Step[400/483], loss: 0.8105
 Epoch [3/20], Step[410/483], loss: 0.6719
 Epoch [3/20], Step[420/483], loss: 0.8020
 Epoch [3/20], Step[430/483], loss: 0.8389
 Epoch [3/20], Step[440/483], loss: 0.8053
 Epoch [3/20], Step[450/483], loss: 0.6768
 Epoch [3/20], Step[460/483], loss: 0.9230
 Epoch [3/20], Step[470/483], loss: 0.9552
 Epoch [3/20], Step[480/483], loss: 0.5451
 ====> Epoch 3: Training loss: 418.8314
 ====> Epoch 3: Validation loss: 54.7212
 Epoch [4/20], Step[0/483], loss: 0.7204
 Epoch [4/20], Step[10/483], loss: 0.8184
 Epoch [4/20], Step[20/483], loss: 0.8803
 Epoch [4/20], Step[30/483], loss: 0.8309
 Epoch [4/20], Step[40/483], loss: 0.8623
 Epoch [4/20], Step[50/483], loss: 0.9464
 Epoch [4/20], Step[60/483], loss: 1.0195
 Epoch [4/20], Step[70/483], loss: 0.8954
 Epoch [4/20], Step[80/483], loss: 1.0179
 Epoch [4/20], Step[90/483], loss: 0.7159
 Epoch [4/20], Step[100/483], loss: 0.7286
 Epoch [4/20], Step[110/483], loss: 0.8886
 Epoch [4/20], Step[120/483], loss: 0.9386
 Epoch [4/20], Step[130/483], loss: 0.8005
 Epoch [4/20], Step[140/483], loss: 0.8901
 Epoch [4/20], Step[150/483], loss: 0.8792
 Epoch [4/20], Step[160/483], loss: 0.9928
 Epoch [4/20], Step[170/483], loss: 0.6647
 Epoch [4/20], Step[180/483], loss: 0.9249
 Epoch [4/20], Step[190/483], loss: 0.9267
 Epoch [4/20], Step[200/483], loss: 0.6807
 Epoch [4/20], Step[210/483], loss: 0.8212
 Epoch [4/20], Step[220/483], loss: 0.7352
 Epoch [4/20], Step[230/483], loss: 0.6945
 Epoch [4/20], Step[240/483], loss: 0.8432
 Epoch [4/20], Step[250/483], loss: 0.8830
 Epoch [4/20], Step[260/483], loss: 0.5577
 Epoch [4/20], Step[270/483], loss: 0.8443
 Epoch [4/20], Step[280/483], loss: 0.7450
 Epoch [4/20], Step[290/483], loss: 0.6160
 Epoch [4/20], Step[300/483], loss: 0.8493
 Epoch [4/20], Step[310/483], loss: 0.8618
 Epoch [4/20], Step[320/483], loss: 0.9064
 Epoch [4/20], Step[330/483], loss: 0.8556
 Epoch [4/20], Step[340/483], loss: 0.8257
 Epoch [4/20], Step[350/483], loss: 0.7987
 Epoch [4/20], Step[360/483], loss: 0.6192
 Epoch [4/20], Step[370/483], loss: 0.5518
 Epoch [4/20], Step[380/483], loss: 0.7403
 Epoch [4/20], Step[390/483], loss: 0.8319
 Epoch [4/20], Step[400/483], loss: 0.7954
 Epoch [4/20], Step[410/483], loss: 0.6626
 Epoch [4/20], Step[420/483], loss: 0.7847
 Epoch [4/20], Step[430/483], loss: 0.7783
 Epoch [4/20], Step[440/483], loss: 0.7868
 Epoch [4/20], Step[450/483], loss: 0.6459
 Epoch [4/20], Step[460/483], loss: 0.9028
 Epoch [4/20], Step[470/483], loss: 0.9270
 Epoch [4/20], Step[480/483], loss: 0.5445
 ====> Epoch 4: Training loss: 398.3555
 ====> Epoch 4: Validation loss: 54.1786
 Epoch [5/20], Step[0/483], loss: 0.6868
 Epoch [5/20], Step[10/483], loss: 0.8033
 Epoch [5/20], Step[20/483], loss: 0.8435
 Epoch [5/20], Step[30/483], loss: 0.7882
 Epoch [5/20], Step[40/483], loss: 0.8262
 Epoch [5/20], Step[50/483], loss: 0.9019
 Epoch [5/20], Step[60/483], loss: 0.9616
 Epoch [5/20], Step[70/483], loss: 0.8597
 Epoch [5/20], Step[80/483], loss: 1.0112
 Epoch [5/20], Step[90/483], loss: 0.7011
 Epoch [5/20], Step[100/483], loss: 0.7099
 Epoch [5/20], Step[110/483], loss: 0.8489
 Epoch [5/20], Step[120/483], loss: 0.8967
 Epoch [5/20], Step[130/483], loss: 0.7723
 Epoch [5/20], Step[140/483], loss: 0.8726
 Epoch [5/20], Step[150/483], loss: 0.8619
 Epoch [5/20], Step[160/483], loss: 0.9522
 Epoch [5/20], Step[170/483], loss: 0.6666
 Epoch [5/20], Step[180/483], loss: 0.9024
 Epoch [5/20], Step[190/483], loss: 0.9142
 Epoch [5/20], Step[200/483], loss: 0.6630
 Epoch [5/20], Step[210/483], loss: 0.8162
 Epoch [5/20], Step[220/483], loss: 0.7111
 Epoch [5/20], Step[230/483], loss: 0.6782
 Epoch [5/20], Step[240/483], loss: 0.8162
 Epoch [5/20], Step[250/483], loss: 0.8563
 Epoch [5/20], Step[260/483], loss: 0.5471
 Epoch [5/20], Step[270/483], loss: 0.8188
 Epoch [5/20], Step[280/483], loss: 0.7207
 Epoch [5/20], Step[290/483], loss: 0.5992
 Epoch [5/20], Step[300/483], loss: 0.8296
 Epoch [5/20], Step[310/483], loss: 0.8224
 Epoch [5/20], Step[320/483], loss: 0.8730
 Epoch [5/20], Step[330/483], loss: 0.8192
 Epoch [5/20], Step[340/483], loss: 0.8067
 Epoch [5/20], Step[350/483], loss: 0.7665
 Epoch [5/20], Step[360/483], loss: 0.5884
 Epoch [5/20], Step[370/483], loss: 0.5413
 Epoch [5/20], Step[380/483], loss: 0.7387
 Epoch [5/20], Step[390/483], loss: 0.8187
 Epoch [5/20], Step[400/483], loss: 0.7862
 Epoch [5/20], Step[410/483], loss: 0.6322
 Epoch [5/20], Step[420/483], loss: 0.7571
 Epoch [5/20], Step[430/483], loss: 0.7865
 Epoch [5/20], Step[440/483], loss: 0.7720
 Epoch [5/20], Step[450/483], loss: 0.6420
 Epoch [5/20], Step[460/483], loss: 0.8739
 Epoch [5/20], Step[470/483], loss: 0.8970
 Epoch [5/20], Step[480/483], loss: 0.5333
 ====> Epoch 5: Training loss: 386.6705
 ====> Epoch 5: Validation loss: 54.0106
 Epoch [6/20], Step[0/483], loss: 0.6682
 Epoch [6/20], Step[10/483], loss: 0.8101
 Epoch [6/20], Step[20/483], loss: 0.8248
 Epoch [6/20], Step[30/483], loss: 0.7688
 Epoch [6/20], Step[40/483], loss: 0.8218
 Epoch [6/20], Step[50/483], loss: 0.8529
 Epoch [6/20], Step[60/483], loss: 0.9415
 Epoch [6/20], Step[70/483], loss: 0.8593
 Epoch [6/20], Step[80/483], loss: 0.9674
 Epoch [6/20], Step[90/483], loss: 0.6792
 Epoch [6/20], Step[100/483], loss: 0.6983
 Epoch [6/20], Step[110/483], loss: 0.8301
 Epoch [6/20], Step[120/483], loss: 0.8769
 Epoch [6/20], Step[130/483], loss: 0.7506
 Epoch [6/20], Step[140/483], loss: 0.8595
 Epoch [6/20], Step[150/483], loss: 0.8338
 Epoch [6/20], Step[160/483], loss: 0.9459
 Epoch [6/20], Step[170/483], loss: 0.6364
 Epoch [6/20], Step[180/483], loss: 0.8814
 Epoch [6/20], Step[190/483], loss: 0.8930
 Epoch [6/20], Step[200/483], loss: 0.6680
 Epoch [6/20], Step[210/483], loss: 0.7952
 Epoch [6/20], Step[220/483], loss: 0.7051
 Epoch [6/20], Step[230/483], loss: 0.6685
 Epoch [6/20], Step[240/483], loss: 0.7809
 Epoch [6/20], Step[250/483], loss: 0.8382
 Epoch [6/20], Step[260/483], loss: 0.5432
 Epoch [6/20], Step[270/483], loss: 0.7976
 Epoch [6/20], Step[280/483], loss: 0.6972
 Epoch [6/20], Step[290/483], loss: 0.5786
 Epoch [6/20], Step[300/483], loss: 0.8123
 Epoch [6/20], Step[310/483], loss: 0.8187
 Epoch [6/20], Step[320/483], loss: 0.8537
 Epoch [6/20], Step[330/483], loss: 0.8075
 Epoch [6/20], Step[340/483], loss: 0.7912
 Epoch [6/20], Step[350/483], loss: 0.7594
 Epoch [6/20], Step[360/483], loss: 0.5842
 Epoch [6/20], Step[370/483], loss: 0.5406
 Epoch [6/20], Step[380/483], loss: 0.7219
 Epoch [6/20], Step[390/483], loss: 0.7998
 Epoch [6/20], Step[400/483], loss: 0.7691
 Epoch [6/20], Step[410/483], loss: 0.6223
 Epoch [6/20], Step[420/483], loss: 0.7406
 Epoch [6/20], Step[430/483], loss: 0.7608
 Epoch [6/20], Step[440/483], loss: 0.7631
 Epoch [6/20], Step[450/483], loss: 0.6310
 Epoch [6/20], Step[460/483], loss: 0.8498
 Epoch [6/20], Step[470/483], loss: 0.8763
 Epoch [6/20], Step[480/483], loss: 0.5102
 ====> Epoch 6: Training loss: 377.2585
 ====> Epoch 6: Validation loss: 54.4337
 Epoch [7/20], Step[0/483], loss: 0.6665
 Epoch [7/20], Step[10/483], loss: 0.7556
 Epoch [7/20], Step[20/483], loss: 0.8046
 Epoch [7/20], Step[30/483], loss: 0.7596
 Epoch [7/20], Step[40/483], loss: 0.8040
 Epoch [7/20], Step[50/483], loss: 0.8565
 Epoch [7/20], Step[60/483], loss: 0.9246
 Epoch [7/20], Step[70/483], loss: 0.8313
 Epoch [7/20], Step[80/483], loss: 0.9462
 Epoch [7/20], Step[90/483], loss: 0.6651
 Epoch [7/20], Step[100/483], loss: 0.6769
 Epoch [7/20], Step[110/483], loss: 0.8227
 Epoch [7/20], Step[120/483], loss: 0.8593
 Epoch [7/20], Step[130/483], loss: 0.7280
 Epoch [7/20], Step[140/483], loss: 0.8375
 Epoch [7/20], Step[150/483], loss: 0.8074
 Epoch [7/20], Step[160/483], loss: 0.9145
 Epoch [7/20], Step[170/483], loss: 0.6375
 Epoch [7/20], Step[180/483], loss: 0.8563
 Epoch [7/20], Step[190/483], loss: 0.8742
 Epoch [7/20], Step[200/483], loss: 0.6406
 Epoch [7/20], Step[210/483], loss: 0.7868
 Epoch [7/20], Step[220/483], loss: 0.6858
 Epoch [7/20], Step[230/483], loss: 0.6299
 Epoch [7/20], Step[240/483], loss: 0.7725
 Epoch [7/20], Step[250/483], loss: 0.8221
 Epoch [7/20], Step[260/483], loss: 0.5245
 Epoch [7/20], Step[270/483], loss: 0.7961
 Epoch [7/20], Step[280/483], loss: 0.6941
 Epoch [7/20], Step[290/483], loss: 0.5661
 Epoch [7/20], Step[300/483], loss: 0.7865
 Epoch [7/20], Step[310/483], loss: 0.8125
 Epoch [7/20], Step[320/483], loss: 0.8177
 Epoch [7/20], Step[330/483], loss: 0.7977
 Epoch [7/20], Step[340/483], loss: 0.7607
 Epoch [7/20], Step[350/483], loss: 0.7505
 Epoch [7/20], Step[360/483], loss: 0.5952
 Epoch [7/20], Step[370/483], loss: 0.5421
 Epoch [7/20], Step[380/483], loss: 0.6983
 Epoch [7/20], Step[390/483], loss: 0.7893
 Epoch [7/20], Step[400/483], loss: 0.7397
 Epoch [7/20], Step[410/483], loss: 0.6325
 Epoch [7/20], Step[420/483], loss: 0.7199
 Epoch [7/20], Step[430/483], loss: 0.7596
 Epoch [7/20], Step[440/483], loss: 0.7447
 Epoch [7/20], Step[450/483], loss: 0.6119
 Epoch [7/20], Step[460/483], loss: 0.8231
 Epoch [7/20], Step[470/483], loss: 0.8589
 Epoch [7/20], Step[480/483], loss: 0.5190
 ====> Epoch 7: Training loss: 370.7047
 ====> Epoch 7: Validation loss: 54.7306
 Epoch [8/20], Step[0/483], loss: 0.6707
 Epoch [8/20], Step[10/483], loss: 0.7612
 Epoch [8/20], Step[20/483], loss: 0.7942
 Epoch [8/20], Step[30/483], loss: 0.7363
 Epoch [8/20], Step[40/483], loss: 0.8010
 Epoch [8/20], Step[50/483], loss: 0.8475
 Epoch [8/20], Step[60/483], loss: 0.9148
 Epoch [8/20], Step[70/483], loss: 0.8295
 Epoch [8/20], Step[80/483], loss: 0.9347
 Epoch [8/20], Step[90/483], loss: 0.6627
 Epoch [8/20], Step[100/483], loss: 0.6687
 Epoch [8/20], Step[110/483], loss: 0.8120
 Epoch [8/20], Step[120/483], loss: 0.8396
 Epoch [8/20], Step[130/483], loss: 0.7374
 Epoch [8/20], Step[140/483], loss: 0.8391
 Epoch [8/20], Step[150/483], loss: 0.8012
 Epoch [8/20], Step[160/483], loss: 0.8921
 Epoch [8/20], Step[170/483], loss: 0.6397
 Epoch [8/20], Step[180/483], loss: 0.8520
 Epoch [8/20], Step[190/483], loss: 0.8576
 Epoch [8/20], Step[200/483], loss: 0.6347
 Epoch [8/20], Step[210/483], loss: 0.7744
 Epoch [8/20], Step[220/483], loss: 0.6782
 Epoch [8/20], Step[230/483], loss: 0.6315
 Epoch [8/20], Step[240/483], loss: 0.7743
 Epoch [8/20], Step[250/483], loss: 0.8286
 Epoch [8/20], Step[260/483], loss: 0.5360
 Epoch [8/20], Step[270/483], loss: 0.7759
 Epoch [8/20], Step[280/483], loss: 0.6899
 Epoch [8/20], Step[290/483], loss: 0.5687
 Epoch [8/20], Step[300/483], loss: 0.7774
 Epoch [8/20], Step[310/483], loss: 0.8050
 Epoch [8/20], Step[320/483], loss: 0.8115
 Epoch [8/20], Step[330/483], loss: 0.7776
 Epoch [8/20], Step[340/483], loss: 0.7554
 Epoch [8/20], Step[350/483], loss: 0.7489
 Epoch [8/20], Step[360/483], loss: 0.5818
 Epoch [8/20], Step[370/483], loss: 0.5290
 Epoch [8/20], Step[380/483], loss: 0.7090
 Epoch [8/20], Step[390/483], loss: 0.8056
 Epoch [8/20], Step[400/483], loss: 0.7410
 Epoch [8/20], Step[410/483], loss: 0.6078
 Epoch [8/20], Step[420/483], loss: 0.7243
 Epoch [8/20], Step[430/483], loss: 0.7312
 Epoch [8/20], Step[440/483], loss: 0.7467
 Epoch [8/20], Step[450/483], loss: 0.6109
 Epoch [8/20], Step[460/483], loss: 0.8347
 Epoch [8/20], Step[470/483], loss: 0.8519
 Epoch [8/20], Step[480/483], loss: 0.5210
 ====> Epoch 8: Training loss: 366.3475
 ====> Epoch 8: Validation loss: 54.9344
 Epoch [9/20], Step[0/483], loss: 0.6619
 Epoch [9/20], Step[10/483], loss: 0.7512
 Epoch [9/20], Step[20/483], loss: 0.7745
 Epoch [9/20], Step[30/483], loss: 0.7428
 Epoch [9/20], Step[40/483], loss: 0.7728
 Epoch [9/20], Step[50/483], loss: 0.8286
 Epoch [9/20], Step[60/483], loss: 0.8939
 Epoch [9/20], Step[70/483], loss: 0.8370
 Epoch [9/20], Step[80/483], loss: 0.9049
 Epoch [9/20], Step[90/483], loss: 0.6549
 Epoch [9/20], Step[100/483], loss: 0.6499
 Epoch [9/20], Step[110/483], loss: 0.7981
 Epoch [9/20], Step[120/483], loss: 0.8288
 Epoch [9/20], Step[130/483], loss: 0.7192
 Epoch [9/20], Step[140/483], loss: 0.8121
 Epoch [9/20], Step[150/483], loss: 0.7902
 Epoch [9/20], Step[160/483], loss: 0.8857
 Epoch [9/20], Step[170/483], loss: 0.6233
 Epoch [9/20], Step[180/483], loss: 0.8512
 Epoch [9/20], Step[190/483], loss: 0.8405
 Epoch [9/20], Step[200/483], loss: 0.6314
 Epoch [9/20], Step[210/483], loss: 0.7607
 Epoch [9/20], Step[220/483], loss: 0.6648
 Epoch [9/20], Step[230/483], loss: 0.6229
 Epoch [9/20], Step[240/483], loss: 0.7397
 Epoch [9/20], Step[250/483], loss: 0.8180
 Epoch [9/20], Step[260/483], loss: 0.5233
 Epoch [9/20], Step[270/483], loss: 0.7794
 Epoch [9/20], Step[280/483], loss: 0.6674
 Epoch [9/20], Step[290/483], loss: 0.5509
 Epoch [9/20], Step[300/483], loss: 0.7632
 Epoch [9/20], Step[310/483], loss: 0.7864
 Epoch [9/20], Step[320/483], loss: 0.7906
 Epoch [9/20], Step[330/483], loss: 0.7798
 Epoch [9/20], Step[340/483], loss: 0.7557
 Epoch [9/20], Step[350/483], loss: 0.7508
 Epoch [9/20], Step[360/483], loss: 0.5891
 Epoch [9/20], Step[370/483], loss: 0.5393
 Epoch [9/20], Step[380/483], loss: 0.6989
 Epoch [9/20], Step[390/483], loss: 0.7778
 Epoch [9/20], Step[400/483], loss: 0.7475
 Epoch [9/20], Step[410/483], loss: 0.6258
 Epoch [9/20], Step[420/483], loss: 0.7155
 Epoch [9/20], Step[430/483], loss: 0.7303
 Epoch [9/20], Step[440/483], loss: 0.7531
 Epoch [9/20], Step[450/483], loss: 0.6098
 Epoch [9/20], Step[460/483], loss: 0.7851
 Epoch [9/20], Step[470/483], loss: 0.8443
 Epoch [9/20], Step[480/483], loss: 0.5077
 ====> Epoch 9: Training loss: 361.3616
 ====> Epoch 9: Validation loss: 54.9519
 Epoch [10/20], Step[0/483], loss: 0.6444
 Epoch [10/20], Step[10/483], loss: 0.7298
 Epoch [10/20], Step[20/483], loss: 0.7688
 Epoch [10/20], Step[30/483], loss: 0.7239
 Epoch [10/20], Step[40/483], loss: 0.7815
 Epoch [10/20], Step[50/483], loss: 0.8359
 Epoch [10/20], Step[60/483], loss: 0.9031
 Epoch [10/20], Step[70/483], loss: 0.7958
 Epoch [10/20], Step[80/483], loss: 0.9137
 Epoch [10/20], Step[90/483], loss: 0.6474
 Epoch [10/20], Step[100/483], loss: 0.6404
 Epoch [10/20], Step[110/483], loss: 0.7872
 Epoch [10/20], Step[120/483], loss: 0.8132
 Epoch [10/20], Step[130/483], loss: 0.7260
 Epoch [10/20], Step[140/483], loss: 0.8099
 Epoch [10/20], Step[150/483], loss: 0.7979
 Epoch [10/20], Step[160/483], loss: 0.8746
 Epoch [10/20], Step[170/483], loss: 0.6128
 Epoch [10/20], Step[180/483], loss: 0.8254
 Epoch [10/20], Step[190/483], loss: 0.8310
 Epoch [10/20], Step[200/483], loss: 0.6257
 Epoch [10/20], Step[210/483], loss: 0.7491
 Epoch [10/20], Step[220/483], loss: 0.6716
 Epoch [10/20], Step[230/483], loss: 0.6225
 Epoch [10/20], Step[240/483], loss: 0.7611
 Epoch [10/20], Step[250/483], loss: 0.8052
 Epoch [10/20], Step[260/483], loss: 0.5303
 Epoch [10/20], Step[270/483], loss: 0.7639
 Epoch [10/20], Step[280/483], loss: 0.6658
 Epoch [10/20], Step[290/483], loss: 0.5455
 Epoch [10/20], Step[300/483], loss: 0.7671
 Epoch [10/20], Step[310/483], loss: 0.7675
 Epoch [10/20], Step[320/483], loss: 0.7638
 Epoch [10/20], Step[330/483], loss: 0.7504
 Epoch [10/20], Step[340/483], loss: 0.7427
 Epoch [10/20], Step[350/483], loss: 0.7497
 Epoch [10/20], Step[360/483], loss: 0.5743
 Epoch [10/20], Step[370/483], loss: 0.5248
 Epoch [10/20], Step[380/483], loss: 0.6814
 Epoch [10/20], Step[390/483], loss: 0.7303
 Epoch [10/20], Step[400/483], loss: 0.7240
 Epoch [10/20], Step[410/483], loss: 0.6200
 Epoch [10/20], Step[420/483], loss: 0.7026
 Epoch [10/20], Step[430/483], loss: 0.7167
 Epoch [10/20], Step[440/483], loss: 0.7319
 Epoch [10/20], Step[450/483], loss: 0.6097
 Epoch [10/20], Step[460/483], loss: 0.7940
 Epoch [10/20], Step[470/483], loss: 0.8495
 Epoch [10/20], Step[480/483], loss: 0.4994
 ====> Epoch 10: Training loss: 357.1244
 ====> Epoch 10: Validation loss: 54.8209
 Epoch [11/20], Step[0/483], loss: 0.6386
 Epoch [11/20], Step[10/483], loss: 0.7517
 Epoch [11/20], Step[20/483], loss: 0.7810
 Epoch [11/20], Step[30/483], loss: 0.7116
 Epoch [11/20], Step[40/483], loss: 0.7537
 Epoch [11/20], Step[50/483], loss: 0.8277
 Epoch [11/20], Step[60/483], loss: 0.8783
 Epoch [11/20], Step[70/483], loss: 0.7811
 Epoch [11/20], Step[80/483], loss: 0.8991
 Epoch [11/20], Step[90/483], loss: 0.6400
 Epoch [11/20], Step[100/483], loss: 0.6390
 Epoch [11/20], Step[110/483], loss: 0.7713
 Epoch [11/20], Step[120/483], loss: 0.8392
 Epoch [11/20], Step[130/483], loss: 0.7065
 Epoch [11/20], Step[140/483], loss: 0.8047
 Epoch [11/20], Step[150/483], loss: 0.7810
 Epoch [11/20], Step[160/483], loss: 0.8838
 Epoch [11/20], Step[170/483], loss: 0.6055
 Epoch [11/20], Step[180/483], loss: 0.8267
 Epoch [11/20], Step[190/483], loss: 0.8464
 Epoch [11/20], Step[200/483], loss: 0.6185
 Epoch [11/20], Step[210/483], loss: 0.7371
 Epoch [11/20], Step[220/483], loss: 0.6428
 Epoch [11/20], Step[230/483], loss: 0.6200
 Epoch [11/20], Step[240/483], loss: 0.7098
 Epoch [11/20], Step[250/483], loss: 0.8040
 Epoch [11/20], Step[260/483], loss: 0.5308
 Epoch [11/20], Step[270/483], loss: 0.7861
 Epoch [11/20], Step[280/483], loss: 0.6591
 Epoch [11/20], Step[290/483], loss: 0.5680
 Epoch [11/20], Step[300/483], loss: 0.7599
 Epoch [11/20], Step[310/483], loss: 0.7644
 Epoch [11/20], Step[320/483], loss: 0.7946
 Epoch [11/20], Step[330/483], loss: 0.7602
 Epoch [11/20], Step[340/483], loss: 0.7399
 Epoch [11/20], Step[350/483], loss: 0.7222
 Epoch [11/20], Step[360/483], loss: 0.5647
 Epoch [11/20], Step[370/483], loss: 0.5239
 Epoch [11/20], Step[380/483], loss: 0.6675
 Epoch [11/20], Step[390/483], loss: 0.7572
 Epoch [11/20], Step[400/483], loss: 0.7055
 Epoch [11/20], Step[410/483], loss: 0.6076
 Epoch [11/20], Step[420/483], loss: 0.7113
 Epoch [11/20], Step[430/483], loss: 0.7256
 Epoch [11/20], Step[440/483], loss: 0.7272
 Epoch [11/20], Step[450/483], loss: 0.5962
 Epoch [11/20], Step[460/483], loss: 0.7954
 Epoch [11/20], Step[470/483], loss: 0.8265
 Epoch [11/20], Step[480/483], loss: 0.4953
 ====> Epoch 11: Training loss: 354.3746
 ====> Epoch 11: Validation loss: 54.9759
 Epoch [12/20], Step[0/483], loss: 0.6321
 Epoch [12/20], Step[10/483], loss: 0.7515
 Epoch [12/20], Step[20/483], loss: 0.7709
 Epoch [12/20], Step[30/483], loss: 0.7028
 Epoch [12/20], Step[40/483], loss: 0.7203
 Epoch [12/20], Step[50/483], loss: 0.8093
 Epoch [12/20], Step[60/483], loss: 0.8637
 Epoch [12/20], Step[70/483], loss: 0.8042
 Epoch [12/20], Step[80/483], loss: 0.8917
 Epoch [12/20], Step[90/483], loss: 0.6402
 Epoch [12/20], Step[100/483], loss: 0.6347
 Epoch [12/20], Step[110/483], loss: 0.7841
 Epoch [12/20], Step[120/483], loss: 0.8223
 Epoch [12/20], Step[130/483], loss: 0.7169
 Epoch [12/20], Step[140/483], loss: 0.8030
 Epoch [12/20], Step[150/483], loss: 0.7841
 Epoch [12/20], Step[160/483], loss: 0.8492
 Epoch [12/20], Step[170/483], loss: 0.5940
 Epoch [12/20], Step[180/483], loss: 0.8142
 Epoch [12/20], Step[190/483], loss: 0.8144
 Epoch [12/20], Step[200/483], loss: 0.6082
 Epoch [12/20], Step[210/483], loss: 0.7144
 Epoch [12/20], Step[220/483], loss: 0.6492
 Epoch [12/20], Step[230/483], loss: 0.6062
 Epoch [12/20], Step[240/483], loss: 0.7317
 Epoch [12/20], Step[250/483], loss: 0.7870
 Epoch [12/20], Step[260/483], loss: 0.5093
 Epoch [12/20], Step[270/483], loss: 0.7582
 Epoch [12/20], Step[280/483], loss: 0.6539
 Epoch [12/20], Step[290/483], loss: 0.5436
 Epoch [12/20], Step[300/483], loss: 0.7393
 Epoch [12/20], Step[310/483], loss: 0.7657
 Epoch [12/20], Step[320/483], loss: 0.7684
 Epoch [12/20], Step[330/483], loss: 0.7693
 Epoch [12/20], Step[340/483], loss: 0.7426
 Epoch [12/20], Step[350/483], loss: 0.6966
 Epoch [12/20], Step[360/483], loss: 0.5506
 Epoch [12/20], Step[370/483], loss: 0.5063
 Epoch [12/20], Step[380/483], loss: 0.6617
 Epoch [12/20], Step[390/483], loss: 0.7237
 Epoch [12/20], Step[400/483], loss: 0.7071
 Epoch [12/20], Step[410/483], loss: 0.5772
 Epoch [12/20], Step[420/483], loss: 0.6996
 Epoch [12/20], Step[430/483], loss: 0.6959
 Epoch [12/20], Step[440/483], loss: 0.7144
 Epoch [12/20], Step[450/483], loss: 0.5852
 Epoch [12/20], Step[460/483], loss: 0.7946
 Epoch [12/20], Step[470/483], loss: 0.7996
 Epoch [12/20], Step[480/483], loss: 0.4991
 ====> Epoch 12: Training loss: 351.5530
 ====> Epoch 12: Validation loss: 55.2241
 Epoch [13/20], Step[0/483], loss: 0.6341
 Epoch [13/20], Step[10/483], loss: 0.7294
 Epoch [13/20], Step[20/483], loss: 0.7669
 Epoch [13/20], Step[30/483], loss: 0.7267
 Epoch [13/20], Step[40/483], loss: 0.7355
 Epoch [13/20], Step[50/483], loss: 0.7977
 Epoch [13/20], Step[60/483], loss: 0.8604
 Epoch [13/20], Step[70/483], loss: 0.8043
 Epoch [13/20], Step[80/483], loss: 0.8779
 Epoch [13/20], Step[90/483], loss: 0.6261
 Epoch [13/20], Step[100/483], loss: 0.6274
 Epoch [13/20], Step[110/483], loss: 0.7732
 Epoch [13/20], Step[120/483], loss: 0.8151
 Epoch [13/20], Step[130/483], loss: 0.7205
 Epoch [13/20], Step[140/483], loss: 0.7733
 Epoch [13/20], Step[150/483], loss: 0.7710
 Epoch [13/20], Step[160/483], loss: 0.8445
 Epoch [13/20], Step[170/483], loss: 0.5870
 Epoch [13/20], Step[180/483], loss: 0.8071
 Epoch [13/20], Step[190/483], loss: 0.8428
 Epoch [13/20], Step[200/483], loss: 0.6148
 Epoch [13/20], Step[210/483], loss: 0.7087
 Epoch [13/20], Step[220/483], loss: 0.6432
 Epoch [13/20], Step[230/483], loss: 0.6178
 Epoch [13/20], Step[240/483], loss: 0.7391
 Epoch [13/20], Step[250/483], loss: 0.7926
 Epoch [13/20], Step[260/483], loss: 0.5064
 Epoch [13/20], Step[270/483], loss: 0.7558
 Epoch [13/20], Step[280/483], loss: 0.6463
 Epoch [13/20], Step[290/483], loss: 0.5412
 Epoch [13/20], Step[300/483], loss: 0.7473
 Epoch [13/20], Step[310/483], loss: 0.7407
 Epoch [13/20], Step[320/483], loss: 0.7721
 Epoch [13/20], Step[330/483], loss: 0.7463
 Epoch [13/20], Step[340/483], loss: 0.7439
 Epoch [13/20], Step[350/483], loss: 0.7190
 Epoch [13/20], Step[360/483], loss: 0.5560
 Epoch [13/20], Step[370/483], loss: 0.5182
 Epoch [13/20], Step[380/483], loss: 0.6670
 Epoch [13/20], Step[390/483], loss: 0.7122
 Epoch [13/20], Step[400/483], loss: 0.6872
 Epoch [13/20], Step[410/483], loss: 0.5990
 Epoch [13/20], Step[420/483], loss: 0.6928
 Epoch [13/20], Step[430/483], loss: 0.6917
 Epoch [13/20], Step[440/483], loss: 0.7061
 Epoch [13/20], Step[450/483], loss: 0.5870
 Epoch [13/20], Step[460/483], loss: 0.8003
 Epoch [13/20], Step[470/483], loss: 0.8105
 Epoch [13/20], Step[480/483], loss: 0.4871
 ====> Epoch 13: Training loss: 347.6567
 ====> Epoch 13: Validation loss: 55.4134
 Epoch [14/20], Step[0/483], loss: 0.6358
 Epoch [14/20], Step[10/483], loss: 0.7300
 Epoch [14/20], Step[20/483], loss: 0.7379
 Epoch [14/20], Step[30/483], loss: 0.6874
 Epoch [14/20], Step[40/483], loss: 0.7589
 Epoch [14/20], Step[50/483], loss: 0.7915
 Epoch [14/20], Step[60/483], loss: 0.8591
 Epoch [14/20], Step[70/483], loss: 0.7685
 Epoch [14/20], Step[80/483], loss: 0.8597
 Epoch [14/20], Step[90/483], loss: 0.6243
 Epoch [14/20], Step[100/483], loss: 0.6317
 Epoch [14/20], Step[110/483], loss: 0.7549
 Epoch [14/20], Step[120/483], loss: 0.7907
 Epoch [14/20], Step[130/483], loss: 0.6950
 Epoch [14/20], Step[140/483], loss: 0.7763
 Epoch [14/20], Step[150/483], loss: 0.7576
 Epoch [14/20], Step[160/483], loss: 0.8403
 Epoch [14/20], Step[170/483], loss: 0.6100
 Epoch [14/20], Step[180/483], loss: 0.8189
 Epoch [14/20], Step[190/483], loss: 0.8127
 Epoch [14/20], Step[200/483], loss: 0.5849
 Epoch [14/20], Step[210/483], loss: 0.7057
 Epoch [14/20], Step[220/483], loss: 0.6476
 Epoch [14/20], Step[230/483], loss: 0.6092
 Epoch [14/20], Step[240/483], loss: 0.7169
 Epoch [14/20], Step[250/483], loss: 0.7729
 Epoch [14/20], Step[260/483], loss: 0.5042
 Epoch [14/20], Step[270/483], loss: 0.7494
 Epoch [14/20], Step[280/483], loss: 0.6581
 Epoch [14/20], Step[290/483], loss: 0.5344
 Epoch [14/20], Step[300/483], loss: 0.7384
 Epoch [14/20], Step[310/483], loss: 0.7398
 Epoch [14/20], Step[320/483], loss: 0.7701
 Epoch [14/20], Step[330/483], loss: 0.7496
 Epoch [14/20], Step[340/483], loss: 0.7318
 Epoch [14/20], Step[350/483], loss: 0.7017
 Epoch [14/20], Step[360/483], loss: 0.5407
 Epoch [14/20], Step[370/483], loss: 0.5161
 Epoch [14/20], Step[380/483], loss: 0.6625
 Epoch [14/20], Step[390/483], loss: 0.7305
 Epoch [14/20], Step[400/483], loss: 0.6912
 Epoch [14/20], Step[410/483], loss: 0.5862
 Epoch [14/20], Step[420/483], loss: 0.6808
 Epoch [14/20], Step[430/483], loss: 0.7183
 Epoch [14/20], Step[440/483], loss: 0.7070
 Epoch [14/20], Step[450/483], loss: 0.5829
 Epoch [14/20], Step[460/483], loss: 0.7781
 Epoch [14/20], Step[470/483], loss: 0.7800
 Epoch [14/20], Step[480/483], loss: 0.4826
 ====> Epoch 14: Training loss: 346.1602
 ====> Epoch 14: Validation loss: 55.5371
 Epoch [15/20], Step[0/483], loss: 0.6226
 Epoch [15/20], Step[10/483], loss: 0.7361
 Epoch [15/20], Step[20/483], loss: 0.7527
 Epoch [15/20], Step[30/483], loss: 0.7036
 Epoch [15/20], Step[40/483], loss: 0.7632
 Epoch [15/20], Step[50/483], loss: 0.7975
 Epoch [15/20], Step[60/483], loss: 0.8687
 Epoch [15/20], Step[70/483], loss: 0.7747
 Epoch [15/20], Step[80/483], loss: 0.8811
 Epoch [15/20], Step[90/483], loss: 0.6237
 Epoch [15/20], Step[100/483], loss: 0.6367
 Epoch [15/20], Step[110/483], loss: 0.7623
 Epoch [15/20], Step[120/483], loss: 0.7974
 Epoch [15/20], Step[130/483], loss: 0.7190
 Epoch [15/20], Step[140/483], loss: 0.7774
 Epoch [15/20], Step[150/483], loss: 0.7425
 Epoch [15/20], Step[160/483], loss: 0.8182
 Epoch [15/20], Step[170/483], loss: 0.5907
 Epoch [15/20], Step[180/483], loss: 0.8078
 Epoch [15/20], Step[190/483], loss: 0.7936
 Epoch [15/20], Step[200/483], loss: 0.6007
 Epoch [15/20], Step[210/483], loss: 0.7125
 Epoch [15/20], Step[220/483], loss: 0.6569
 Epoch [15/20], Step[230/483], loss: 0.6059
 Epoch [15/20], Step[240/483], loss: 0.7147
 Epoch [15/20], Step[250/483], loss: 0.7813
 Epoch [15/20], Step[260/483], loss: 0.5009
 Epoch [15/20], Step[270/483], loss: 0.7437
 Epoch [15/20], Step[280/483], loss: 0.6371
 Epoch [15/20], Step[290/483], loss: 0.5438
 Epoch [15/20], Step[300/483], loss: 0.7420
 Epoch [15/20], Step[310/483], loss: 0.7229
 Epoch [15/20], Step[320/483], loss: 0.7579
 Epoch [15/20], Step[330/483], loss: 0.7457
 Epoch [15/20], Step[340/483], loss: 0.7413
 Epoch [15/20], Step[350/483], loss: 0.7011
 Epoch [15/20], Step[360/483], loss: 0.5398
 Epoch [15/20], Step[370/483], loss: 0.5052
 Epoch [15/20], Step[380/483], loss: 0.6690
 Epoch [15/20], Step[390/483], loss: 0.7303
 Epoch [15/20], Step[400/483], loss: 0.6997
 Epoch [15/20], Step[410/483], loss: 0.5666
 Epoch [15/20], Step[420/483], loss: 0.6590
 Epoch [15/20], Step[430/483], loss: 0.6962
 Epoch [15/20], Step[440/483], loss: 0.7095
 Epoch [15/20], Step[450/483], loss: 0.5817
 Epoch [15/20], Step[460/483], loss: 0.7955
 Epoch [15/20], Step[470/483], loss: 0.7833
 Epoch [15/20], Step[480/483], loss: 0.4965
 ====> Epoch 15: Training loss: 344.9599
 ====> Epoch 15: Validation loss: 55.8104
 Epoch [16/20], Step[0/483], loss: 0.6352
 Epoch [16/20], Step[10/483], loss: 0.7119
 Epoch [16/20], Step[20/483], loss: 0.7421
 Epoch [16/20], Step[30/483], loss: 0.6993
 Epoch [16/20], Step[40/483], loss: 0.7376
 Epoch [16/20], Step[50/483], loss: 0.7841
 Epoch [16/20], Step[60/483], loss: 0.8658
 Epoch [16/20], Step[70/483], loss: 0.7721
 Epoch [16/20], Step[80/483], loss: 0.8653
 Epoch [16/20], Step[90/483], loss: 0.6109
 Epoch [16/20], Step[100/483], loss: 0.5966
 Epoch [16/20], Step[110/483], loss: 0.7534
 Epoch [16/20], Step[120/483], loss: 0.8085
 Epoch [16/20], Step[130/483], loss: 0.6963
 Epoch [16/20], Step[140/483], loss: 0.7787
 Epoch [16/20], Step[150/483], loss: 0.7557
 Epoch [16/20], Step[160/483], loss: 0.8449
 Epoch [16/20], Step[170/483], loss: 0.5864
 Epoch [16/20], Step[180/483], loss: 0.7851
 Epoch [16/20], Step[190/483], loss: 0.7778
 Epoch [16/20], Step[200/483], loss: 0.6037
 Epoch [16/20], Step[210/483], loss: 0.6984
 Epoch [16/20], Step[220/483], loss: 0.6630
 Epoch [16/20], Step[230/483], loss: 0.6118
 Epoch [16/20], Step[240/483], loss: 0.7351
 Epoch [16/20], Step[250/483], loss: 0.7554
 Epoch [16/20], Step[260/483], loss: 0.5116
 Epoch [16/20], Step[270/483], loss: 0.7447
 Epoch [16/20], Step[280/483], loss: 0.6334
 Epoch [16/20], Step[290/483], loss: 0.5334
 Epoch [16/20], Step[300/483], loss: 0.7160
 Epoch [16/20], Step[310/483], loss: 0.7239
 Epoch [16/20], Step[320/483], loss: 0.7540
 Epoch [16/20], Step[330/483], loss: 0.7296
 Epoch [16/20], Step[340/483], loss: 0.7367
 Epoch [16/20], Step[350/483], loss: 0.6942
 Epoch [16/20], Step[360/483], loss: 0.5552
 Epoch [16/20], Step[370/483], loss: 0.5155
 Epoch [16/20], Step[380/483], loss: 0.6622
 Epoch [16/20], Step[390/483], loss: 0.7240
 Epoch [16/20], Step[400/483], loss: 0.6700
 Epoch [16/20], Step[410/483], loss: 0.5933
 Epoch [16/20], Step[420/483], loss: 0.6630
 Epoch [16/20], Step[430/483], loss: 0.7060
 Epoch [16/20], Step[440/483], loss: 0.6927
 Epoch [16/20], Step[450/483], loss: 0.5594
 Epoch [16/20], Step[460/483], loss: 0.7787
 Epoch [16/20], Step[470/483], loss: 0.7814
 Epoch [16/20], Step[480/483], loss: 0.4893
 ====> Epoch 16: Training loss: 343.3814
 ====> Epoch 16: Validation loss: 56.0452
 Epoch [17/20], Step[0/483], loss: 0.6344
 Epoch [17/20], Step[10/483], loss: 0.7203
 Epoch [17/20], Step[20/483], loss: 0.7345
 Epoch [17/20], Step[30/483], loss: 0.6891
 Epoch [17/20], Step[40/483], loss: 0.7239
 Epoch [17/20], Step[50/483], loss: 0.7695
 Epoch [17/20], Step[60/483], loss: 0.8412
 Epoch [17/20], Step[70/483], loss: 0.7534
 Epoch [17/20], Step[80/483], loss: 0.8630
 Epoch [17/20], Step[90/483], loss: 0.6310
 Epoch [17/20], Step[100/483], loss: 0.6234
 Epoch [17/20], Step[110/483], loss: 0.7603
 Epoch [17/20], Step[120/483], loss: 0.8110
 Epoch [17/20], Step[130/483], loss: 0.6739
 Epoch [17/20], Step[140/483], loss: 0.7638
 Epoch [17/20], Step[150/483], loss: 0.7516
 Epoch [17/20], Step[160/483], loss: 0.8313
 Epoch [17/20], Step[170/483], loss: 0.5936
 Epoch [17/20], Step[180/483], loss: 0.7910
 Epoch [17/20], Step[190/483], loss: 0.8042
 Epoch [17/20], Step[200/483], loss: 0.5892
 Epoch [17/20], Step[210/483], loss: 0.7020
 Epoch [17/20], Step[220/483], loss: 0.6502
 Epoch [17/20], Step[230/483], loss: 0.5939
 Epoch [17/20], Step[240/483], loss: 0.7121
 Epoch [17/20], Step[250/483], loss: 0.7701
 Epoch [17/20], Step[260/483], loss: 0.5077
 Epoch [17/20], Step[270/483], loss: 0.7321
 Epoch [17/20], Step[280/483], loss: 0.6458
 Epoch [17/20], Step[290/483], loss: 0.5412
 Epoch [17/20], Step[300/483], loss: 0.7267
 Epoch [17/20], Step[310/483], loss: 0.7397
 Epoch [17/20], Step[320/483], loss: 0.7517
 Epoch [17/20], Step[330/483], loss: 0.7540
 Epoch [17/20], Step[340/483], loss: 0.7256
 Epoch [17/20], Step[350/483], loss: 0.7011
 Epoch [17/20], Step[360/483], loss: 0.5395
 Epoch [17/20], Step[370/483], loss: 0.4964
 Epoch [17/20], Step[380/483], loss: 0.6377
 Epoch [17/20], Step[390/483], loss: 0.7236
 Epoch [17/20], Step[400/483], loss: 0.6734
 Epoch [17/20], Step[410/483], loss: 0.5745
 Epoch [17/20], Step[420/483], loss: 0.6599
 Epoch [17/20], Step[430/483], loss: 0.7067
 Epoch [17/20], Step[440/483], loss: 0.6807
 Epoch [17/20], Step[450/483], loss: 0.5587
 Epoch [17/20], Step[460/483], loss: 0.7450
 Epoch [17/20], Step[470/483], loss: 0.7766
 Epoch [17/20], Step[480/483], loss: 0.4754
 ====> Epoch 17: Training loss: 340.9270
 ====> Epoch 17: Validation loss: 56.0074
 Epoch [18/20], Step[0/483], loss: 0.6560
 Epoch [18/20], Step[10/483], loss: 0.7527
 Epoch [18/20], Step[20/483], loss: 0.7248
 Epoch [18/20], Step[30/483], loss: 0.7012
 Epoch [18/20], Step[40/483], loss: 0.7315
 Epoch [18/20], Step[50/483], loss: 0.7488
 Epoch [18/20], Step[60/483], loss: 0.8586
 Epoch [18/20], Step[70/483], loss: 0.7389
 Epoch [18/20], Step[80/483], loss: 0.8463
 Epoch [18/20], Step[90/483], loss: 0.6212
 Epoch [18/20], Step[100/483], loss: 0.6057
 Epoch [18/20], Step[110/483], loss: 0.7360
 Epoch [18/20], Step[120/483], loss: 0.8012
 Epoch [18/20], Step[130/483], loss: 0.6777
 Epoch [18/20], Step[140/483], loss: 0.7514
 Epoch [18/20], Step[150/483], loss: 0.7514
 Epoch [18/20], Step[160/483], loss: 0.8267
 Epoch [18/20], Step[170/483], loss: 0.5688
 Epoch [18/20], Step[180/483], loss: 0.8222
 Epoch [18/20], Step[190/483], loss: 0.8117
 Epoch [18/20], Step[200/483], loss: 0.5832
 Epoch [18/20], Step[210/483], loss: 0.6980
 Epoch [18/20], Step[220/483], loss: 0.6419
 Epoch [18/20], Step[230/483], loss: 0.5915
 Epoch [18/20], Step[240/483], loss: 0.7085
 Epoch [18/20], Step[250/483], loss: 0.7505
 Epoch [18/20], Step[260/483], loss: 0.4997
 Epoch [18/20], Step[270/483], loss: 0.7516
 Epoch [18/20], Step[280/483], loss: 0.6269
 Epoch [18/20], Step[290/483], loss: 0.5471
 Epoch [18/20], Step[300/483], loss: 0.7182
 Epoch [18/20], Step[310/483], loss: 0.7188
 Epoch [18/20], Step[320/483], loss: 0.7316
 Epoch [18/20], Step[330/483], loss: 0.7346
 Epoch [18/20], Step[340/483], loss: 0.7190
 Epoch [18/20], Step[350/483], loss: 0.6926
 Epoch [18/20], Step[360/483], loss: 0.5416
 Epoch [18/20], Step[370/483], loss: 0.5040
 Epoch [18/20], Step[380/483], loss: 0.6545
 Epoch [18/20], Step[390/483], loss: 0.6994
 Epoch [18/20], Step[400/483], loss: 0.6929
 Epoch [18/20], Step[410/483], loss: 0.5992
 Epoch [18/20], Step[420/483], loss: 0.6760
 Epoch [18/20], Step[430/483], loss: 0.6790
 Epoch [18/20], Step[440/483], loss: 0.6746
 Epoch [18/20], Step[450/483], loss: 0.5667
 Epoch [18/20], Step[460/483], loss: 0.7788
 Epoch [18/20], Step[470/483], loss: 0.7739
 Epoch [18/20], Step[480/483], loss: 0.4756
 ====> Epoch 18: Training loss: 339.3804
 ====> Epoch 18: Validation loss: 56.1462
 Epoch [19/20], Step[0/483], loss: 0.6203
 Epoch [19/20], Step[10/483], loss: 0.7129
 Epoch [19/20], Step[20/483], loss: 0.7031
 Epoch [19/20], Step[30/483], loss: 0.6835
 Epoch [19/20], Step[40/483], loss: 0.7299
 Epoch [19/20], Step[50/483], loss: 0.7883
 Epoch [19/20], Step[60/483], loss: 0.8126
 Epoch [19/20], Step[70/483], loss: 0.7533
 Epoch [19/20], Step[80/483], loss: 0.8303
 Epoch [19/20], Step[90/483], loss: 0.6176
 Epoch [19/20], Step[100/483], loss: 0.6139
 Epoch [19/20], Step[110/483], loss: 0.7645
 Epoch [19/20], Step[120/483], loss: 0.7930
 Epoch [19/20], Step[130/483], loss: 0.6814
 Epoch [19/20], Step[140/483], loss: 0.7578
 Epoch [19/20], Step[150/483], loss: 0.7509
 Epoch [19/20], Step[160/483], loss: 0.8037
 Epoch [19/20], Step[170/483], loss: 0.5644
 Epoch [19/20], Step[180/483], loss: 0.7980
 Epoch [19/20], Step[190/483], loss: 0.8090
 Epoch [19/20], Step[200/483], loss: 0.5744
 Epoch [19/20], Step[210/483], loss: 0.6923
 Epoch [19/20], Step[220/483], loss: 0.6684
 Epoch [19/20], Step[230/483], loss: 0.5947
 Epoch [19/20], Step[240/483], loss: 0.6893
 Epoch [19/20], Step[250/483], loss: 0.7553
 Epoch [19/20], Step[260/483], loss: 0.4913
 Epoch [19/20], Step[270/483], loss: 0.7272
 Epoch [19/20], Step[280/483], loss: 0.6332
 Epoch [19/20], Step[290/483], loss: 0.5385
 Epoch [19/20], Step[300/483], loss: 0.7211
 Epoch [19/20], Step[310/483], loss: 0.7182
 Epoch [19/20], Step[320/483], loss: 0.7335
 Epoch [19/20], Step[330/483], loss: 0.7284
 Epoch [19/20], Step[340/483], loss: 0.7061
 Epoch [19/20], Step[350/483], loss: 0.6913
 Epoch [19/20], Step[360/483], loss: 0.5301
 Epoch [19/20], Step[370/483], loss: 0.5094
 Epoch [19/20], Step[380/483], loss: 0.6541
 Epoch [19/20], Step[390/483], loss: 0.7045
 Epoch [19/20], Step[400/483], loss: 0.6969
 Epoch [19/20], Step[410/483], loss: 0.5879
 Epoch [19/20], Step[420/483], loss: 0.6522
 Epoch [19/20], Step[430/483], loss: 0.6882
 Epoch [19/20], Step[440/483], loss: 0.6861
 Epoch [19/20], Step[450/483], loss: 0.5725
 Epoch [19/20], Step[460/483], loss: 0.7694
 Epoch [19/20], Step[470/483], loss: 0.7771
 Epoch [19/20], Step[480/483], loss: 0.4906
 ====> Epoch 19: Training loss: 337.2563
 ====> Epoch 19: Validation loss: 56.1221
 Epoch [20/20], Step[0/483], loss: 0.6277
 Epoch [20/20], Step[10/483], loss: 0.7118
 Epoch [20/20], Step[20/483], loss: 0.7149
 Epoch [20/20], Step[30/483], loss: 0.6944
 Epoch [20/20], Step[40/483], loss: 0.7267
 Epoch [20/20], Step[50/483], loss: 0.7718
 Epoch [20/20], Step[60/483], loss: 0.8190
 Epoch [20/20], Step[70/483], loss: 0.7498
 Epoch [20/20], Step[80/483], loss: 0.8314
 Epoch [20/20], Step[90/483], loss: 0.6185
 Epoch [20/20], Step[100/483], loss: 0.6085
 Epoch [20/20], Step[110/483], loss: 0.7298
 Epoch [20/20], Step[120/483], loss: 0.7730
 Epoch [20/20], Step[130/483], loss: 0.6986
 Epoch [20/20], Step[140/483], loss: 0.7753
 Epoch [20/20], Step[150/483], loss: 0.7537
 Epoch [20/20], Step[160/483], loss: 0.8187
 Epoch [20/20], Step[170/483], loss: 0.5766
 Epoch [20/20], Step[180/483], loss: 0.7896
 Epoch [20/20], Step[190/483], loss: 0.8078
 Epoch [20/20], Step[200/483], loss: 0.5825
 Epoch [20/20], Step[210/483], loss: 0.7000
 Epoch [20/20], Step[220/483], loss: 0.6455
 Epoch [20/20], Step[230/483], loss: 0.5847
