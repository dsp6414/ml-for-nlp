 Loading feature files...
 <s> = 1
 </s> = 2
 All scenes loaded.
 Hyperparameters:Namespace(LR=0.01, alternatives=1, batch_size=100, dec='LSTM', dropout=0.3, epochs=10, hidden_sz=100, k='20', load=None, log_interval=10, model='ss1', no_cuda=False, save=None, seed=1)
 Listener0: Listener0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=100)
  )
  (string_encoder): LinearStringEncoder(
    (fc): Linear(in_features=1063, out_features=100)
  )
  (scorer): MLPScorer(
    (dropout): Dropout(p=0.3)
    (linear_4): Linear(in_features=100, out_features=100)
    (linear_5): Linear(in_features=100, out_features=100)
    (linear_3): Linear(in_features=100, out_features=1)
  )
)
 Speaker0: Speaker0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=100)
  )
  (string_decoder): LSTMStringDecoder(
    (embedding): Embedding(1063, 100)
    (lstm): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.3)
    (linear): Linear(in_features=100, out_features=1063)
    (dropout): Dropout(p=0.3)
  )
)
 Training Listener0...
 Epoch [1/10], Step[0/483], loss: 0.6984
 Epoch [1/10], Step[10/483], loss: 0.6814
 Epoch [1/10], Step[20/483], loss: 0.6792
 Epoch [1/10], Step[30/483], loss: 0.6807
 Epoch [1/10], Step[40/483], loss: 0.7173
 Epoch [1/10], Step[50/483], loss: 0.7051
 Epoch [1/10], Step[60/483], loss: 0.6916
 Epoch [1/10], Step[70/483], loss: 0.6935
 Epoch [1/10], Step[80/483], loss: 0.6841
 Epoch [1/10], Step[90/483], loss: 0.6502
 Epoch [1/10], Step[100/483], loss: 0.6374
 Epoch [1/10], Step[110/483], loss: 0.7617
 Epoch [1/10], Step[120/483], loss: 0.5752
 Epoch [1/10], Step[130/483], loss: 0.6942
 Epoch [1/10], Step[140/483], loss: 0.6733
 Epoch [1/10], Step[150/483], loss: 0.7359
 Epoch [1/10], Step[160/483], loss: 0.7730
 Epoch [1/10], Step[170/483], loss: 0.6696
 Epoch [1/10], Step[180/483], loss: 0.6804
 Epoch [1/10], Step[190/483], loss: 0.7363
 Epoch [1/10], Step[200/483], loss: 0.6758
 Epoch [1/10], Step[210/483], loss: 0.6097
 Epoch [1/10], Step[220/483], loss: 0.7049
 Epoch [1/10], Step[230/483], loss: 0.6790
 Epoch [1/10], Step[240/483], loss: 0.6446
 Epoch [1/10], Step[250/483], loss: 0.5424
 Epoch [1/10], Step[260/483], loss: 0.6030
 Epoch [1/10], Step[270/483], loss: 0.5865
 Epoch [1/10], Step[280/483], loss: 0.5626
 Epoch [1/10], Step[290/483], loss: 0.6260
 Epoch [1/10], Step[300/483], loss: 0.6578
 Epoch [1/10], Step[310/483], loss: 0.6931
 Epoch [1/10], Step[320/483], loss: 0.6526
 Epoch [1/10], Step[330/483], loss: 0.6128
 Epoch [1/10], Step[340/483], loss: 0.5518
 Epoch [1/10], Step[350/483], loss: 0.6174
 Epoch [1/10], Step[360/483], loss: 0.6840
 Epoch [1/10], Step[370/483], loss: 0.5615
 Epoch [1/10], Step[380/483], loss: 0.6466
 Epoch [1/10], Step[390/483], loss: 0.6009
 Epoch [1/10], Step[400/483], loss: 0.5949
 Epoch [1/10], Step[410/483], loss: 0.6085
 Epoch [1/10], Step[420/483], loss: 0.5054
 Epoch [1/10], Step[430/483], loss: 0.6424
 Epoch [1/10], Step[440/483], loss: 0.6713
 Epoch [1/10], Step[450/483], loss: 0.6456
 Epoch [1/10], Step[460/483], loss: 0.6434
 Epoch [1/10], Step[470/483], loss: 0.6503
 Epoch [1/10], Step[480/483], loss: 0.6548
 ====> Epoch 1: Training loss: 320.9561
 Training Accuracy: 0.639130
 ====> Epoch 1: Validation loss: 36.3789
 Validation Accuracy: 0.790333
 Epoch [2/10], Step[0/483], loss: 0.6376
 Epoch [2/10], Step[10/483], loss: 0.4133
 Epoch [2/10], Step[20/483], loss: 0.7524
 Epoch [2/10], Step[30/483], loss: 0.5356
 Epoch [2/10], Step[40/483], loss: 0.4359
 Epoch [2/10], Step[50/483], loss: 0.5258
 Epoch [2/10], Step[60/483], loss: 0.5989
 Epoch [2/10], Step[70/483], loss: 0.5495
 Epoch [2/10], Step[80/483], loss: 0.5514
 Epoch [2/10], Step[90/483], loss: 0.5385
 Epoch [2/10], Step[100/483], loss: 0.5270
 Epoch [2/10], Step[110/483], loss: 0.5224
 Epoch [2/10], Step[120/483], loss: 0.6792
 Epoch [2/10], Step[130/483], loss: 0.5940
 Epoch [2/10], Step[140/483], loss: 0.4281
 Epoch [2/10], Step[150/483], loss: 0.6390
 Epoch [2/10], Step[160/483], loss: 0.5625
 Epoch [2/10], Step[170/483], loss: 0.5760
 Epoch [2/10], Step[180/483], loss: 0.4580
 Epoch [2/10], Step[190/483], loss: 0.5570
 Epoch [2/10], Step[200/483], loss: 0.5204
 Epoch [2/10], Step[210/483], loss: 0.5344
 Epoch [2/10], Step[220/483], loss: 0.4777
 Epoch [2/10], Step[230/483], loss: 0.5670
 Epoch [2/10], Step[240/483], loss: 0.4932
 Epoch [2/10], Step[250/483], loss: 0.3962
 Epoch [2/10], Step[260/483], loss: 0.3547
 Epoch [2/10], Step[270/483], loss: 0.3796
 Epoch [2/10], Step[280/483], loss: 0.4531
 Epoch [2/10], Step[290/483], loss: 0.5362
 Epoch [2/10], Step[300/483], loss: 0.4902
 Epoch [2/10], Step[310/483], loss: 0.3790
 Epoch [2/10], Step[320/483], loss: 0.4999
 Epoch [2/10], Step[330/483], loss: 0.5088
 Epoch [2/10], Step[340/483], loss: 0.4141
 Epoch [2/10], Step[350/483], loss: 0.6733
 Epoch [2/10], Step[360/483], loss: 0.4928
 Epoch [2/10], Step[370/483], loss: 0.3224
 Epoch [2/10], Step[380/483], loss: 0.4368
 Epoch [2/10], Step[390/483], loss: 0.5469
 Epoch [2/10], Step[400/483], loss: 0.4133
 Epoch [2/10], Step[410/483], loss: 0.4772
 Epoch [2/10], Step[420/483], loss: 0.4071
 Epoch [2/10], Step[430/483], loss: 0.4591
 Epoch [2/10], Step[440/483], loss: 0.5022
 Epoch [2/10], Step[450/483], loss: 0.4044
 Epoch [2/10], Step[460/483], loss: 0.5167
 Epoch [2/10], Step[470/483], loss: 0.5518
 Epoch [2/10], Step[480/483], loss: 0.4650
 ====> Epoch 2: Training loss: 250.2206
 Training Accuracy: 0.724596
 ====> Epoch 2: Validation loss: 28.1818
 Validation Accuracy: 0.748667
 Epoch [3/10], Step[0/483], loss: 0.4459
 Epoch [3/10], Step[10/483], loss: 0.3184
 Epoch [3/10], Step[20/483], loss: 0.3687
 Epoch [3/10], Step[30/483], loss: 0.5665
 Epoch [3/10], Step[40/483], loss: 0.3931
 Epoch [3/10], Step[50/483], loss: 0.4360
 Epoch [3/10], Step[60/483], loss: 0.4285
 Epoch [3/10], Step[70/483], loss: 0.5011
 Epoch [3/10], Step[80/483], loss: 0.4511
 Epoch [3/10], Step[90/483], loss: 0.3878
 Epoch [3/10], Step[100/483], loss: 0.4363
 Epoch [3/10], Step[110/483], loss: 0.5561
 Epoch [3/10], Step[120/483], loss: 0.4156
 Epoch [3/10], Step[130/483], loss: 0.4200
 Epoch [3/10], Step[140/483], loss: 0.3727
 Epoch [3/10], Step[150/483], loss: 0.2964
 Epoch [3/10], Step[160/483], loss: 0.3602
 Epoch [3/10], Step[170/483], loss: 0.4148
 Epoch [3/10], Step[180/483], loss: 0.3808
 Epoch [3/10], Step[190/483], loss: 0.4524
 Epoch [3/10], Step[200/483], loss: 0.4025
 Epoch [3/10], Step[210/483], loss: 0.4616
 Epoch [3/10], Step[220/483], loss: 0.3671
 Epoch [3/10], Step[230/483], loss: 0.4373
 Epoch [3/10], Step[240/483], loss: 0.3704
 Epoch [3/10], Step[250/483], loss: 0.3829
 Epoch [3/10], Step[260/483], loss: 0.3009
 Epoch [3/10], Step[270/483], loss: 0.2888
 Epoch [3/10], Step[280/483], loss: 0.4121
 Epoch [3/10], Step[290/483], loss: 0.3247
 Epoch [3/10], Step[300/483], loss: 0.4061
 Epoch [3/10], Step[310/483], loss: 0.3355
 Epoch [3/10], Step[320/483], loss: 0.5227
 Epoch [3/10], Step[330/483], loss: 0.4782
 Epoch [3/10], Step[340/483], loss: 0.3271
 Epoch [3/10], Step[350/483], loss: 0.4807
 Epoch [3/10], Step[360/483], loss: 0.5267
 Epoch [3/10], Step[370/483], loss: 0.3110
 Epoch [3/10], Step[380/483], loss: 0.4169
 Epoch [3/10], Step[390/483], loss: 0.4162
 Epoch [3/10], Step[400/483], loss: 0.4783
 Epoch [3/10], Step[410/483], loss: 0.3932
 Epoch [3/10], Step[420/483], loss: 0.4337
 Epoch [3/10], Step[430/483], loss: 0.3813
 Epoch [3/10], Step[440/483], loss: 0.3878
 Epoch [3/10], Step[450/483], loss: 0.4041
 Epoch [3/10], Step[460/483], loss: 0.4347
 Epoch [3/10], Step[470/483], loss: 0.3423
 Epoch [3/10], Step[480/483], loss: 0.3044
 ====> Epoch 3: Training loss: 198.6487
 Training Accuracy: 0.788696
 ====> Epoch 3: Validation loss: 23.2420
 Validation Accuracy: 0.808667
 Epoch [4/10], Step[0/483], loss: 0.3578
 Epoch [4/10], Step[10/483], loss: 0.3444
 Epoch [4/10], Step[20/483], loss: 0.3255
 Epoch [4/10], Step[30/483], loss: 0.3824
 Epoch [4/10], Step[40/483], loss: 0.5043
 Epoch [4/10], Step[50/483], loss: 0.4064
 Epoch [4/10], Step[60/483], loss: 0.4741
 Epoch [4/10], Step[70/483], loss: 0.3691
 Epoch [4/10], Step[80/483], loss: 0.3104
 Epoch [4/10], Step[90/483], loss: 0.3295
 Epoch [4/10], Step[100/483], loss: 0.3817
 Epoch [4/10], Step[110/483], loss: 0.3718
 Epoch [4/10], Step[120/483], loss: 0.3603
 Epoch [4/10], Step[130/483], loss: 0.5801
 Epoch [4/10], Step[140/483], loss: 0.3548
 Epoch [4/10], Step[150/483], loss: 0.2811
 Epoch [4/10], Step[160/483], loss: 0.4381
 Epoch [4/10], Step[170/483], loss: 0.3558
 Epoch [4/10], Step[180/483], loss: 0.2861
 Epoch [4/10], Step[190/483], loss: 0.4377
 Epoch [4/10], Step[200/483], loss: 0.3968
 Epoch [4/10], Step[210/483], loss: 0.3454
 Epoch [4/10], Step[220/483], loss: 0.4452
 Epoch [4/10], Step[230/483], loss: 0.3687
 Epoch [4/10], Step[240/483], loss: 0.3352
 Epoch [4/10], Step[250/483], loss: 0.3561
 Epoch [4/10], Step[260/483], loss: 0.2974
 Epoch [4/10], Step[270/483], loss: 0.3323
 Epoch [4/10], Step[280/483], loss: 0.4115
 Epoch [4/10], Step[290/483], loss: 0.3311
 Epoch [4/10], Step[300/483], loss: 0.2831
 Epoch [4/10], Step[310/483], loss: 0.4237
 Epoch [4/10], Step[320/483], loss: 0.3051
 Epoch [4/10], Step[330/483], loss: 0.3893
 Epoch [4/10], Step[340/483], loss: 0.2491
 Epoch [4/10], Step[350/483], loss: 0.3856
 Epoch [4/10], Step[360/483], loss: 0.4428
 Epoch [4/10], Step[370/483], loss: 0.4650
 Epoch [4/10], Step[380/483], loss: 0.3260
 Epoch [4/10], Step[390/483], loss: 0.3397
 Epoch [4/10], Step[400/483], loss: 0.3375
 Epoch [4/10], Step[410/483], loss: 0.3122
 Epoch [4/10], Step[420/483], loss: 0.3461
 Epoch [4/10], Step[430/483], loss: 0.3523
 Epoch [4/10], Step[440/483], loss: 0.3650
 Epoch [4/10], Step[450/483], loss: 0.2759
 Epoch [4/10], Step[460/483], loss: 0.4349
 Epoch [4/10], Step[470/483], loss: 0.3498
 Epoch [4/10], Step[480/483], loss: 0.3222
 ====> Epoch 4: Training loss: 176.9781
 Training Accuracy: 0.813954
 ====> Epoch 4: Validation loss: 23.2212
 Validation Accuracy: 0.795000
 Epoch [5/10], Step[0/483], loss: 0.2995
 Epoch [5/10], Step[10/483], loss: 0.2697
 Epoch [5/10], Step[20/483], loss: 0.3030
 Epoch [5/10], Step[30/483], loss: 0.3048
 Epoch [5/10], Step[40/483], loss: 0.2106
 Epoch [5/10], Step[50/483], loss: 0.2838
 Epoch [5/10], Step[60/483], loss: 0.2862
 Epoch [5/10], Step[70/483], loss: 0.2705
 Epoch [5/10], Step[80/483], loss: 0.3442
 Epoch [5/10], Step[90/483], loss: 0.2936
 Epoch [5/10], Step[100/483], loss: 0.3850
 Epoch [5/10], Step[110/483], loss: 0.3957
 Epoch [5/10], Step[120/483], loss: 0.2708
 Epoch [5/10], Step[130/483], loss: 0.2864
 Epoch [5/10], Step[140/483], loss: 0.2831
 Epoch [5/10], Step[150/483], loss: 0.3402
 Epoch [5/10], Step[160/483], loss: 0.3922
 Epoch [5/10], Step[170/483], loss: 0.2622
 Epoch [5/10], Step[180/483], loss: 0.2672
 Epoch [5/10], Step[190/483], loss: 0.4090
 Epoch [5/10], Step[200/483], loss: 0.4887
 Epoch [5/10], Step[210/483], loss: 0.2557
 Epoch [5/10], Step[220/483], loss: 0.3299
 Epoch [5/10], Step[230/483], loss: 0.3409
 Epoch [5/10], Step[240/483], loss: 0.3109
 Epoch [5/10], Step[250/483], loss: 0.3760
 Epoch [5/10], Step[260/483], loss: 0.2364
 Epoch [5/10], Step[270/483], loss: 0.2246
 Epoch [5/10], Step[280/483], loss: 0.4023
 Epoch [5/10], Step[290/483], loss: 0.3819
 Epoch [5/10], Step[300/483], loss: 0.3024
 Epoch [5/10], Step[310/483], loss: 0.4145
 Epoch [5/10], Step[320/483], loss: 0.3753
 Epoch [5/10], Step[330/483], loss: 0.3610
 Epoch [5/10], Step[340/483], loss: 0.2645
 Epoch [5/10], Step[350/483], loss: 0.3930
 Epoch [5/10], Step[360/483], loss: 0.2878
 Epoch [5/10], Step[370/483], loss: 0.2553
 Epoch [5/10], Step[380/483], loss: 0.3217
 Epoch [5/10], Step[390/483], loss: 0.3281
 Epoch [5/10], Step[400/483], loss: 0.3477
 Epoch [5/10], Step[410/483], loss: 0.2783
 Epoch [5/10], Step[420/483], loss: 0.3529
 Epoch [5/10], Step[430/483], loss: 0.2619
 Epoch [5/10], Step[440/483], loss: 0.3381
 Epoch [5/10], Step[450/483], loss: 0.2943
 Epoch [5/10], Step[460/483], loss: 0.3672
 Epoch [5/10], Step[470/483], loss: 0.3901
 Epoch [5/10], Step[480/483], loss: 0.2406
 ====> Epoch 5: Training loss: 159.3637
 Training Accuracy: 0.830021
 ====> Epoch 5: Validation loss: 19.2676
 Validation Accuracy: 0.834333
 Epoch [6/10], Step[0/483], loss: 0.3357
 Epoch [6/10], Step[10/483], loss: 0.2534
 Epoch [6/10], Step[20/483], loss: 0.4193
 Epoch [6/10], Step[30/483], loss: 0.3628
 Epoch [6/10], Step[40/483], loss: 0.3517
 Epoch [6/10], Step[50/483], loss: 0.3256
 Epoch [6/10], Step[60/483], loss: 0.3533
 Epoch [6/10], Step[70/483], loss: 0.3648
 Epoch [6/10], Step[80/483], loss: 0.2229
 Epoch [6/10], Step[90/483], loss: 0.3062
 Epoch [6/10], Step[100/483], loss: 0.3338
 Epoch [6/10], Step[110/483], loss: 0.2899
 Epoch [6/10], Step[120/483], loss: 0.2703
 Epoch [6/10], Step[130/483], loss: 0.4106
 Epoch [6/10], Step[140/483], loss: 0.2632
 Epoch [6/10], Step[150/483], loss: 0.2293
 Epoch [6/10], Step[160/483], loss: 0.2553
 Epoch [6/10], Step[170/483], loss: 0.3271
 Epoch [6/10], Step[180/483], loss: 0.2893
 Epoch [6/10], Step[190/483], loss: 0.2783
 Epoch [6/10], Step[200/483], loss: 0.3929
 Epoch [6/10], Step[210/483], loss: 0.1881
 Epoch [6/10], Step[220/483], loss: 0.3673
 Epoch [6/10], Step[230/483], loss: 0.3689
 Epoch [6/10], Step[240/483], loss: 0.3728
 Epoch [6/10], Step[250/483], loss: 0.3355
 Epoch [6/10], Step[260/483], loss: 0.1983
 Epoch [6/10], Step[270/483], loss: 0.2018
 Epoch [6/10], Step[280/483], loss: 0.3296
 Epoch [6/10], Step[290/483], loss: 0.3965
 Epoch [6/10], Step[300/483], loss: 0.2100
 Epoch [6/10], Step[310/483], loss: 0.3303
 Epoch [6/10], Step[320/483], loss: 0.2873
 Epoch [6/10], Step[330/483], loss: 0.3096
 Epoch [6/10], Step[340/483], loss: 0.2102
 Epoch [6/10], Step[350/483], loss: 0.4003
 Epoch [6/10], Step[360/483], loss: 0.3227
 Epoch [6/10], Step[370/483], loss: 0.2987
 Epoch [6/10], Step[380/483], loss: 0.2936
 Epoch [6/10], Step[390/483], loss: 0.2904
 Epoch [6/10], Step[400/483], loss: 0.4722
 Epoch [6/10], Step[410/483], loss: 0.2371
 Epoch [6/10], Step[420/483], loss: 0.3859
 Epoch [6/10], Step[430/483], loss: 0.2767
 Epoch [6/10], Step[440/483], loss: 0.2898
 Epoch [6/10], Step[450/483], loss: 0.2485
 Epoch [6/10], Step[460/483], loss: 0.3677
 Epoch [6/10], Step[470/483], loss: 0.3535
 Epoch [6/10], Step[480/483], loss: 0.2957
 ====> Epoch 6: Training loss: 148.4533
 Training Accuracy: 0.842402
 ====> Epoch 6: Validation loss: 20.1083
 Validation Accuracy: 0.836167
 Epoch [7/10], Step[0/483], loss: 0.3865
 Epoch [7/10], Step[10/483], loss: 0.2838
 Epoch [7/10], Step[20/483], loss: 0.2992
 Epoch [7/10], Step[30/483], loss: 0.2168
 Epoch [7/10], Step[40/483], loss: 0.2711
 Epoch [7/10], Step[50/483], loss: 0.2472
 Epoch [7/10], Step[60/483], loss: 0.3259
 Epoch [7/10], Step[70/483], loss: 0.1878
 Epoch [7/10], Step[80/483], loss: 0.2544
 Epoch [7/10], Step[90/483], loss: 0.2879
 Epoch [7/10], Step[100/483], loss: 0.2915
 Epoch [7/10], Step[110/483], loss: 0.3823
 Epoch [7/10], Step[120/483], loss: 0.3051
 Epoch [7/10], Step[130/483], loss: 0.1779
 Epoch [7/10], Step[140/483], loss: 0.1887
 Epoch [7/10], Step[150/483], loss: 0.3246
 Epoch [7/10], Step[160/483], loss: 0.2403
 Epoch [7/10], Step[170/483], loss: 0.1308
 Epoch [7/10], Step[180/483], loss: 0.1944
 Epoch [7/10], Step[190/483], loss: 0.2786
 Epoch [7/10], Step[200/483], loss: 0.4332
 Epoch [7/10], Step[210/483], loss: 0.2433
 Epoch [7/10], Step[220/483], loss: 0.2980
 Epoch [7/10], Step[230/483], loss: 0.2916
 Epoch [7/10], Step[240/483], loss: 0.2571
 Epoch [7/10], Step[250/483], loss: 0.3507
 Epoch [7/10], Step[260/483], loss: 0.2204
 Epoch [7/10], Step[270/483], loss: 0.2285
 Epoch [7/10], Step[280/483], loss: 0.4654
 Epoch [7/10], Step[290/483], loss: 0.3081
 Epoch [7/10], Step[300/483], loss: 0.2581
 Epoch [7/10], Step[310/483], loss: 0.3467
 Epoch [7/10], Step[320/483], loss: 0.2353
 Epoch [7/10], Step[330/483], loss: 0.3013
 Epoch [7/10], Step[340/483], loss: 0.2184
 Epoch [7/10], Step[350/483], loss: 0.3829
 Epoch [7/10], Step[360/483], loss: 0.2581
 Epoch [7/10], Step[370/483], loss: 0.2288
 Epoch [7/10], Step[380/483], loss: 0.3091
 Epoch [7/10], Step[390/483], loss: 0.4037
 Epoch [7/10], Step[400/483], loss: 0.3156
 Epoch [7/10], Step[410/483], loss: 0.3263
 Epoch [7/10], Step[420/483], loss: 0.2752
 Epoch [7/10], Step[430/483], loss: 0.2673
 Epoch [7/10], Step[440/483], loss: 0.3331
 Epoch [7/10], Step[450/483], loss: 0.2305
 Epoch [7/10], Step[460/483], loss: 0.4344
 Epoch [7/10], Step[470/483], loss: 0.3585
 Epoch [7/10], Step[480/483], loss: 0.2467
 ====> Epoch 7: Training loss: 142.9184
 Training Accuracy: 0.850041
 ====> Epoch 7: Validation loss: 18.5781
 Validation Accuracy: 0.847333
 Epoch [8/10], Step[0/483], loss: 0.2962
 Epoch [8/10], Step[10/483], loss: 0.2267
 Epoch [8/10], Step[20/483], loss: 0.2071
 Epoch [8/10], Step[30/483], loss: 0.3531
 Epoch [8/10], Step[40/483], loss: 0.2605
 Epoch [8/10], Step[50/483], loss: 0.2827
 Epoch [8/10], Step[60/483], loss: 0.2916
 Epoch [8/10], Step[70/483], loss: 0.1699
 Epoch [8/10], Step[80/483], loss: 0.3387
 Epoch [8/10], Step[90/483], loss: 0.2332
 Epoch [8/10], Step[100/483], loss: 0.3636
 Epoch [8/10], Step[110/483], loss: 0.3909
 Epoch [8/10], Step[120/483], loss: 0.1907
 Epoch [8/10], Step[130/483], loss: 0.2809
 Epoch [8/10], Step[140/483], loss: 0.2433
 Epoch [8/10], Step[150/483], loss: 0.3598
 Epoch [8/10], Step[160/483], loss: 0.3002
 Epoch [8/10], Step[170/483], loss: 0.2654
 Epoch [8/10], Step[180/483], loss: 0.2811
 Epoch [8/10], Step[190/483], loss: 0.2533
 Epoch [8/10], Step[200/483], loss: 0.3257
 Epoch [8/10], Step[210/483], loss: 0.2797
 Epoch [8/10], Step[220/483], loss: 0.3312
 Epoch [8/10], Step[230/483], loss: 0.3553
 Epoch [8/10], Step[240/483], loss: 0.2421
 Epoch [8/10], Step[250/483], loss: 0.3467
 Epoch [8/10], Step[260/483], loss: 0.2028
 Epoch [8/10], Step[270/483], loss: 0.2549
 Epoch [8/10], Step[280/483], loss: 0.2729
 Epoch [8/10], Step[290/483], loss: 0.3332
 Epoch [8/10], Step[300/483], loss: 0.2066
 Epoch [8/10], Step[310/483], loss: 0.2761
 Epoch [8/10], Step[320/483], loss: 0.3309
 Epoch [8/10], Step[330/483], loss: 0.3488
 Epoch [8/10], Step[340/483], loss: 0.1902
 Epoch [8/10], Step[350/483], loss: 0.3426
 Epoch [8/10], Step[360/483], loss: 0.3387
 Epoch [8/10], Step[370/483], loss: 0.1975
 Epoch [8/10], Step[380/483], loss: 0.2420
 Epoch [8/10], Step[390/483], loss: 0.3246
 Epoch [8/10], Step[400/483], loss: 0.3465
 Epoch [8/10], Step[410/483], loss: 0.1851
 Epoch [8/10], Step[420/483], loss: 0.2633
 Epoch [8/10], Step[430/483], loss: 0.2240
 Epoch [8/10], Step[440/483], loss: 0.3038
 Epoch [8/10], Step[450/483], loss: 0.2563
 Epoch [8/10], Step[460/483], loss: 0.3758
 Epoch [8/10], Step[470/483], loss: 0.3058
 Epoch [8/10], Step[480/483], loss: 0.2789
 ====> Epoch 8: Training loss: 135.4114
 Training Accuracy: 0.856501
 ====> Epoch 8: Validation loss: 19.1260
 Validation Accuracy: 0.843833
 Epoch [9/10], Step[0/483], loss: 0.3115
 Epoch [9/10], Step[10/483], loss: 0.2279
 Epoch [9/10], Step[20/483], loss: 0.2725
 Epoch [9/10], Step[30/483], loss: 0.3575
 Epoch [9/10], Step[40/483], loss: 0.3037
 Epoch [9/10], Step[50/483], loss: 0.1923
 Epoch [9/10], Step[60/483], loss: 0.4290
 Epoch [9/10], Step[70/483], loss: 0.2593
 Epoch [9/10], Step[80/483], loss: 0.2541
 Epoch [9/10], Step[90/483], loss: 0.2254
 Epoch [9/10], Step[100/483], loss: 0.3570
 Epoch [9/10], Step[110/483], loss: 0.4338
 Epoch [9/10], Step[120/483], loss: 0.2411
 Epoch [9/10], Step[130/483], loss: 0.2509
 Epoch [9/10], Step[140/483], loss: 0.2913
 Epoch [9/10], Step[150/483], loss: 0.2159
 Epoch [9/10], Step[160/483], loss: 0.2805
 Epoch [9/10], Step[170/483], loss: 0.1638
 Epoch [9/10], Step[180/483], loss: 0.2951
 Epoch [9/10], Step[190/483], loss: 0.2724
 Epoch [9/10], Step[200/483], loss: 0.3871
 Epoch [9/10], Step[210/483], loss: 0.2392
 Epoch [9/10], Step[220/483], loss: 0.2902
 Epoch [9/10], Step[230/483], loss: 0.3236
 Epoch [9/10], Step[240/483], loss: 0.2655
 Epoch [9/10], Step[250/483], loss: 0.3061
 Epoch [9/10], Step[260/483], loss: 0.1824
 Epoch [9/10], Step[270/483], loss: 0.2377
 Epoch [9/10], Step[280/483], loss: 0.2862
 Epoch [9/10], Step[290/483], loss: 0.2795
 Epoch [9/10], Step[300/483], loss: 0.2336
 Epoch [9/10], Step[310/483], loss: 0.3495
 Epoch [9/10], Step[320/483], loss: 0.3873
 Epoch [9/10], Step[330/483], loss: 0.3912
 Epoch [9/10], Step[340/483], loss: 0.2040
 Epoch [9/10], Step[350/483], loss: 0.2623
 Epoch [9/10], Step[360/483], loss: 0.2697
 Epoch [9/10], Step[370/483], loss: 0.2907
 Epoch [9/10], Step[380/483], loss: 0.3014
 Epoch [9/10], Step[390/483], loss: 0.2136
 Epoch [9/10], Step[400/483], loss: 0.4700
 Epoch [9/10], Step[410/483], loss: 0.2384
 Epoch [9/10], Step[420/483], loss: 0.2989
 Epoch [9/10], Step[430/483], loss: 0.2352
 Epoch [9/10], Step[440/483], loss: 0.3605
 Epoch [9/10], Step[450/483], loss: 0.3284
 Epoch [9/10], Step[460/483], loss: 0.2004
 Epoch [9/10], Step[470/483], loss: 0.2199
 Epoch [9/10], Step[480/483], loss: 0.1636
 ====> Epoch 9: Training loss: 133.3291
 Training Accuracy: 0.859482
 ====> Epoch 9: Validation loss: 18.5499
 Validation Accuracy: 0.848500
 Epoch [10/10], Step[0/483], loss: 0.3534
 Epoch [10/10], Step[10/483], loss: 0.2286
 Epoch [10/10], Step[20/483], loss: 0.1998
 Epoch [10/10], Step[30/483], loss: 0.3378
 Epoch [10/10], Step[40/483], loss: 0.2319
 Epoch [10/10], Step[50/483], loss: 0.3805
 Epoch [10/10], Step[60/483], loss: 0.3656
 Epoch [10/10], Step[70/483], loss: 0.2369
 Epoch [10/10], Step[80/483], loss: 0.2263
 Epoch [10/10], Step[90/483], loss: 0.3138
 Epoch [10/10], Step[100/483], loss: 0.2558
 Epoch [10/10], Step[110/483], loss: 0.1889
 Epoch [10/10], Step[120/483], loss: 0.1825
 Epoch [10/10], Step[130/483], loss: 0.2127
 Epoch [10/10], Step[140/483], loss: 0.2982
 Epoch [10/10], Step[150/483], loss: 0.3627
 Epoch [10/10], Step[160/483], loss: 0.2881
 Epoch [10/10], Step[170/483], loss: 0.2133
 Epoch [10/10], Step[180/483], loss: 0.3479
 Epoch [10/10], Step[190/483], loss: 0.2989
 Epoch [10/10], Step[200/483], loss: 0.2760
 Epoch [10/10], Step[210/483], loss: 0.1444
 Epoch [10/10], Step[220/483], loss: 0.3428
 Epoch [10/10], Step[230/483], loss: 0.2792
 Epoch [10/10], Step[240/483], loss: 0.1988
 Epoch [10/10], Step[250/483], loss: 0.2261
 Epoch [10/10], Step[260/483], loss: 0.2058
 Epoch [10/10], Step[270/483], loss: 0.1697
 Epoch [10/10], Step[280/483], loss: 0.2375
 Epoch [10/10], Step[290/483], loss: 0.2635
 Epoch [10/10], Step[300/483], loss: 0.1941
 Epoch [10/10], Step[310/483], loss: 0.2560
 Epoch [10/10], Step[320/483], loss: 0.2756
 Epoch [10/10], Step[330/483], loss: 0.4251
 Epoch [10/10], Step[340/483], loss: 0.2370
 Epoch [10/10], Step[350/483], loss: 0.3073
 Epoch [10/10], Step[360/483], loss: 0.2227
 Epoch [10/10], Step[370/483], loss: 0.2020
 Epoch [10/10], Step[380/483], loss: 0.2800
 Epoch [10/10], Step[390/483], loss: 0.2725
 Epoch [10/10], Step[400/483], loss: 0.3222
 Epoch [10/10], Step[410/483], loss: 0.1727
 Epoch [10/10], Step[420/483], loss: 0.2450
 Epoch [10/10], Step[430/483], loss: 0.3133
 Epoch [10/10], Step[440/483], loss: 0.2950
 Epoch [10/10], Step[450/483], loss: 0.2213
 Epoch [10/10], Step[460/483], loss: 0.2833
 Epoch [10/10], Step[470/483], loss: 0.2553
 Epoch [10/10], Step[480/483], loss: 0.1583
 ====> Epoch 10: Training loss: 129.8638
 Training Accuracy: 0.861636
 ====> Epoch 10: Validation loss: 17.0231
 Validation Accuracy: 0.853833
 Training Speaker0...
 Epoch [1/10], Step[0/483], loss: 7.0413
 Epoch [1/10], Step[10/483], loss: 2.9167
 Epoch [1/10], Step[20/483], loss: 2.2907
 Epoch [1/10], Step[30/483], loss: 2.0013
 Epoch [1/10], Step[40/483], loss: 1.8976
 Epoch [1/10], Step[50/483], loss: 1.9493
 Epoch [1/10], Step[60/483], loss: 1.9334
 Epoch [1/10], Step[70/483], loss: 1.6763
 Epoch [1/10], Step[80/483], loss: 1.8409
 Epoch [1/10], Step[90/483], loss: 1.2901
 Epoch [1/10], Step[100/483], loss: 1.2616
 Epoch [1/10], Step[110/483], loss: 1.4467
 Epoch [1/10], Step[120/483], loss: 1.5312
 Epoch [1/10], Step[130/483], loss: 1.2387
 Epoch [1/10], Step[140/483], loss: 1.4728
 Epoch [1/10], Step[150/483], loss: 1.4966
 Epoch [1/10], Step[160/483], loss: 1.6278
 Epoch [1/10], Step[170/483], loss: 1.0832
 Epoch [1/10], Step[180/483], loss: 1.4965
 Epoch [1/10], Step[190/483], loss: 1.4352
 Epoch [1/10], Step[200/483], loss: 1.0218
 Epoch [1/10], Step[210/483], loss: 1.2838
 Epoch [1/10], Step[220/483], loss: 1.1027
 Epoch [1/10], Step[230/483], loss: 1.0326
 Epoch [1/10], Step[240/483], loss: 1.2930
 Epoch [1/10], Step[250/483], loss: 1.2758
 Epoch [1/10], Step[260/483], loss: 0.8378
 Epoch [1/10], Step[270/483], loss: 1.2646
 Epoch [1/10], Step[280/483], loss: 1.0374
 Epoch [1/10], Step[290/483], loss: 0.9023
 Epoch [1/10], Step[300/483], loss: 1.2797
 Epoch [1/10], Step[310/483], loss: 1.2448
 Epoch [1/10], Step[320/483], loss: 1.3338
 Epoch [1/10], Step[330/483], loss: 1.2015
 Epoch [1/10], Step[340/483], loss: 1.2876
 Epoch [1/10], Step[350/483], loss: 1.2306
 Epoch [1/10], Step[360/483], loss: 0.9092
 Epoch [1/10], Step[370/483], loss: 0.7863
 Epoch [1/10], Step[380/483], loss: 1.0693
 Epoch [1/10], Step[390/483], loss: 1.1966
 Epoch [1/10], Step[400/483], loss: 1.1533
 Epoch [1/10], Step[410/483], loss: 0.8977
 Epoch [1/10], Step[420/483], loss: 1.1038
 Epoch [1/10], Step[430/483], loss: 1.0742
 Epoch [1/10], Step[440/483], loss: 1.1514
 Epoch [1/10], Step[450/483], loss: 0.9439
 Epoch [1/10], Step[460/483], loss: 1.2367
 Epoch [1/10], Step[470/483], loss: 1.3750
 Epoch [1/10], Step[480/483], loss: 0.7652
 ====> Epoch 1: Training loss: 679.3653
 ====> Epoch 1: Validation loss: 63.7592
 Epoch [2/10], Step[0/483], loss: 0.8937
 Epoch [2/10], Step[10/483], loss: 1.0525
 Epoch [2/10], Step[20/483], loss: 1.1136
 Epoch [2/10], Step[30/483], loss: 1.0359
 Epoch [2/10], Step[40/483], loss: 1.0788
 Epoch [2/10], Step[50/483], loss: 1.1835
 Epoch [2/10], Step[60/483], loss: 1.2772
 Epoch [2/10], Step[70/483], loss: 1.1157
 Epoch [2/10], Step[80/483], loss: 1.3196
 Epoch [2/10], Step[90/483], loss: 0.8579
 Epoch [2/10], Step[100/483], loss: 0.8692
 Epoch [2/10], Step[110/483], loss: 1.0496
 Epoch [2/10], Step[120/483], loss: 1.1374
 Epoch [2/10], Step[130/483], loss: 0.9294
 Epoch [2/10], Step[140/483], loss: 1.0851
 Epoch [2/10], Step[150/483], loss: 1.0847
 Epoch [2/10], Step[160/483], loss: 1.2330
 Epoch [2/10], Step[170/483], loss: 0.8179
 Epoch [2/10], Step[180/483], loss: 1.1580
 Epoch [2/10], Step[190/483], loss: 1.1154
 Epoch [2/10], Step[200/483], loss: 0.8089
 Epoch [2/10], Step[210/483], loss: 0.9966
 Epoch [2/10], Step[220/483], loss: 0.8865
 Epoch [2/10], Step[230/483], loss: 0.7796
 Epoch [2/10], Step[240/483], loss: 1.0229
 Epoch [2/10], Step[250/483], loss: 1.0296
 Epoch [2/10], Step[260/483], loss: 0.6636
 Epoch [2/10], Step[270/483], loss: 0.9782
 Epoch [2/10], Step[280/483], loss: 0.8631
 Epoch [2/10], Step[290/483], loss: 0.7063
 Epoch [2/10], Step[300/483], loss: 1.0292
 Epoch [2/10], Step[310/483], loss: 0.9940
 Epoch [2/10], Step[320/483], loss: 1.0744
 Epoch [2/10], Step[330/483], loss: 0.9806
 Epoch [2/10], Step[340/483], loss: 1.0110
 Epoch [2/10], Step[350/483], loss: 0.9823
 Epoch [2/10], Step[360/483], loss: 0.7430
 Epoch [2/10], Step[370/483], loss: 0.6518
 Epoch [2/10], Step[380/483], loss: 0.8929
 Epoch [2/10], Step[390/483], loss: 0.9793
 Epoch [2/10], Step[400/483], loss: 0.9352
 Epoch [2/10], Step[410/483], loss: 0.7562
 Epoch [2/10], Step[420/483], loss: 0.9015
 Epoch [2/10], Step[430/483], loss: 0.9232
 Epoch [2/10], Step[440/483], loss: 0.9418
 Epoch [2/10], Step[450/483], loss: 0.7622
 Epoch [2/10], Step[460/483], loss: 1.0414
 Epoch [2/10], Step[470/483], loss: 1.0756
 Epoch [2/10], Step[480/483], loss: 0.6303
 ====> Epoch 2: Training loss: 478.9583
 ====> Epoch 2: Validation loss: 57.5058
 Epoch [3/10], Step[0/483], loss: 0.7816
 Epoch [3/10], Step[10/483], loss: 0.9215
 Epoch [3/10], Step[20/483], loss: 0.9997
 Epoch [3/10], Step[30/483], loss: 0.9319
 Epoch [3/10], Step[40/483], loss: 0.9603
 Epoch [3/10], Step[50/483], loss: 1.0633
 Epoch [3/10], Step[60/483], loss: 1.1326
 Epoch [3/10], Step[70/483], loss: 1.0294
 Epoch [3/10], Step[80/483], loss: 1.1817
 Epoch [3/10], Step[90/483], loss: 0.7793
 Epoch [3/10], Step[100/483], loss: 0.7997
 Epoch [3/10], Step[110/483], loss: 0.9507
 Epoch [3/10], Step[120/483], loss: 1.0232
 Epoch [3/10], Step[130/483], loss: 0.8447
 Epoch [3/10], Step[140/483], loss: 0.9716
 Epoch [3/10], Step[150/483], loss: 0.9523
 Epoch [3/10], Step[160/483], loss: 1.1223
 Epoch [3/10], Step[170/483], loss: 0.7356
 Epoch [3/10], Step[180/483], loss: 1.0486
 Epoch [3/10], Step[190/483], loss: 1.0339
 Epoch [3/10], Step[200/483], loss: 0.7451
 Epoch [3/10], Step[210/483], loss: 0.9183
 Epoch [3/10], Step[220/483], loss: 0.8113
 Epoch [3/10], Step[230/483], loss: 0.7292
 Epoch [3/10], Step[240/483], loss: 0.9376
 Epoch [3/10], Step[250/483], loss: 0.9672
 Epoch [3/10], Step[260/483], loss: 0.6159
 Epoch [3/10], Step[270/483], loss: 0.8986
 Epoch [3/10], Step[280/483], loss: 0.8058
 Epoch [3/10], Step[290/483], loss: 0.6620
 Epoch [3/10], Step[300/483], loss: 0.9536
 Epoch [3/10], Step[310/483], loss: 0.9263
 Epoch [3/10], Step[320/483], loss: 1.0076
 Epoch [3/10], Step[330/483], loss: 0.9049
 Epoch [3/10], Step[340/483], loss: 0.9338
 Epoch [3/10], Step[350/483], loss: 0.8954
 Epoch [3/10], Step[360/483], loss: 0.6805
 Epoch [3/10], Step[370/483], loss: 0.6049
 Epoch [3/10], Step[380/483], loss: 0.8033
 Epoch [3/10], Step[390/483], loss: 0.9022
 Epoch [3/10], Step[400/483], loss: 0.9090
 Epoch [3/10], Step[410/483], loss: 0.6970
 Epoch [3/10], Step[420/483], loss: 0.8258
 Epoch [3/10], Step[430/483], loss: 0.8557
 Epoch [3/10], Step[440/483], loss: 0.8653
 Epoch [3/10], Step[450/483], loss: 0.7183
 Epoch [3/10], Step[460/483], loss: 0.9825
 Epoch [3/10], Step[470/483], loss: 0.9949
 Epoch [3/10], Step[480/483], loss: 0.5872
 ====> Epoch 3: Training loss: 437.7650
 ====> Epoch 3: Validation loss: 55.1694
 Epoch [4/10], Step[0/483], loss: 0.7207
 Epoch [4/10], Step[10/483], loss: 0.8788
 Epoch [4/10], Step[20/483], loss: 0.9286
 Epoch [4/10], Step[30/483], loss: 0.8652
 Epoch [4/10], Step[40/483], loss: 0.8885
 Epoch [4/10], Step[50/483], loss: 0.9833
 Epoch [4/10], Step[60/483], loss: 1.0518
 Epoch [4/10], Step[70/483], loss: 0.9747
 Epoch [4/10], Step[80/483], loss: 1.1094
 Epoch [4/10], Step[90/483], loss: 0.7441
 Epoch [4/10], Step[100/483], loss: 0.7584
 Epoch [4/10], Step[110/483], loss: 0.9014
 Epoch [4/10], Step[120/483], loss: 0.9730
 Epoch [4/10], Step[130/483], loss: 0.8002
 Epoch [4/10], Step[140/483], loss: 0.9043
 Epoch [4/10], Step[150/483], loss: 0.9032
 Epoch [4/10], Step[160/483], loss: 1.0588
 Epoch [4/10], Step[170/483], loss: 0.6978
 Epoch [4/10], Step[180/483], loss: 0.9972
 Epoch [4/10], Step[190/483], loss: 0.9904
 Epoch [4/10], Step[200/483], loss: 0.7177
 Epoch [4/10], Step[210/483], loss: 0.8696
 Epoch [4/10], Step[220/483], loss: 0.7707
 Epoch [4/10], Step[230/483], loss: 0.7089
 Epoch [4/10], Step[240/483], loss: 0.8759
 Epoch [4/10], Step[250/483], loss: 0.9278
 Epoch [4/10], Step[260/483], loss: 0.5801
 Epoch [4/10], Step[270/483], loss: 0.8510
 Epoch [4/10], Step[280/483], loss: 0.7684
 Epoch [4/10], Step[290/483], loss: 0.6346
 Epoch [4/10], Step[300/483], loss: 0.8849
 Epoch [4/10], Step[310/483], loss: 0.8815
 Epoch [4/10], Step[320/483], loss: 0.9566
 Epoch [4/10], Step[330/483], loss: 0.8670
 Epoch [4/10], Step[340/483], loss: 0.8882
 Epoch [4/10], Step[350/483], loss: 0.8524
 Epoch [4/10], Step[360/483], loss: 0.6550
 Epoch [4/10], Step[370/483], loss: 0.5715
 Epoch [4/10], Step[380/483], loss: 0.7653
 Epoch [4/10], Step[390/483], loss: 0.8840
 Epoch [4/10], Step[400/483], loss: 0.8717
 Epoch [4/10], Step[410/483], loss: 0.6778
 Epoch [4/10], Step[420/483], loss: 0.7903
 Epoch [4/10], Step[430/483], loss: 0.8156
 Epoch [4/10], Step[440/483], loss: 0.8226
 Epoch [4/10], Step[450/483], loss: 0.6902
 Epoch [4/10], Step[460/483], loss: 0.9456
 Epoch [4/10], Step[470/483], loss: 0.9539
 Epoch [4/10], Step[480/483], loss: 0.5643
 ====> Epoch 4: Training loss: 414.8452
 ====> Epoch 4: Validation loss: 54.4950
 Epoch [5/10], Step[0/483], loss: 0.6994
 Epoch [5/10], Step[10/483], loss: 0.8529
 Epoch [5/10], Step[20/483], loss: 0.8730
 Epoch [5/10], Step[30/483], loss: 0.8333
 Epoch [5/10], Step[40/483], loss: 0.8654
 Epoch [5/10], Step[50/483], loss: 0.9316
 Epoch [5/10], Step[60/483], loss: 1.0131
 Epoch [5/10], Step[70/483], loss: 0.9273
 Epoch [5/10], Step[80/483], loss: 1.0493
 Epoch [5/10], Step[90/483], loss: 0.7087
 Epoch [5/10], Step[100/483], loss: 0.7225
 Epoch [5/10], Step[110/483], loss: 0.8726
 Epoch [5/10], Step[120/483], loss: 0.9192
 Epoch [5/10], Step[130/483], loss: 0.7520
 Epoch [5/10], Step[140/483], loss: 0.8809
 Epoch [5/10], Step[150/483], loss: 0.8723
 Epoch [5/10], Step[160/483], loss: 1.0134
 Epoch [5/10], Step[170/483], loss: 0.6680
 Epoch [5/10], Step[180/483], loss: 0.9569
 Epoch [5/10], Step[190/483], loss: 0.9614
 Epoch [5/10], Step[200/483], loss: 0.6977
 Epoch [5/10], Step[210/483], loss: 0.8387
 Epoch [5/10], Step[220/483], loss: 0.7369
 Epoch [5/10], Step[230/483], loss: 0.6985
 Epoch [5/10], Step[240/483], loss: 0.8488
 Epoch [5/10], Step[250/483], loss: 0.8947
 Epoch [5/10], Step[260/483], loss: 0.5814
 Epoch [5/10], Step[270/483], loss: 0.8158
 Epoch [5/10], Step[280/483], loss: 0.7537
 Epoch [5/10], Step[290/483], loss: 0.6136
 Epoch [5/10], Step[300/483], loss: 0.8621
 Epoch [5/10], Step[310/483], loss: 0.8699
 Epoch [5/10], Step[320/483], loss: 0.8963
 Epoch [5/10], Step[330/483], loss: 0.8410
 Epoch [5/10], Step[340/483], loss: 0.8432
 Epoch [5/10], Step[350/483], loss: 0.8219
 Epoch [5/10], Step[360/483], loss: 0.6342
 Epoch [5/10], Step[370/483], loss: 0.5706
 Epoch [5/10], Step[380/483], loss: 0.7523
 Epoch [5/10], Step[390/483], loss: 0.8440
 Epoch [5/10], Step[400/483], loss: 0.8175
 Epoch [5/10], Step[410/483], loss: 0.6487
 Epoch [5/10], Step[420/483], loss: 0.7855
 Epoch [5/10], Step[430/483], loss: 0.7799
 Epoch [5/10], Step[440/483], loss: 0.7904
 Epoch [5/10], Step[450/483], loss: 0.6735
 Epoch [5/10], Step[460/483], loss: 0.9133
 Epoch [5/10], Step[470/483], loss: 0.9343
 Epoch [5/10], Step[480/483], loss: 0.5463
 ====> Epoch 5: Training loss: 400.8916
 ====> Epoch 5: Validation loss: 54.3078
 Epoch [6/10], Step[0/483], loss: 0.6940
 Epoch [6/10], Step[10/483], loss: 0.8256
 Epoch [6/10], Step[20/483], loss: 0.8708
 Epoch [6/10], Step[30/483], loss: 0.8117
 Epoch [6/10], Step[40/483], loss: 0.8441
 Epoch [6/10], Step[50/483], loss: 0.9008
 Epoch [6/10], Step[60/483], loss: 0.9677
 Epoch [6/10], Step[70/483], loss: 0.9017
 Epoch [6/10], Step[80/483], loss: 1.0147
 Epoch [6/10], Step[90/483], loss: 0.6961
 Epoch [6/10], Step[100/483], loss: 0.7146
 Epoch [6/10], Step[110/483], loss: 0.8597
 Epoch [6/10], Step[120/483], loss: 0.9232
 Epoch [6/10], Step[130/483], loss: 0.7386
 Epoch [6/10], Step[140/483], loss: 0.8782
 Epoch [6/10], Step[150/483], loss: 0.8574
 Epoch [6/10], Step[160/483], loss: 0.9918
 Epoch [6/10], Step[170/483], loss: 0.6531
 Epoch [6/10], Step[180/483], loss: 0.9226
 Epoch [6/10], Step[190/483], loss: 0.9270
 Epoch [6/10], Step[200/483], loss: 0.6660
 Epoch [6/10], Step[210/483], loss: 0.8246
 Epoch [6/10], Step[220/483], loss: 0.7243
 Epoch [6/10], Step[230/483], loss: 0.6759
 Epoch [6/10], Step[240/483], loss: 0.8207
 Epoch [6/10], Step[250/483], loss: 0.8910
 Epoch [6/10], Step[260/483], loss: 0.5602
 Epoch [6/10], Step[270/483], loss: 0.8229
 Epoch [6/10], Step[280/483], loss: 0.7388
 Epoch [6/10], Step[290/483], loss: 0.5974
 Epoch [6/10], Step[300/483], loss: 0.8221
 Epoch [6/10], Step[310/483], loss: 0.8313
 Epoch [6/10], Step[320/483], loss: 0.9010
 Epoch [6/10], Step[330/483], loss: 0.8220
 Epoch [6/10], Step[340/483], loss: 0.8230
 Epoch [6/10], Step[350/483], loss: 0.8063
 Epoch [6/10], Step[360/483], loss: 0.6303
 Epoch [6/10], Step[370/483], loss: 0.5582
 Epoch [6/10], Step[380/483], loss: 0.7394
 Epoch [6/10], Step[390/483], loss: 0.8243
 Epoch [6/10], Step[400/483], loss: 0.8061
 Epoch [6/10], Step[410/483], loss: 0.6524
 Epoch [6/10], Step[420/483], loss: 0.7651
 Epoch [6/10], Step[430/483], loss: 0.7670
 Epoch [6/10], Step[440/483], loss: 0.7814
 Epoch [6/10], Step[450/483], loss: 0.6678
 Epoch [6/10], Step[460/483], loss: 0.8866
 Epoch [6/10], Step[470/483], loss: 0.9218
 Epoch [6/10], Step[480/483], loss: 0.5410
 ====> Epoch 6: Training loss: 391.4550
 ====> Epoch 6: Validation loss: 54.3234
 Epoch [7/10], Step[0/483], loss: 0.6927
 Epoch [7/10], Step[10/483], loss: 0.8116
 Epoch [7/10], Step[20/483], loss: 0.8503
 Epoch [7/10], Step[30/483], loss: 0.7882
 Epoch [7/10], Step[40/483], loss: 0.8364
 Epoch [7/10], Step[50/483], loss: 0.8827
 Epoch [7/10], Step[60/483], loss: 0.9689
 Epoch [7/10], Step[70/483], loss: 0.8852
 Epoch [7/10], Step[80/483], loss: 0.9895
 Epoch [7/10], Step[90/483], loss: 0.6801
 Epoch [7/10], Step[100/483], loss: 0.7119
 Epoch [7/10], Step[110/483], loss: 0.8375
 Epoch [7/10], Step[120/483], loss: 0.8903
 Epoch [7/10], Step[130/483], loss: 0.7471
 Epoch [7/10], Step[140/483], loss: 0.8696
 Epoch [7/10], Step[150/483], loss: 0.8399
 Epoch [7/10], Step[160/483], loss: 0.9408
 Epoch [7/10], Step[170/483], loss: 0.6432
 Epoch [7/10], Step[180/483], loss: 0.8952
 Epoch [7/10], Step[190/483], loss: 0.9025
 Epoch [7/10], Step[200/483], loss: 0.6616
 Epoch [7/10], Step[210/483], loss: 0.8054
 Epoch [7/10], Step[220/483], loss: 0.7224
 Epoch [7/10], Step[230/483], loss: 0.6638
 Epoch [7/10], Step[240/483], loss: 0.7894
 Epoch [7/10], Step[250/483], loss: 0.8745
 Epoch [7/10], Step[260/483], loss: 0.5550
 Epoch [7/10], Step[270/483], loss: 0.8127
 Epoch [7/10], Step[280/483], loss: 0.7367
 Epoch [7/10], Step[290/483], loss: 0.5796
 Epoch [7/10], Step[300/483], loss: 0.8129
 Epoch [7/10], Step[310/483], loss: 0.8300
 Epoch [7/10], Step[320/483], loss: 0.8561
 Epoch [7/10], Step[330/483], loss: 0.8119
 Epoch [7/10], Step[340/483], loss: 0.8036
 Epoch [7/10], Step[350/483], loss: 0.7879
 Epoch [7/10], Step[360/483], loss: 0.6131
 Epoch [7/10], Step[370/483], loss: 0.5590
 Epoch [7/10], Step[380/483], loss: 0.7271
 Epoch [7/10], Step[390/483], loss: 0.8168
 Epoch [7/10], Step[400/483], loss: 0.7850
 Epoch [7/10], Step[410/483], loss: 0.6320
 Epoch [7/10], Step[420/483], loss: 0.7652
 Epoch [7/10], Step[430/483], loss: 0.7597
 Epoch [7/10], Step[440/483], loss: 0.7687
 Epoch [7/10], Step[450/483], loss: 0.6523
 Epoch [7/10], Step[460/483], loss: 0.8768
 Epoch [7/10], Step[470/483], loss: 0.8924
 Epoch [7/10], Step[480/483], loss: 0.5335
 ====> Epoch 7: Training loss: 384.0766
 ====> Epoch 7: Validation loss: 54.1921
 Epoch [8/10], Step[0/483], loss: 0.6622
 Epoch [8/10], Step[10/483], loss: 0.8068
 Epoch [8/10], Step[20/483], loss: 0.8445
 Epoch [8/10], Step[30/483], loss: 0.7776
 Epoch [8/10], Step[40/483], loss: 0.8230
 Epoch [8/10], Step[50/483], loss: 0.8508
 Epoch [8/10], Step[60/483], loss: 0.9302
 Epoch [8/10], Step[70/483], loss: 0.8836
 Epoch [8/10], Step[80/483], loss: 0.9731
 Epoch [8/10], Step[90/483], loss: 0.6693
 Epoch [8/10], Step[100/483], loss: 0.6944
 Epoch [8/10], Step[110/483], loss: 0.8312
 Epoch [8/10], Step[120/483], loss: 0.8697
 Epoch [8/10], Step[130/483], loss: 0.7287
 Epoch [8/10], Step[140/483], loss: 0.8435
 Epoch [8/10], Step[150/483], loss: 0.8293
 Epoch [8/10], Step[160/483], loss: 0.9569
 Epoch [8/10], Step[170/483], loss: 0.6381
 Epoch [8/10], Step[180/483], loss: 0.8802
 Epoch [8/10], Step[190/483], loss: 0.8758
 Epoch [8/10], Step[200/483], loss: 0.6541
 Epoch [8/10], Step[210/483], loss: 0.7990
 Epoch [8/10], Step[220/483], loss: 0.6919
 Epoch [8/10], Step[230/483], loss: 0.6594
 Epoch [8/10], Step[240/483], loss: 0.7687
 Epoch [8/10], Step[250/483], loss: 0.8775
 Epoch [8/10], Step[260/483], loss: 0.5451
 Epoch [8/10], Step[270/483], loss: 0.7791
 Epoch [8/10], Step[280/483], loss: 0.7037
 Epoch [8/10], Step[290/483], loss: 0.5850
 Epoch [8/10], Step[300/483], loss: 0.8135
 Epoch [8/10], Step[310/483], loss: 0.8358
 Epoch [8/10], Step[320/483], loss: 0.8510
 Epoch [8/10], Step[330/483], loss: 0.7950
 Epoch [8/10], Step[340/483], loss: 0.7933
 Epoch [8/10], Step[350/483], loss: 0.7866
 Epoch [8/10], Step[360/483], loss: 0.5981
 Epoch [8/10], Step[370/483], loss: 0.5550
 Epoch [8/10], Step[380/483], loss: 0.7126
 Epoch [8/10], Step[390/483], loss: 0.8014
 Epoch [8/10], Step[400/483], loss: 0.7795
 Epoch [8/10], Step[410/483], loss: 0.6208
 Epoch [8/10], Step[420/483], loss: 0.7427
 Epoch [8/10], Step[430/483], loss: 0.7522
 Epoch [8/10], Step[440/483], loss: 0.7484
 Epoch [8/10], Step[450/483], loss: 0.6338
 Epoch [8/10], Step[460/483], loss: 0.8488
 Epoch [8/10], Step[470/483], loss: 0.8867
 Epoch [8/10], Step[480/483], loss: 0.5281
 ====> Epoch 8: Training loss: 378.3556
 ====> Epoch 8: Validation loss: 54.6117
 Epoch [9/10], Step[0/483], loss: 0.6500
 Epoch [9/10], Step[10/483], loss: 0.7867
 Epoch [9/10], Step[20/483], loss: 0.8184
 Epoch [9/10], Step[30/483], loss: 0.7697
 Epoch [9/10], Step[40/483], loss: 0.7998
 Epoch [9/10], Step[50/483], loss: 0.8422
 Epoch [9/10], Step[60/483], loss: 0.9289
 Epoch [9/10], Step[70/483], loss: 0.8621
 Epoch [9/10], Step[80/483], loss: 0.9473
 Epoch [9/10], Step[90/483], loss: 0.6568
 Epoch [9/10], Step[100/483], loss: 0.6949
 Epoch [9/10], Step[110/483], loss: 0.8392
 Epoch [9/10], Step[120/483], loss: 0.8683
 Epoch [9/10], Step[130/483], loss: 0.7387
 Epoch [9/10], Step[140/483], loss: 0.8471
 Epoch [9/10], Step[150/483], loss: 0.8071
 Epoch [9/10], Step[160/483], loss: 0.9228
 Epoch [9/10], Step[170/483], loss: 0.6290
 Epoch [9/10], Step[180/483], loss: 0.8680
 Epoch [9/10], Step[190/483], loss: 0.8777
 Epoch [9/10], Step[200/483], loss: 0.6419
 Epoch [9/10], Step[210/483], loss: 0.7984
 Epoch [9/10], Step[220/483], loss: 0.6829
 Epoch [9/10], Step[230/483], loss: 0.6643
 Epoch [9/10], Step[240/483], loss: 0.7636
 Epoch [9/10], Step[250/483], loss: 0.8474
 Epoch [9/10], Step[260/483], loss: 0.5313
 Epoch [9/10], Step[270/483], loss: 0.7671
 Epoch [9/10], Step[280/483], loss: 0.6980
 Epoch [9/10], Step[290/483], loss: 0.5817
 Epoch [9/10], Step[300/483], loss: 0.7882
 Epoch [9/10], Step[310/483], loss: 0.8218
 Epoch [9/10], Step[320/483], loss: 0.8345
 Epoch [9/10], Step[330/483], loss: 0.7792
 Epoch [9/10], Step[340/483], loss: 0.7871
 Epoch [9/10], Step[350/483], loss: 0.7646
 Epoch [9/10], Step[360/483], loss: 0.6047
 Epoch [9/10], Step[370/483], loss: 0.5482
 Epoch [9/10], Step[380/483], loss: 0.6907
 Epoch [9/10], Step[390/483], loss: 0.8091
 Epoch [9/10], Step[400/483], loss: 0.7728
 Epoch [9/10], Step[410/483], loss: 0.6236
 Epoch [9/10], Step[420/483], loss: 0.7584
 Epoch [9/10], Step[430/483], loss: 0.7496
 Epoch [9/10], Step[440/483], loss: 0.7299
 Epoch [9/10], Step[450/483], loss: 0.6429
 Epoch [9/10], Step[460/483], loss: 0.8548
 Epoch [9/10], Step[470/483], loss: 0.8796
 Epoch [9/10], Step[480/483], loss: 0.5296
 ====> Epoch 9: Training loss: 374.0375
 ====> Epoch 9: Validation loss: 54.7267
 Epoch [10/10], Step[0/483], loss: 0.6531
 Epoch [10/10], Step[10/483], loss: 0.7808
 Epoch [10/10], Step[20/483], loss: 0.8322
 Epoch [10/10], Step[30/483], loss: 0.7645
 Epoch [10/10], Step[40/483], loss: 0.7941
 Epoch [10/10], Step[50/483], loss: 0.8414
 Epoch [10/10], Step[60/483], loss: 0.8845
 Epoch [10/10], Step[70/483], loss: 0.8497
 Epoch [10/10], Step[80/483], loss: 0.9314
 Epoch [10/10], Step[90/483], loss: 0.6515
 Epoch [10/10], Step[100/483], loss: 0.6812
 Epoch [10/10], Step[110/483], loss: 0.8014
 Epoch [10/10], Step[120/483], loss: 0.8489
 Epoch [10/10], Step[130/483], loss: 0.7083
 Epoch [10/10], Step[140/483], loss: 0.8324
 Epoch [10/10], Step[150/483], loss: 0.7803
 Epoch [10/10], Step[160/483], loss: 0.9137
 Epoch [10/10], Step[170/483], loss: 0.6145
 Epoch [10/10], Step[180/483], loss: 0.8686
 Epoch [10/10], Step[190/483], loss: 0.8801
 Epoch [10/10], Step[200/483], loss: 0.6404
 Epoch [10/10], Step[210/483], loss: 0.7984
 Epoch [10/10], Step[220/483], loss: 0.6796
 Epoch [10/10], Step[230/483], loss: 0.6370
 Epoch [10/10], Step[240/483], loss: 0.7354
 Epoch [10/10], Step[250/483], loss: 0.8327
 Epoch [10/10], Step[260/483], loss: 0.5318
 Epoch [10/10], Step[270/483], loss: 0.7753
 Epoch [10/10], Step[280/483], loss: 0.6760
 Epoch [10/10], Step[290/483], loss: 0.5851
 Epoch [10/10], Step[300/483], loss: 0.7843
 Epoch [10/10], Step[310/483], loss: 0.8093
 Epoch [10/10], Step[320/483], loss: 0.8359
 Epoch [10/10], Step[330/483], loss: 0.7924
 Epoch [10/10], Step[340/483], loss: 0.7667
 Epoch [10/10], Step[350/483], loss: 0.7422
 Epoch [10/10], Step[360/483], loss: 0.5891
 Epoch [10/10], Step[370/483], loss: 0.5395
 Epoch [10/10], Step[380/483], loss: 0.6967
 Epoch [10/10], Step[390/483], loss: 0.7960
 Epoch [10/10], Step[400/483], loss: 0.7712
 Epoch [10/10], Step[410/483], loss: 0.6318
 Epoch [10/10], Step[420/483], loss: 0.7382
 Epoch [10/10], Step[430/483], loss: 0.7469
 Epoch [10/10], Step[440/483], loss: 0.7455
 Epoch [10/10], Step[450/483], loss: 0.6315
 Epoch [10/10], Step[460/483], loss: 0.8334
 Epoch [10/10], Step[470/483], loss: 0.8717
 Epoch [10/10], Step[480/483], loss: 0.5176
 ====> Epoch 10: Training loss: 370.2091
 ====> Epoch 10: Validation loss: 54.7085
 SamplingSpeaker1Model: SamplingSpeaker1Model(
  (listener0): Listener0Model(
    (scene_encoder): LinearSceneEncoder(
      (fc): Linear(in_features=280, out_features=100)
    )
    (string_encoder): LinearStringEncoder(
      (fc): Linear(in_features=1063, out_features=100)
    )
    (scorer): MLPScorer(
      (dropout): Dropout(p=0.3)
      (linear_4): Linear(in_features=100, out_features=100)
      (linear_5): Linear(in_features=100, out_features=100)
      (linear_3): Linear(in_features=100, out_features=1)
    )
  )
  (speaker0): Speaker0Model(
    (scene_encoder): LinearSceneEncoder(
      (fc): Linear(in_features=280, out_features=100)
    )
    (string_decoder): LSTMStringDecoder(
      (embedding): Embedding(1063, 100)
      (lstm): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.3)
      (linear): Linear(in_features=100, out_features=1063)
      (dropout): Dropout(p=0.3)
    )
  )
)
