â‡’  python3 main.py --LR=0.1 --epochs=30 2>&1 | tee outfile2
Loading feature files...
All scenes loaded.
Hyperparameters: Namespace(LR=0.1, alternatives=1, batch_size=100, dropout=0.0, epochs=30, hidden_sz=50, log_interval=10, no_cuda=False, seed=1)
Epoch [1/30], Step[0/483], loss: 0.6946
Epoch [1/30], Step[100/483], loss: 1.0913
Epoch [1/30], Step[200/483], loss: 1.1573
Epoch [1/30], Step[300/483], loss: 3.4419
Epoch [1/30], Step[400/483], loss: 2.4911
====> Epoch 1: Training loss: 1227.5856
Epoch [2/30], Step[0/483], loss: 3.5474
Epoch [2/30], Step[100/483], loss: 3.6968
Epoch [2/30], Step[200/483], loss: 0.9476
Epoch [2/30], Step[300/483], loss: 6.0199
Epoch [2/30], Step[400/483], loss: 1.0084
====> Epoch 2: Training loss: 1109.5764
Epoch [3/30], Step[0/483], loss: 2.6688
Epoch [3/30], Step[100/483], loss: 1.8326
Epoch [3/30], Step[200/483], loss: 1.1354
Epoch [3/30], Step[300/483], loss: 1.2523
Epoch [3/30], Step[400/483], loss: 0.9504
====> Epoch 3: Training loss: 621.2976
Epoch [4/30], Step[0/483], loss: 0.8751
Epoch [4/30], Step[100/483], loss: 0.7419
Epoch [4/30], Step[200/483], loss: 0.3939
Epoch [4/30], Step[300/483], loss: 1.3213
Epoch [4/30], Step[400/483], loss: 1.1380
====> Epoch 4: Training loss: 437.7978
Epoch [5/30], Step[0/483], loss: 1.0578
Epoch [5/30], Step[100/483], loss: 0.6289
Epoch [5/30], Step[200/483], loss: 1.3654
Epoch [5/30], Step[300/483], loss: 3.4992
Epoch [5/30], Step[400/483], loss: 2.7398
====> Epoch 5: Training loss: 684.2833
Epoch [6/30], Step[0/483], loss: 2.3497
Epoch [6/30], Step[100/483], loss: 7.4842
Epoch [6/30], Step[200/483], loss: 2.8406
Epoch [6/30], Step[300/483], loss: 1.8398
Epoch [6/30], Step[400/483], loss: 8.6637
====> Epoch 6: Training loss: 1607.2595
Epoch [7/30], Step[0/483], loss: 3.9631
Epoch [7/30], Step[100/483], loss: 2.8977
Epoch [7/30], Step[200/483], loss: 1.1598
Epoch [7/30], Step[300/483], loss: 0.6612
Epoch [7/30], Step[400/483], loss: 1.8163
====> Epoch 7: Training loss: 762.4339
Epoch [8/30], Step[0/483], loss: 1.8488
Epoch [8/30], Step[100/483], loss: 1.1278
Epoch [8/30], Step[200/483], loss: 0.8736
Epoch [8/30], Step[300/483], loss: 1.1329
Epoch [8/30], Step[400/483], loss: 1.0124
====> Epoch 8: Training loss: 548.4455
Epoch [9/30], Step[0/483], loss: 1.0381
Epoch [9/30], Step[100/483], loss: 1.1118
Epoch [9/30], Step[200/483], loss: 0.7071
Epoch [9/30], Step[300/483], loss: 0.7446
Epoch [9/30], Step[400/483], loss: 1.1479
====> Epoch 9: Training loss: 558.5343
Epoch [10/30], Step[0/483], loss: 1.1394
Epoch [10/30], Step[100/483], loss: 0.8265
Epoch [10/30], Step[200/483], loss: 0.4973
Epoch [10/30], Step[300/483], loss: 0.9477
Epoch [10/30], Step[400/483], loss: 1.8260
====> Epoch 10: Training loss: 591.0850
Epoch [11/30], Step[0/483], loss: 0.9360
Epoch [11/30], Step[100/483], loss: 1.0944
Epoch [11/30], Step[200/483], loss: 0.9403
Epoch [11/30], Step[300/483], loss: 1.2843
Epoch [11/30], Step[400/483], loss: 0.9916
====> Epoch 11: Training loss: 530.8700
Epoch [12/30], Step[0/483], loss: 0.4782
Epoch [12/30], Step[100/483], loss: 1.7680
Epoch [12/30], Step[200/483], loss: 0.5927
Epoch [12/30], Step[300/483], loss: 0.9955
Epoch [12/30], Step[400/483], loss: 1.2463
====> Epoch 12: Training loss: 586.2925
Epoch [13/30], Step[0/483], loss: 0.8039
Epoch [13/30], Step[100/483], loss: 1.3441
Epoch [13/30], Step[200/483], loss: 0.7118
Epoch [13/30], Step[300/483], loss: 0.7174
Epoch [13/30], Step[400/483], loss: 0.9932
====> Epoch 13: Training loss: 590.0891
Epoch [14/30], Step[0/483], loss: 2.0579
Epoch [14/30], Step[100/483], loss: 0.9483
Epoch [14/30], Step[200/483], loss: 0.6350
Epoch [14/30], Step[300/483], loss: 1.3794
Epoch [14/30], Step[400/483], loss: 0.8494
====> Epoch 14: Training loss: 537.5248
Epoch [15/30], Step[0/483], loss: 1.2979
Epoch [15/30], Step[100/483], loss: 1.0992
Epoch [15/30], Step[200/483], loss: 0.6256
Epoch [15/30], Step[300/483], loss: 1.0159
Epoch [15/30], Step[400/483], loss: 1.2719
====> Epoch 15: Training loss: 485.7276
Epoch [16/30], Step[0/483], loss: 0.8196
Epoch [16/30], Step[100/483], loss: 1.1789
Epoch [16/30], Step[200/483], loss: 0.4333
Epoch [16/30], Step[300/483], loss: 0.5950
Epoch [16/30], Step[400/483], loss: 1.2123
====> Epoch 16: Training loss: 548.9261
Epoch [17/30], Step[0/483], loss: 1.5134
Epoch [17/30], Step[100/483], loss: 0.8385
Epoch [17/30], Step[200/483], loss: 1.1482
Epoch [17/30], Step[300/483], loss: 0.7708
Epoch [17/30], Step[400/483], loss: 0.8405
====> Epoch 17: Training loss: 492.1378
Epoch [18/30], Step[0/483], loss: 1.6107
Epoch [18/30], Step[100/483], loss: 0.6457
Epoch [18/30], Step[200/483], loss: 0.9435
Epoch [18/30], Step[300/483], loss: 1.1424
Epoch [18/30], Step[400/483], loss: 1.7427
====> Epoch 18: Training loss: 534.5364
Epoch [19/30], Step[0/483], loss: 2.2206
Epoch [19/30], Step[100/483], loss: 1.0741
Epoch [19/30], Step[200/483], loss: 0.8126
Epoch [19/30], Step[300/483], loss: 1.5814
Epoch [19/30], Step[400/483], loss: 1.2494
====> Epoch 19: Training loss: 560.3566
Epoch [20/30], Step[0/483], loss: 1.2272
Epoch [20/30], Step[100/483], loss: 1.5675
Epoch [20/30], Step[200/483], loss: 0.5389
Epoch [20/30], Step[300/483], loss: 1.2451
Epoch [20/30], Step[400/483], loss: 1.0994
====> Epoch 20: Training loss: 494.2438
Epoch [21/30], Step[0/483], loss: 0.8890
Epoch [21/30], Step[100/483], loss: 1.6354
Epoch [21/30], Step[200/483], loss: 0.8425
Epoch [21/30], Step[300/483], loss: 0.4326
Epoch [21/30], Step[400/483], loss: 1.3719
====> Epoch 21: Training loss: 492.7166
Epoch [22/30], Step[0/483], loss: 1.5890
Epoch [22/30], Step[100/483], loss: 1.1104
Epoch [22/30], Step[200/483], loss: 0.8445
Epoch [22/30], Step[300/483], loss: 0.8729
Epoch [22/30], Step[400/483], loss: 1.2317
====> Epoch 22: Training loss: 566.4233
Epoch [23/30], Step[0/483], loss: 0.9403
Epoch [23/30], Step[100/483], loss: 0.8392
Epoch [23/30], Step[200/483], loss: 0.6723
Epoch [23/30], Step[300/483], loss: 1.0398
Epoch [23/30], Step[400/483], loss: 1.4093
====> Epoch 23: Training loss: 567.2392
Epoch [24/30], Step[0/483], loss: 1.7308
Epoch [24/30], Step[100/483], loss: 1.2930
Epoch [24/30], Step[200/483], loss: 0.5825
Epoch [24/30], Step[300/483], loss: 0.4894
Epoch [24/30], Step[400/483], loss: 1.0028
====> Epoch 24: Training loss: 567.3386
Epoch [25/30], Step[0/483], loss: 0.8526
Epoch [25/30], Step[100/483], loss: 1.5262
Epoch [25/30], Step[200/483], loss: 0.7389
Epoch [25/30], Step[300/483], loss: 0.9722
Epoch [25/30], Step[400/483], loss: 0.7961
====> Epoch 25: Training loss: 475.8621
Epoch [26/30], Step[0/483], loss: 1.0003
Epoch [26/30], Step[100/483], loss: 0.8577
Epoch [26/30], Step[200/483], loss: 0.8811
Epoch [26/30], Step[300/483], loss: 1.7717
Epoch [26/30], Step[400/483], loss: 0.7264
====> Epoch 26: Training loss: 468.6775
Epoch [27/30], Step[0/483], loss: 0.7842
Epoch [27/30], Step[100/483], loss: 0.6652
Epoch [27/30], Step[200/483], loss: 1.0189
Epoch [27/30], Step[300/483], loss: 0.7781
Epoch [27/30], Step[400/483], loss: 3.9363
====> Epoch 27: Training loss: 620.3804
Epoch [28/30], Step[0/483], loss: 1.5989
Epoch [28/30], Step[100/483], loss: 0.6861
Epoch [28/30], Step[200/483], loss: 2.5499
Epoch [28/30], Step[300/483], loss: 0.6961
Epoch [28/30], Step[400/483], loss: 1.0214
====> Epoch 28: Training loss: 644.8954
Epoch [29/30], Step[0/483], loss: 3.1828
Epoch [29/30], Step[100/483], loss: 0.9066
Epoch [29/30], Step[200/483], loss: 0.4397
Epoch [29/30], Step[300/483], loss: 1.5501
Epoch [29/30], Step[400/483], loss: 1.6819
====> Epoch 29: Training loss: 661.4542
Epoch [30/30], Step[0/483], loss: 1.3816
Epoch [30/30], Step[100/483], loss: 0.7361
Epoch [30/30], Step[200/483], loss: 0.6257
Epoch [30/30], Step[300/483], loss: 0.9873
Epoch [30/30], Step[400/483], loss: 1.0798
====> Epoch 30: Training loss: 567.5307
