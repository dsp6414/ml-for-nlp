 Loading feature files...
 <s> = 1
 </s> = 2
 All scenes loaded.
 Hyperparameters:Namespace(LR=0.01, alternatives=1, batch_size=100, dec='LSTM', dropout=0.0, epochs=10, hidden_sz=50, log_interval=10, model='ss1', no_cuda=False, seed=1)
 Listener0: Listener0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=50)
  )
  (string_encoder): LinearStringEncoder(
    (fc): Linear(in_features=1063, out_features=50)
  )
  (scorer): MLPScorer(
    (linear_4): Linear(in_features=50, out_features=50)
    (linear_5): Linear(in_features=50, out_features=50)
    (linear_3): Linear(in_features=50, out_features=1)
  )
)
 Speaker0: Speaker0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=50)
  )
  (string_decoder): LSTMStringDecoder(
    (embedding): Embedding(1063, 50)
    (lstm): LSTM(50, 50, num_layers=2, batch_first=True)
    (linear): Linear(in_features=50, out_features=1063)
    (dropout): Dropout(p=0.0)
  )
)
 Training Listener0...
 Epoch [1/10], Step[0/483], loss: 0.6938
 Epoch [1/10], Step[10/483], loss: 0.6833
 Epoch [1/10], Step[20/483], loss: 0.6724
 Epoch [1/10], Step[30/483], loss: 0.6763
 Epoch [1/10], Step[40/483], loss: 0.6808
 Epoch [1/10], Step[50/483], loss: 0.6999
 Epoch [1/10], Step[60/483], loss: 0.6874
 Epoch [1/10], Step[70/483], loss: 0.6974
 Epoch [1/10], Step[80/483], loss: 0.6799
 Epoch [1/10], Step[90/483], loss: 0.6820
 Epoch [1/10], Step[100/483], loss: 0.6994
 Epoch [1/10], Step[110/483], loss: 0.7381
 Epoch [1/10], Step[120/483], loss: 0.6769
 Epoch [1/10], Step[130/483], loss: 0.6814
 Epoch [1/10], Step[140/483], loss: 0.6652
 Epoch [1/10], Step[150/483], loss: 0.8509
 Epoch [1/10], Step[160/483], loss: 0.7027
 Epoch [1/10], Step[170/483], loss: 0.6862
 Epoch [1/10], Step[180/483], loss: 0.5712
 Epoch [1/10], Step[190/483], loss: 0.7341
 Epoch [1/10], Step[200/483], loss: 0.6935
 Epoch [1/10], Step[210/483], loss: 0.6526
 Epoch [1/10], Step[220/483], loss: 0.6287
 Epoch [1/10], Step[230/483], loss: 0.6500
 Epoch [1/10], Step[240/483], loss: 0.6244
 Epoch [1/10], Step[250/483], loss: 0.5458
 Epoch [1/10], Step[260/483], loss: 0.5830
 Epoch [1/10], Step[270/483], loss: 0.5364
 Epoch [1/10], Step[280/483], loss: 0.6273
 Epoch [1/10], Step[290/483], loss: 0.6578
 Epoch [1/10], Step[300/483], loss: 0.5938
 Epoch [1/10], Step[310/483], loss: 0.6445
 Epoch [1/10], Step[320/483], loss: 0.7959
 Epoch [1/10], Step[330/483], loss: 0.6356
 Epoch [1/10], Step[340/483], loss: 0.5050
 Epoch [1/10], Step[350/483], loss: 0.6217
 Epoch [1/10], Step[360/483], loss: 0.6172
 Epoch [1/10], Step[370/483], loss: 0.4609
 Epoch [1/10], Step[380/483], loss: 0.6287
 Epoch [1/10], Step[390/483], loss: 0.5615
 Epoch [1/10], Step[400/483], loss: 0.8368
 Epoch [1/10], Step[410/483], loss: 0.5118
 Epoch [1/10], Step[420/483], loss: 0.5010
 Epoch [1/10], Step[430/483], loss: 0.7007
 Epoch [1/10], Step[440/483], loss: 0.6069
 Epoch [1/10], Step[450/483], loss: 0.5870
 Epoch [1/10], Step[460/483], loss: 0.6405
 Epoch [1/10], Step[470/483], loss: 0.4999
 Epoch [1/10], Step[480/483], loss: 0.4758
 ====> Epoch 1: Training loss: 309.7298
 Accuracy: 0.599607
 Epoch [2/10], Step[0/483], loss: 0.5028
 Epoch [2/10], Step[10/483], loss: 0.4178
 Epoch [2/10], Step[20/483], loss: 0.5527
 Epoch [2/10], Step[30/483], loss: 0.6466
 Epoch [2/10], Step[40/483], loss: 0.5834
 Epoch [2/10], Step[50/483], loss: 0.5775
 Epoch [2/10], Step[60/483], loss: 0.5091
 Epoch [2/10], Step[70/483], loss: 0.4999
 Epoch [2/10], Step[80/483], loss: 0.5146
 Epoch [2/10], Step[90/483], loss: 0.6031
 Epoch [2/10], Step[100/483], loss: 0.4804
 Epoch [2/10], Step[110/483], loss: 0.6443
 Epoch [2/10], Step[120/483], loss: 0.6042
 Epoch [2/10], Step[130/483], loss: 0.6746
 Epoch [2/10], Step[140/483], loss: 0.4581
 Epoch [2/10], Step[150/483], loss: 0.5296
 Epoch [2/10], Step[160/483], loss: 0.6047
 Epoch [2/10], Step[170/483], loss: 0.5748
 Epoch [2/10], Step[180/483], loss: 0.2837
 Epoch [2/10], Step[190/483], loss: 0.4296
 Epoch [2/10], Step[200/483], loss: 0.4181
 Epoch [2/10], Step[210/483], loss: 0.5586
 Epoch [2/10], Step[220/483], loss: 0.5205
 Epoch [2/10], Step[230/483], loss: 0.5030
 Epoch [2/10], Step[240/483], loss: 0.4350
 Epoch [2/10], Step[250/483], loss: 0.3936
 Epoch [2/10], Step[260/483], loss: 0.3231
 Epoch [2/10], Step[270/483], loss: 0.4713
 Epoch [2/10], Step[280/483], loss: 0.5120
 Epoch [2/10], Step[290/483], loss: 0.5130
 Epoch [2/10], Step[300/483], loss: 0.5376
 Epoch [2/10], Step[310/483], loss: 0.4759
 Epoch [2/10], Step[320/483], loss: 0.6594
 Epoch [2/10], Step[330/483], loss: 0.5220
 Epoch [2/10], Step[340/483], loss: 0.3591
 Epoch [2/10], Step[350/483], loss: 0.5779
 Epoch [2/10], Step[360/483], loss: 0.4438
 Epoch [2/10], Step[370/483], loss: 0.4448
 Epoch [2/10], Step[380/483], loss: 0.4417
 Epoch [2/10], Step[390/483], loss: 0.5213
 Epoch [2/10], Step[400/483], loss: 0.4893
 Epoch [2/10], Step[410/483], loss: 0.3941
 Epoch [2/10], Step[420/483], loss: 0.3771
 Epoch [2/10], Step[430/483], loss: 0.6148
 Epoch [2/10], Step[440/483], loss: 0.4878
 Epoch [2/10], Step[450/483], loss: 0.4301
 Epoch [2/10], Step[460/483], loss: 0.5964
 Epoch [2/10], Step[470/483], loss: 0.3918
 Epoch [2/10], Step[480/483], loss: 0.4453
 ====> Epoch 2: Training loss: 239.5540
 Accuracy: 0.736108
 Epoch [3/10], Step[0/483], loss: 0.4385
 Epoch [3/10], Step[10/483], loss: 0.3346
 Epoch [3/10], Step[20/483], loss: 0.3688
 Epoch [3/10], Step[30/483], loss: 0.5269
 Epoch [3/10], Step[40/483], loss: 0.3296
 Epoch [3/10], Step[50/483], loss: 0.4855
 Epoch [3/10], Step[60/483], loss: 0.4320
 Epoch [3/10], Step[70/483], loss: 0.3827
 Epoch [3/10], Step[80/483], loss: 0.4942
 Epoch [3/10], Step[90/483], loss: 0.4671
 Epoch [3/10], Step[100/483], loss: 0.2541
 Epoch [3/10], Step[110/483], loss: 0.4611
 Epoch [3/10], Step[120/483], loss: 0.4165
 Epoch [3/10], Step[130/483], loss: 0.3506
 Epoch [3/10], Step[140/483], loss: 0.3267
 Epoch [3/10], Step[150/483], loss: 0.3506
 Epoch [3/10], Step[160/483], loss: 0.3742
 Epoch [3/10], Step[170/483], loss: 0.5286
 Epoch [3/10], Step[180/483], loss: 0.3378
 Epoch [3/10], Step[190/483], loss: 0.3765
 Epoch [3/10], Step[200/483], loss: 0.3032
 Epoch [3/10], Step[210/483], loss: 0.4686
 Epoch [3/10], Step[220/483], loss: 0.3632
 Epoch [3/10], Step[230/483], loss: 0.3707
 Epoch [3/10], Step[240/483], loss: 0.3427
 Epoch [3/10], Step[250/483], loss: 0.4292
 Epoch [3/10], Step[260/483], loss: 0.3457
 Epoch [3/10], Step[270/483], loss: 0.3954
 Epoch [3/10], Step[280/483], loss: 0.4647
 Epoch [3/10], Step[290/483], loss: 0.4909
 Epoch [3/10], Step[300/483], loss: 0.4501
 Epoch [3/10], Step[310/483], loss: 0.3355
 Epoch [3/10], Step[320/483], loss: 0.4780
 Epoch [3/10], Step[330/483], loss: 0.4419
 Epoch [3/10], Step[340/483], loss: 0.3734
 Epoch [3/10], Step[350/483], loss: 0.4935
 Epoch [3/10], Step[360/483], loss: 0.4463
 Epoch [3/10], Step[370/483], loss: 0.3946
 Epoch [3/10], Step[380/483], loss: 0.3572
 Epoch [3/10], Step[390/483], loss: 0.4294
 Epoch [3/10], Step[400/483], loss: 0.4712
 Epoch [3/10], Step[410/483], loss: 0.3033
 Epoch [3/10], Step[420/483], loss: 0.4093
 Epoch [3/10], Step[430/483], loss: 0.4051
 Epoch [3/10], Step[440/483], loss: 0.3700
 Epoch [3/10], Step[450/483], loss: 0.3947
 Epoch [3/10], Step[460/483], loss: 0.5070
 Epoch [3/10], Step[470/483], loss: 0.3520
 Epoch [3/10], Step[480/483], loss: 0.4230
 ====> Epoch 3: Training loss: 202.0316
 Accuracy: 0.783416
 Epoch [4/10], Step[0/483], loss: 0.4286
 Epoch [4/10], Step[10/483], loss: 0.3197
 Epoch [4/10], Step[20/483], loss: 0.4188
 Epoch [4/10], Step[30/483], loss: 0.4392
 Epoch [4/10], Step[40/483], loss: 0.2763
 Epoch [4/10], Step[50/483], loss: 0.4400
 Epoch [4/10], Step[60/483], loss: 0.4057
 Epoch [4/10], Step[70/483], loss: 0.3251
 Epoch [4/10], Step[80/483], loss: 0.3224
 Epoch [4/10], Step[90/483], loss: 0.3903
 Epoch [4/10], Step[100/483], loss: 0.2203
 Epoch [4/10], Step[110/483], loss: 0.4365
 Epoch [4/10], Step[120/483], loss: 0.4033
 Epoch [4/10], Step[130/483], loss: 0.4046
 Epoch [4/10], Step[140/483], loss: 0.3984
 Epoch [4/10], Step[150/483], loss: 0.3867
 Epoch [4/10], Step[160/483], loss: 0.3670
 Epoch [4/10], Step[170/483], loss: 0.3757
 Epoch [4/10], Step[180/483], loss: 0.2770
 Epoch [4/10], Step[190/483], loss: 0.5022
 Epoch [4/10], Step[200/483], loss: 0.3490
 Epoch [4/10], Step[210/483], loss: 0.3131
 Epoch [4/10], Step[220/483], loss: 0.3212
 Epoch [4/10], Step[230/483], loss: 0.3685
 Epoch [4/10], Step[240/483], loss: 0.3793
 Epoch [4/10], Step[250/483], loss: 0.4081
 Epoch [4/10], Step[260/483], loss: 0.3916
 Epoch [4/10], Step[270/483], loss: 0.3155
 Epoch [4/10], Step[280/483], loss: 0.4073
 Epoch [4/10], Step[290/483], loss: 0.3277
 Epoch [4/10], Step[300/483], loss: 0.3757
 Epoch [4/10], Step[310/483], loss: 0.4005
 Epoch [4/10], Step[320/483], loss: 0.4013
 Epoch [4/10], Step[330/483], loss: 0.3540
 Epoch [4/10], Step[340/483], loss: 0.3910
 Epoch [4/10], Step[350/483], loss: 0.3760
 Epoch [4/10], Step[360/483], loss: 0.4375
 Epoch [4/10], Step[370/483], loss: 0.3178
 Epoch [4/10], Step[380/483], loss: 0.3722
 Epoch [4/10], Step[390/483], loss: 0.3966
 Epoch [4/10], Step[400/483], loss: 0.3105
 Epoch [4/10], Step[410/483], loss: 0.4634
 Epoch [4/10], Step[420/483], loss: 0.3082
 Epoch [4/10], Step[430/483], loss: 0.3041
 Epoch [4/10], Step[440/483], loss: 0.3702
 Epoch [4/10], Step[450/483], loss: 0.3025
 Epoch [4/10], Step[460/483], loss: 0.3606
 Epoch [4/10], Step[470/483], loss: 0.2733
 Epoch [4/10], Step[480/483], loss: 0.2613
 ====> Epoch 4: Training loss: 174.8031
 Accuracy: 0.820704
 Epoch [5/10], Step[0/483], loss: 0.2494
 Epoch [5/10], Step[10/483], loss: 0.4021
 Epoch [5/10], Step[20/483], loss: 0.3295
 Epoch [5/10], Step[30/483], loss: 0.3088
 Epoch [5/10], Step[40/483], loss: 0.3016
 Epoch [5/10], Step[50/483], loss: 0.2810
 Epoch [5/10], Step[60/483], loss: 0.3583
 Epoch [5/10], Step[70/483], loss: 0.2520
 Epoch [5/10], Step[80/483], loss: 0.3307
 Epoch [5/10], Step[90/483], loss: 0.3914
 Epoch [5/10], Step[100/483], loss: 0.2398
 Epoch [5/10], Step[110/483], loss: 0.3624
 Epoch [5/10], Step[120/483], loss: 0.3045
 Epoch [5/10], Step[130/483], loss: 0.4894
 Epoch [5/10], Step[140/483], loss: 0.2736
 Epoch [5/10], Step[150/483], loss: 0.3734
 Epoch [5/10], Step[160/483], loss: 0.2470
 Epoch [5/10], Step[170/483], loss: 0.3306
 Epoch [5/10], Step[180/483], loss: 0.3136
 Epoch [5/10], Step[190/483], loss: 0.3429
 Epoch [5/10], Step[200/483], loss: 0.4152
 Epoch [5/10], Step[210/483], loss: 0.2688
 Epoch [5/10], Step[220/483], loss: 0.3934
 Epoch [5/10], Step[230/483], loss: 0.3760
 Epoch [5/10], Step[240/483], loss: 0.3168
 Epoch [5/10], Step[250/483], loss: 0.4331
 Epoch [5/10], Step[260/483], loss: 0.2065
 Epoch [5/10], Step[270/483], loss: 0.3184
 Epoch [5/10], Step[280/483], loss: 0.3886
 Epoch [5/10], Step[290/483], loss: 0.3224
 Epoch [5/10], Step[300/483], loss: 0.2518
 Epoch [5/10], Step[310/483], loss: 0.2624
 Epoch [5/10], Step[320/483], loss: 0.3248
 Epoch [5/10], Step[330/483], loss: 0.4222
 Epoch [5/10], Step[340/483], loss: 0.3455
 Epoch [5/10], Step[350/483], loss: 0.2975
 Epoch [5/10], Step[360/483], loss: 0.2697
 Epoch [5/10], Step[370/483], loss: 0.2619
 Epoch [5/10], Step[380/483], loss: 0.3197
 Epoch [5/10], Step[390/483], loss: 0.2789
 Epoch [5/10], Step[400/483], loss: 0.3382
 Epoch [5/10], Step[410/483], loss: 0.4112
 Epoch [5/10], Step[420/483], loss: 0.2554
 Epoch [5/10], Step[430/483], loss: 0.3747
 Epoch [5/10], Step[440/483], loss: 0.3066
 Epoch [5/10], Step[450/483], loss: 0.2026
 Epoch [5/10], Step[460/483], loss: 0.4059
 Epoch [5/10], Step[470/483], loss: 0.2843
 Epoch [5/10], Step[480/483], loss: 0.1528
 ====> Epoch 5: Training loss: 155.2764
 Accuracy: 0.840973
 Epoch [6/10], Step[0/483], loss: 0.2242
 Epoch [6/10], Step[10/483], loss: 0.3099
 Epoch [6/10], Step[20/483], loss: 0.2338
 Epoch [6/10], Step[30/483], loss: 0.3423
 Epoch [6/10], Step[40/483], loss: 0.2066
 Epoch [6/10], Step[50/483], loss: 0.3784
 Epoch [6/10], Step[60/483], loss: 0.3060
 Epoch [6/10], Step[70/483], loss: 0.2549
 Epoch [6/10], Step[80/483], loss: 0.2893
 Epoch [6/10], Step[90/483], loss: 0.3304
 Epoch [6/10], Step[100/483], loss: 0.2317
 Epoch [6/10], Step[110/483], loss: 0.3540
 Epoch [6/10], Step[120/483], loss: 0.2955
 Epoch [6/10], Step[130/483], loss: 0.3765
 Epoch [6/10], Step[140/483], loss: 0.2698
 Epoch [6/10], Step[150/483], loss: 0.2812
 Epoch [6/10], Step[160/483], loss: 0.2290
 Epoch [6/10], Step[170/483], loss: 0.3175
 Epoch [6/10], Step[180/483], loss: 0.3060
 Epoch [6/10], Step[190/483], loss: 0.3066
 Epoch [6/10], Step[200/483], loss: 0.2833
 Epoch [6/10], Step[210/483], loss: 0.2412
 Epoch [6/10], Step[220/483], loss: 0.2562
 Epoch [6/10], Step[230/483], loss: 0.3205
 Epoch [6/10], Step[240/483], loss: 0.2828
 Epoch [6/10], Step[250/483], loss: 0.3111
 Epoch [6/10], Step[260/483], loss: 0.2489
 Epoch [6/10], Step[270/483], loss: 0.2163
 Epoch [6/10], Step[280/483], loss: 0.2539
 Epoch [6/10], Step[290/483], loss: 0.2799
 Epoch [6/10], Step[300/483], loss: 0.1929
 Epoch [6/10], Step[310/483], loss: 0.2945
 Epoch [6/10], Step[320/483], loss: 0.3217
 Epoch [6/10], Step[330/483], loss: 0.2928
 Epoch [6/10], Step[340/483], loss: 0.2490
 Epoch [6/10], Step[350/483], loss: 0.2971
 Epoch [6/10], Step[360/483], loss: 0.2632
 Epoch [6/10], Step[370/483], loss: 0.1997
 Epoch [6/10], Step[380/483], loss: 0.4207
 Epoch [6/10], Step[390/483], loss: 0.3118
 Epoch [6/10], Step[400/483], loss: 0.3015
 Epoch [6/10], Step[410/483], loss: 0.3072
 Epoch [6/10], Step[420/483], loss: 0.3123
 Epoch [6/10], Step[430/483], loss: 0.2349
 Epoch [6/10], Step[440/483], loss: 0.2747
 Epoch [6/10], Step[450/483], loss: 0.1914
 Epoch [6/10], Step[460/483], loss: 0.3670
 Epoch [6/10], Step[470/483], loss: 0.3043
 Epoch [6/10], Step[480/483], loss: 0.1854
 ====> Epoch 6: Training loss: 139.9371
 Accuracy: 0.857267
 Epoch [7/10], Step[0/483], loss: 0.3696
 Epoch [7/10], Step[10/483], loss: 0.2151
 Epoch [7/10], Step[20/483], loss: 0.2703
 Epoch [7/10], Step[30/483], loss: 0.3562
 Epoch [7/10], Step[40/483], loss: 0.2965
 Epoch [7/10], Step[50/483], loss: 0.3600
 Epoch [7/10], Step[60/483], loss: 0.3786
 Epoch [7/10], Step[70/483], loss: 0.1894
 Epoch [7/10], Step[80/483], loss: 0.2569
 Epoch [7/10], Step[90/483], loss: 0.3407
 Epoch [7/10], Step[100/483], loss: 0.2776
 Epoch [7/10], Step[110/483], loss: 0.3482
 Epoch [7/10], Step[120/483], loss: 0.1504
 Epoch [7/10], Step[130/483], loss: 0.3172
 Epoch [7/10], Step[140/483], loss: 0.3068
 Epoch [7/10], Step[150/483], loss: 0.3217
 Epoch [7/10], Step[160/483], loss: 0.3009
 Epoch [7/10], Step[170/483], loss: 0.2988
 Epoch [7/10], Step[180/483], loss: 0.2030
 Epoch [7/10], Step[190/483], loss: 0.2299
 Epoch [7/10], Step[200/483], loss: 0.3125
 Epoch [7/10], Step[210/483], loss: 0.1775
 Epoch [7/10], Step[220/483], loss: 0.3147
 Epoch [7/10], Step[230/483], loss: 0.3620
 Epoch [7/10], Step[240/483], loss: 0.2395
 Epoch [7/10], Step[250/483], loss: 0.1775
 Epoch [7/10], Step[260/483], loss: 0.2367
 Epoch [7/10], Step[270/483], loss: 0.2628
 Epoch [7/10], Step[280/483], loss: 0.3352
 Epoch [7/10], Step[290/483], loss: 0.2549
 Epoch [7/10], Step[300/483], loss: 0.3006
 Epoch [7/10], Step[310/483], loss: 0.3085
 Epoch [7/10], Step[320/483], loss: 0.2473
 Epoch [7/10], Step[330/483], loss: 0.3660
 Epoch [7/10], Step[340/483], loss: 0.2578
 Epoch [7/10], Step[350/483], loss: 0.3232
 Epoch [7/10], Step[360/483], loss: 0.2720
 Epoch [7/10], Step[370/483], loss: 0.2256
 Epoch [7/10], Step[380/483], loss: 0.2420
 Epoch [7/10], Step[390/483], loss: 0.3244
 Epoch [7/10], Step[400/483], loss: 0.3539
 Epoch [7/10], Step[410/483], loss: 0.3130
 Epoch [7/10], Step[420/483], loss: 0.2786
 Epoch [7/10], Step[430/483], loss: 0.2687
 Epoch [7/10], Step[440/483], loss: 0.3845
 Epoch [7/10], Step[450/483], loss: 0.2157
 Epoch [7/10], Step[460/483], loss: 0.5095
 Epoch [7/10], Step[470/483], loss: 0.2524
 Epoch [7/10], Step[480/483], loss: 0.2026
 ====> Epoch 7: Training loss: 135.9435
 Accuracy: 0.862153
 Epoch [8/10], Step[0/483], loss: 0.3531
 Epoch [8/10], Step[10/483], loss: 0.2115
 Epoch [8/10], Step[20/483], loss: 0.1740
 Epoch [8/10], Step[30/483], loss: 0.2681
 Epoch [8/10], Step[40/483], loss: 0.3434
 Epoch [8/10], Step[50/483], loss: 0.2929
 Epoch [8/10], Step[60/483], loss: 0.3156
 Epoch [8/10], Step[70/483], loss: 0.2773
 Epoch [8/10], Step[80/483], loss: 0.3264
 Epoch [8/10], Step[90/483], loss: 0.2534
 Epoch [8/10], Step[100/483], loss: 0.2239
 Epoch [8/10], Step[110/483], loss: 0.2517
 Epoch [8/10], Step[120/483], loss: 0.2385
 Epoch [8/10], Step[130/483], loss: 0.4665
 Epoch [8/10], Step[140/483], loss: 0.3003
 Epoch [8/10], Step[150/483], loss: 0.2094
 Epoch [8/10], Step[160/483], loss: 0.2460
 Epoch [8/10], Step[170/483], loss: 0.3184
 Epoch [8/10], Step[180/483], loss: 0.2196
 Epoch [8/10], Step[190/483], loss: 0.2507
 Epoch [8/10], Step[200/483], loss: 0.2655
 Epoch [8/10], Step[210/483], loss: 0.1401
 Epoch [8/10], Step[220/483], loss: 0.3810
 Epoch [8/10], Step[230/483], loss: 0.2938
 Epoch [8/10], Step[240/483], loss: 0.3408
 Epoch [8/10], Step[250/483], loss: 0.2790
 Epoch [8/10], Step[260/483], loss: 0.1763
 Epoch [8/10], Step[270/483], loss: 0.2785
 Epoch [8/10], Step[280/483], loss: 0.3161
 Epoch [8/10], Step[290/483], loss: 0.1996
 Epoch [8/10], Step[300/483], loss: 0.2344
 Epoch [8/10], Step[310/483], loss: 0.3687
 Epoch [8/10], Step[320/483], loss: 0.2772
 Epoch [8/10], Step[330/483], loss: 0.3874
 Epoch [8/10], Step[340/483], loss: 0.2240
 Epoch [8/10], Step[350/483], loss: 0.3801
 Epoch [8/10], Step[360/483], loss: 0.2165
 Epoch [8/10], Step[370/483], loss: 0.1926
 Epoch [8/10], Step[380/483], loss: 0.3017
 Epoch [8/10], Step[390/483], loss: 0.3057
 Epoch [8/10], Step[400/483], loss: 0.3208
 Epoch [8/10], Step[410/483], loss: 0.2597
 Epoch [8/10], Step[420/483], loss: 0.2540
 Epoch [8/10], Step[430/483], loss: 0.1733
 Epoch [8/10], Step[440/483], loss: 0.2724
 Epoch [8/10], Step[450/483], loss: 0.2432
 Epoch [8/10], Step[460/483], loss: 0.3642
 Epoch [8/10], Step[470/483], loss: 0.1834
 Epoch [8/10], Step[480/483], loss: 0.2032
 ====> Epoch 8: Training loss: 127.3604
 Accuracy: 0.873706
 Epoch [9/10], Step[0/483], loss: 0.2706
 Epoch [9/10], Step[10/483], loss: 0.3342
 Epoch [9/10], Step[20/483], loss: 0.2952
 Epoch [9/10], Step[30/483], loss: 0.2225
 Epoch [9/10], Step[40/483], loss: 0.2037
 Epoch [9/10], Step[50/483], loss: 0.4404
 Epoch [9/10], Step[60/483], loss: 0.2680
 Epoch [9/10], Step[70/483], loss: 0.1527
 Epoch [9/10], Step[80/483], loss: 0.2355
 Epoch [9/10], Step[90/483], loss: 0.2697
 Epoch [9/10], Step[100/483], loss: 0.2251
 Epoch [9/10], Step[110/483], loss: 0.2124
 Epoch [9/10], Step[120/483], loss: 0.1540
 Epoch [9/10], Step[130/483], loss: 0.2971
 Epoch [9/10], Step[140/483], loss: 0.2469
 Epoch [9/10], Step[150/483], loss: 0.1650
 Epoch [9/10], Step[160/483], loss: 0.2090
 Epoch [9/10], Step[170/483], loss: 0.2413
 Epoch [9/10], Step[180/483], loss: 0.2834
 Epoch [9/10], Step[190/483], loss: 0.2676
 Epoch [9/10], Step[200/483], loss: 0.3013
 Epoch [9/10], Step[210/483], loss: 0.2515
 Epoch [9/10], Step[220/483], loss: 0.3269
 Epoch [9/10], Step[230/483], loss: 0.2482
 Epoch [9/10], Step[240/483], loss: 0.1976
 Epoch [9/10], Step[250/483], loss: 0.3453
 Epoch [9/10], Step[260/483], loss: 0.1284
 Epoch [9/10], Step[270/483], loss: 0.2218
 Epoch [9/10], Step[280/483], loss: 0.2152
 Epoch [9/10], Step[290/483], loss: 0.1801
 Epoch [9/10], Step[300/483], loss: 0.2145
 Epoch [9/10], Step[310/483], loss: 0.3431
 Epoch [9/10], Step[320/483], loss: 0.2936
 Epoch [9/10], Step[330/483], loss: 0.3236
 Epoch [9/10], Step[340/483], loss: 0.2199
 Epoch [9/10], Step[350/483], loss: 0.2275
 Epoch [9/10], Step[360/483], loss: 0.3014
 Epoch [9/10], Step[370/483], loss: 0.2356
 Epoch [9/10], Step[380/483], loss: 0.3469
 Epoch [9/10], Step[390/483], loss: 0.2602
 Epoch [9/10], Step[400/483], loss: 0.2267
 Epoch [9/10], Step[410/483], loss: 0.2505
 Epoch [9/10], Step[420/483], loss: 0.1649
 Epoch [9/10], Step[430/483], loss: 0.1652
 Epoch [9/10], Step[440/483], loss: 0.2837
 Epoch [9/10], Step[450/483], loss: 0.2198
 Epoch [9/10], Step[460/483], loss: 0.3097
 Epoch [9/10], Step[470/483], loss: 0.2031
 Epoch [9/10], Step[480/483], loss: 0.2094
 ====> Epoch 9: Training loss: 120.0141
 Accuracy: 0.880331
 Epoch [10/10], Step[0/483], loss: 0.1389
 Epoch [10/10], Step[10/483], loss: 0.3292
 Epoch [10/10], Step[20/483], loss: 0.4041
 Epoch [10/10], Step[30/483], loss: 0.2296
 Epoch [10/10], Step[40/483], loss: 0.2079
 Epoch [10/10], Step[50/483], loss: 0.2090
 Epoch [10/10], Step[60/483], loss: 0.2902
 Epoch [10/10], Step[70/483], loss: 0.1605
 Epoch [10/10], Step[80/483], loss: 0.2704
 Epoch [10/10], Step[90/483], loss: 0.2376
 Epoch [10/10], Step[100/483], loss: 0.2569
 Epoch [10/10], Step[110/483], loss: 0.3467
 Epoch [10/10], Step[120/483], loss: 0.2645
 Epoch [10/10], Step[130/483], loss: 0.2387
 Epoch [10/10], Step[140/483], loss: 0.2018
 Epoch [10/10], Step[150/483], loss: 0.1885
 Epoch [10/10], Step[160/483], loss: 0.2515
 Epoch [10/10], Step[170/483], loss: 0.2253
 Epoch [10/10], Step[180/483], loss: 0.2658
 Epoch [10/10], Step[190/483], loss: 0.3786
 Epoch [10/10], Step[200/483], loss: 0.2073
 Epoch [10/10], Step[210/483], loss: 0.2046
 Epoch [10/10], Step[220/483], loss: 0.2385
 Epoch [10/10], Step[230/483], loss: 0.2590
 Epoch [10/10], Step[240/483], loss: 0.2825
 Epoch [10/10], Step[250/483], loss: 0.3297
 Epoch [10/10], Step[260/483], loss: 0.1954
 Epoch [10/10], Step[270/483], loss: 0.1535
 Epoch [10/10], Step[280/483], loss: 0.1813
 Epoch [10/10], Step[290/483], loss: 0.1651
 Epoch [10/10], Step[300/483], loss: 0.1568
 Epoch [10/10], Step[310/483], loss: 0.2673
 Epoch [10/10], Step[320/483], loss: 0.2332
 Epoch [10/10], Step[330/483], loss: 0.3047
 Epoch [10/10], Step[340/483], loss: 0.1821
 Epoch [10/10], Step[350/483], loss: 0.3173
 Epoch [10/10], Step[360/483], loss: 0.1926
 Epoch [10/10], Step[370/483], loss: 0.1561
 Epoch [10/10], Step[380/483], loss: 0.3215
 Epoch [10/10], Step[390/483], loss: 0.3372
 Epoch [10/10], Step[400/483], loss: 0.2996
 Epoch [10/10], Step[410/483], loss: 0.2862
 Epoch [10/10], Step[420/483], loss: 0.1716
 Epoch [10/10], Step[430/483], loss: 0.3311
 Epoch [10/10], Step[440/483], loss: 0.1985
 Epoch [10/10], Step[450/483], loss: 0.2656
 Epoch [10/10], Step[460/483], loss: 0.2718
 Epoch [10/10], Step[470/483], loss: 0.2653
 Epoch [10/10], Step[480/483], loss: 0.2563
 ====> Epoch 10: Training loss: 117.2971
 Accuracy: 0.886108
 Training Speaker0...
 Epoch [1/10], Step[0/483], loss: 6.9941
 Epoch [1/10], Step[10/483], loss: 3.5902
 Epoch [1/10], Step[20/483], loss: 2.8391
 Epoch [1/10], Step[30/483], loss: 2.1949
 Epoch [1/10], Step[40/483], loss: 2.0287
 Epoch [1/10], Step[50/483], loss: 2.0898
 Epoch [1/10], Step[60/483], loss: 2.0088
 Epoch [1/10], Step[70/483], loss: 1.7732
 Epoch [1/10], Step[80/483], loss: 1.9053
 Epoch [1/10], Step[90/483], loss: 1.3257
 Epoch [1/10], Step[100/483], loss: 1.2690
 Epoch [1/10], Step[110/483], loss: 1.4409
 Epoch [1/10], Step[120/483], loss: 1.5301
 Epoch [1/10], Step[130/483], loss: 1.2431
 Epoch [1/10], Step[140/483], loss: 1.4319
 Epoch [1/10], Step[150/483], loss: 1.4687
 Epoch [1/10], Step[160/483], loss: 1.5807
 Epoch [1/10], Step[170/483], loss: 1.0536
 Epoch [1/10], Step[180/483], loss: 1.4169
 Epoch [1/10], Step[190/483], loss: 1.4322
 Epoch [1/10], Step[200/483], loss: 0.9872
 Epoch [1/10], Step[210/483], loss: 1.2310
 Epoch [1/10], Step[220/483], loss: 1.0724
 Epoch [1/10], Step[230/483], loss: 0.9970
 Epoch [1/10], Step[240/483], loss: 1.2276
 Epoch [1/10], Step[250/483], loss: 1.2645
 Epoch [1/10], Step[260/483], loss: 0.8151
 Epoch [1/10], Step[270/483], loss: 1.2252
 Epoch [1/10], Step[280/483], loss: 1.0206
 Epoch [1/10], Step[290/483], loss: 0.8581
 Epoch [1/10], Step[300/483], loss: 1.2338
 Epoch [1/10], Step[310/483], loss: 1.1960
 Epoch [1/10], Step[320/483], loss: 1.3180
 Epoch [1/10], Step[330/483], loss: 1.1556
 Epoch [1/10], Step[340/483], loss: 1.2336
 Epoch [1/10], Step[350/483], loss: 1.1672
 Epoch [1/10], Step[360/483], loss: 0.8908
 Epoch [1/10], Step[370/483], loss: 0.7636
 Epoch [1/10], Step[380/483], loss: 1.0355
 Epoch [1/10], Step[390/483], loss: 1.1281
 Epoch [1/10], Step[400/483], loss: 1.1008
 Epoch [1/10], Step[410/483], loss: 0.8589
 Epoch [1/10], Step[420/483], loss: 1.0484
 Epoch [1/10], Step[430/483], loss: 1.0649
 Epoch [1/10], Step[440/483], loss: 1.1193
 Epoch [1/10], Step[450/483], loss: 0.9159
 Epoch [1/10], Step[460/483], loss: 1.2069
 Epoch [1/10], Step[470/483], loss: 1.2800
 Epoch [1/10], Step[480/483], loss: 0.7272
 ====> Epoch 1: Training loss: 687.3386
 Epoch [2/10], Step[0/483], loss: 0.9236
 Epoch [2/10], Step[10/483], loss: 1.0824
 Epoch [2/10], Step[20/483], loss: 1.1398
 Epoch [2/10], Step[30/483], loss: 1.0757
 Epoch [2/10], Step[40/483], loss: 1.1300
 Epoch [2/10], Step[50/483], loss: 1.2288
 Epoch [2/10], Step[60/483], loss: 1.3045
 Epoch [2/10], Step[70/483], loss: 1.1906
 Epoch [2/10], Step[80/483], loss: 1.3776
 Epoch [2/10], Step[90/483], loss: 0.9124
 Epoch [2/10], Step[100/483], loss: 0.9140
 Epoch [2/10], Step[110/483], loss: 1.1064
 Epoch [2/10], Step[120/483], loss: 1.1696
 Epoch [2/10], Step[130/483], loss: 0.9731
 Epoch [2/10], Step[140/483], loss: 1.1257
 Epoch [2/10], Step[150/483], loss: 1.1470
 Epoch [2/10], Step[160/483], loss: 1.2658
 Epoch [2/10], Step[170/483], loss: 0.8549
 Epoch [2/10], Step[180/483], loss: 1.2006
 Epoch [2/10], Step[190/483], loss: 1.1657
 Epoch [2/10], Step[200/483], loss: 0.8349
 Epoch [2/10], Step[210/483], loss: 1.0327
 Epoch [2/10], Step[220/483], loss: 0.9272
 Epoch [2/10], Step[230/483], loss: 0.8305
 Epoch [2/10], Step[240/483], loss: 1.0439
 Epoch [2/10], Step[250/483], loss: 1.0861
 Epoch [2/10], Step[260/483], loss: 0.7000
 Epoch [2/10], Step[270/483], loss: 1.0370
 Epoch [2/10], Step[280/483], loss: 0.8950
 Epoch [2/10], Step[290/483], loss: 0.7365
 Epoch [2/10], Step[300/483], loss: 1.0834
 Epoch [2/10], Step[310/483], loss: 1.0676
 Epoch [2/10], Step[320/483], loss: 1.1314
 Epoch [2/10], Step[330/483], loss: 1.0350
 Epoch [2/10], Step[340/483], loss: 1.0739
 Epoch [2/10], Step[350/483], loss: 1.0211
 Epoch [2/10], Step[360/483], loss: 0.7986
 Epoch [2/10], Step[370/483], loss: 0.6952
 Epoch [2/10], Step[380/483], loss: 0.9409
 Epoch [2/10], Step[390/483], loss: 1.0182
 Epoch [2/10], Step[400/483], loss: 0.9847
 Epoch [2/10], Step[410/483], loss: 0.7917
 Epoch [2/10], Step[420/483], loss: 0.9558
 Epoch [2/10], Step[430/483], loss: 0.9782
 Epoch [2/10], Step[440/483], loss: 1.0150
 Epoch [2/10], Step[450/483], loss: 0.8187
 Epoch [2/10], Step[460/483], loss: 1.1104
 Epoch [2/10], Step[470/483], loss: 1.1512
 Epoch [2/10], Step[480/483], loss: 0.6733
 ====> Epoch 2: Training loss: 503.7907
 Epoch [3/10], Step[0/483], loss: 0.8439
 Epoch [3/10], Step[10/483], loss: 0.9780
 Epoch [3/10], Step[20/483], loss: 1.0536
 Epoch [3/10], Step[30/483], loss: 0.9908
 Epoch [3/10], Step[40/483], loss: 1.0306
 Epoch [3/10], Step[50/483], loss: 1.1271
 Epoch [3/10], Step[60/483], loss: 1.1970
 Epoch [3/10], Step[70/483], loss: 1.1161
 Epoch [3/10], Step[80/483], loss: 1.2729
 Epoch [3/10], Step[90/483], loss: 0.8472
 Epoch [3/10], Step[100/483], loss: 0.8582
 Epoch [3/10], Step[110/483], loss: 1.0294
 Epoch [3/10], Step[120/483], loss: 1.0972
 Epoch [3/10], Step[130/483], loss: 0.9295
 Epoch [3/10], Step[140/483], loss: 1.0456
 Epoch [3/10], Step[150/483], loss: 1.0451
 Epoch [3/10], Step[160/483], loss: 1.1858
 Epoch [3/10], Step[170/483], loss: 0.7901
 Epoch [3/10], Step[180/483], loss: 1.1170
 Epoch [3/10], Step[190/483], loss: 1.0874
 Epoch [3/10], Step[200/483], loss: 0.8079
 Epoch [3/10], Step[210/483], loss: 0.9836
 Epoch [3/10], Step[220/483], loss: 0.8774
 Epoch [3/10], Step[230/483], loss: 0.7904
 Epoch [3/10], Step[240/483], loss: 0.9921
 Epoch [3/10], Step[250/483], loss: 1.0251
 Epoch [3/10], Step[260/483], loss: 0.6609
 Epoch [3/10], Step[270/483], loss: 0.9708
 Epoch [3/10], Step[280/483], loss: 0.8433
 Epoch [3/10], Step[290/483], loss: 0.6990
 Epoch [3/10], Step[300/483], loss: 1.0276
 Epoch [3/10], Step[310/483], loss: 1.0112
 Epoch [3/10], Step[320/483], loss: 1.0729
 Epoch [3/10], Step[330/483], loss: 0.9910
 Epoch [3/10], Step[340/483], loss: 1.0425
 Epoch [3/10], Step[350/483], loss: 0.9745
 Epoch [3/10], Step[360/483], loss: 0.7542
 Epoch [3/10], Step[370/483], loss: 0.6574
 Epoch [3/10], Step[380/483], loss: 0.8900
 Epoch [3/10], Step[390/483], loss: 0.9690
 Epoch [3/10], Step[400/483], loss: 0.9327
 Epoch [3/10], Step[410/483], loss: 0.7500
 Epoch [3/10], Step[420/483], loss: 0.9012
 Epoch [3/10], Step[430/483], loss: 0.9458
 Epoch [3/10], Step[440/483], loss: 0.9592
 Epoch [3/10], Step[450/483], loss: 0.7847
 Epoch [3/10], Step[460/483], loss: 1.0562
 Epoch [3/10], Step[470/483], loss: 1.0883
 Epoch [3/10], Step[480/483], loss: 0.6397
 ====> Epoch 3: Training loss: 472.4449
 Epoch [4/10], Step[0/483], loss: 0.8110
 Epoch [4/10], Step[10/483], loss: 0.9295
 Epoch [4/10], Step[20/483], loss: 1.0168
 Epoch [4/10], Step[30/483], loss: 0.9487
 Epoch [4/10], Step[40/483], loss: 0.9904
 Epoch [4/10], Step[50/483], loss: 1.0816
 Epoch [4/10], Step[60/483], loss: 1.1439
 Epoch [4/10], Step[70/483], loss: 1.0505
 Epoch [4/10], Step[80/483], loss: 1.1993
 Epoch [4/10], Step[90/483], loss: 0.8084
 Epoch [4/10], Step[100/483], loss: 0.8273
 Epoch [4/10], Step[110/483], loss: 0.9868
 Epoch [4/10], Step[120/483], loss: 1.0482
 Epoch [4/10], Step[130/483], loss: 0.8908
 Epoch [4/10], Step[140/483], loss: 1.0202
 Epoch [4/10], Step[150/483], loss: 0.9947
 Epoch [4/10], Step[160/483], loss: 1.1388
 Epoch [4/10], Step[170/483], loss: 0.7581
 Epoch [4/10], Step[180/483], loss: 1.0779
 Epoch [4/10], Step[190/483], loss: 1.0479
 Epoch [4/10], Step[200/483], loss: 0.7709
 Epoch [4/10], Step[210/483], loss: 0.9491
 Epoch [4/10], Step[220/483], loss: 0.8510
 Epoch [4/10], Step[230/483], loss: 0.7649
 Epoch [4/10], Step[240/483], loss: 0.9498
 Epoch [4/10], Step[250/483], loss: 0.9870
 Epoch [4/10], Step[260/483], loss: 0.6399
 Epoch [4/10], Step[270/483], loss: 0.9355
 Epoch [4/10], Step[280/483], loss: 0.8262
 Epoch [4/10], Step[290/483], loss: 0.6785
 Epoch [4/10], Step[300/483], loss: 0.9874
 Epoch [4/10], Step[310/483], loss: 0.9653
 Epoch [4/10], Step[320/483], loss: 1.0204
 Epoch [4/10], Step[330/483], loss: 0.9578
 Epoch [4/10], Step[340/483], loss: 0.9893
 Epoch [4/10], Step[350/483], loss: 0.9377
 Epoch [4/10], Step[360/483], loss: 0.7193
 Epoch [4/10], Step[370/483], loss: 0.6304
 Epoch [4/10], Step[380/483], loss: 0.8478
 Epoch [4/10], Step[390/483], loss: 0.9529
 Epoch [4/10], Step[400/483], loss: 0.8818
 Epoch [4/10], Step[410/483], loss: 0.7296
 Epoch [4/10], Step[420/483], loss: 0.8773
 Epoch [4/10], Step[430/483], loss: 0.9114
 Epoch [4/10], Step[440/483], loss: 0.9243
 Epoch [4/10], Step[450/483], loss: 0.7489
 Epoch [4/10], Step[460/483], loss: 1.0380
 Epoch [4/10], Step[470/483], loss: 1.0416
 Epoch [4/10], Step[480/483], loss: 0.6194
 ====> Epoch 4: Training loss: 453.7536
 Epoch [5/10], Step[0/483], loss: 0.7926
 Epoch [5/10], Step[10/483], loss: 0.9043
 Epoch [5/10], Step[20/483], loss: 0.9931
 Epoch [5/10], Step[30/483], loss: 0.9291
 Epoch [5/10], Step[40/483], loss: 0.9462
 Epoch [5/10], Step[50/483], loss: 1.0366
 Epoch [5/10], Step[60/483], loss: 1.1072
 Epoch [5/10], Step[70/483], loss: 1.0280
 Epoch [5/10], Step[80/483], loss: 1.1650
 Epoch [5/10], Step[90/483], loss: 0.7756
 Epoch [5/10], Step[100/483], loss: 0.7986
 Epoch [5/10], Step[110/483], loss: 0.9553
 Epoch [5/10], Step[120/483], loss: 1.0241
 Epoch [5/10], Step[130/483], loss: 0.8611
 Epoch [5/10], Step[140/483], loss: 0.9944
 Epoch [5/10], Step[150/483], loss: 0.9688
 Epoch [5/10], Step[160/483], loss: 1.0988
 Epoch [5/10], Step[170/483], loss: 0.7445
 Epoch [5/10], Step[180/483], loss: 1.0444
 Epoch [5/10], Step[190/483], loss: 1.0189
 Epoch [5/10], Step[200/483], loss: 0.7475
 Epoch [5/10], Step[210/483], loss: 0.9308
 Epoch [5/10], Step[220/483], loss: 0.8280
 Epoch [5/10], Step[230/483], loss: 0.7391
 Epoch [5/10], Step[240/483], loss: 0.9238
 Epoch [5/10], Step[250/483], loss: 0.9586
 Epoch [5/10], Step[260/483], loss: 0.6263
 Epoch [5/10], Step[270/483], loss: 0.9163
 Epoch [5/10], Step[280/483], loss: 0.8179
 Epoch [5/10], Step[290/483], loss: 0.6566
 Epoch [5/10], Step[300/483], loss: 0.9546
 Epoch [5/10], Step[310/483], loss: 0.9349
 Epoch [5/10], Step[320/483], loss: 0.9833
 Epoch [5/10], Step[330/483], loss: 0.9447
 Epoch [5/10], Step[340/483], loss: 0.9662
 Epoch [5/10], Step[350/483], loss: 0.9050
 Epoch [5/10], Step[360/483], loss: 0.6960
 Epoch [5/10], Step[370/483], loss: 0.6143
 Epoch [5/10], Step[380/483], loss: 0.8233
 Epoch [5/10], Step[390/483], loss: 0.9201
 Epoch [5/10], Step[400/483], loss: 0.8627
 Epoch [5/10], Step[410/483], loss: 0.7178
 Epoch [5/10], Step[420/483], loss: 0.8645
 Epoch [5/10], Step[430/483], loss: 0.8947
 Epoch [5/10], Step[440/483], loss: 0.8950
 Epoch [5/10], Step[450/483], loss: 0.7347
 Epoch [5/10], Step[460/483], loss: 1.0118
 Epoch [5/10], Step[470/483], loss: 1.0216
 Epoch [5/10], Step[480/483], loss: 0.6021
 ====> Epoch 5: Training loss: 441.1169
 Epoch [6/10], Step[0/483], loss: 0.7734
 Epoch [6/10], Step[10/483], loss: 0.8947
 Epoch [6/10], Step[20/483], loss: 0.9670
 Epoch [6/10], Step[30/483], loss: 0.9006
 Epoch [6/10], Step[40/483], loss: 0.9287
 Epoch [6/10], Step[50/483], loss: 1.0076
 Epoch [6/10], Step[60/483], loss: 1.0702
 Epoch [6/10], Step[70/483], loss: 0.9984
 Epoch [6/10], Step[80/483], loss: 1.1278
 Epoch [6/10], Step[90/483], loss: 0.7590
 Epoch [6/10], Step[100/483], loss: 0.7781
 Epoch [6/10], Step[110/483], loss: 0.9379
 Epoch [6/10], Step[120/483], loss: 1.0016
 Epoch [6/10], Step[130/483], loss: 0.8331
 Epoch [6/10], Step[140/483], loss: 0.9822
 Epoch [6/10], Step[150/483], loss: 0.9567
 Epoch [6/10], Step[160/483], loss: 1.0626
 Epoch [6/10], Step[170/483], loss: 0.7265
 Epoch [6/10], Step[180/483], loss: 1.0320
 Epoch [6/10], Step[190/483], loss: 0.9918
 Epoch [6/10], Step[200/483], loss: 0.7355
 Epoch [6/10], Step[210/483], loss: 0.9082
 Epoch [6/10], Step[220/483], loss: 0.8130
 Epoch [6/10], Step[230/483], loss: 0.7224
 Epoch [6/10], Step[240/483], loss: 0.9047
 Epoch [6/10], Step[250/483], loss: 0.9423
 Epoch [6/10], Step[260/483], loss: 0.6119
 Epoch [6/10], Step[270/483], loss: 0.9013
 Epoch [6/10], Step[280/483], loss: 0.8097
 Epoch [6/10], Step[290/483], loss: 0.6507
 Epoch [6/10], Step[300/483], loss: 0.9445
 Epoch [6/10], Step[310/483], loss: 0.9227
 Epoch [6/10], Step[320/483], loss: 0.9656
 Epoch [6/10], Step[330/483], loss: 0.9334
 Epoch [6/10], Step[340/483], loss: 0.9375
 Epoch [6/10], Step[350/483], loss: 0.8884
 Epoch [6/10], Step[360/483], loss: 0.6719
 Epoch [6/10], Step[370/483], loss: 0.6065
 Epoch [6/10], Step[380/483], loss: 0.8101
 Epoch [6/10], Step[390/483], loss: 0.9038
 Epoch [6/10], Step[400/483], loss: 0.8528
 Epoch [6/10], Step[410/483], loss: 0.7134
 Epoch [6/10], Step[420/483], loss: 0.8406
 Epoch [6/10], Step[430/483], loss: 0.8652
 Epoch [6/10], Step[440/483], loss: 0.8690
 Epoch [6/10], Step[450/483], loss: 0.7103
 Epoch [6/10], Step[460/483], loss: 0.9936
 Epoch [6/10], Step[470/483], loss: 1.0027
 Epoch [6/10], Step[480/483], loss: 0.6003
 ====> Epoch 6: Training loss: 431.2565
 Epoch [7/10], Step[0/483], loss: 0.7665
 Epoch [7/10], Step[10/483], loss: 0.8871
 Epoch [7/10], Step[20/483], loss: 0.9563
 Epoch [7/10], Step[30/483], loss: 0.8796
 Epoch [7/10], Step[40/483], loss: 0.9075
 Epoch [7/10], Step[50/483], loss: 0.9955
 Epoch [7/10], Step[60/483], loss: 1.0502
 Epoch [7/10], Step[70/483], loss: 0.9916
 Epoch [7/10], Step[80/483], loss: 1.1069
 Epoch [7/10], Step[90/483], loss: 0.7464
 Epoch [7/10], Step[100/483], loss: 0.7641
 Epoch [7/10], Step[110/483], loss: 0.9155
 Epoch [7/10], Step[120/483], loss: 0.9781
 Epoch [7/10], Step[130/483], loss: 0.8313
 Epoch [7/10], Step[140/483], loss: 0.9684
 Epoch [7/10], Step[150/483], loss: 0.9358
 Epoch [7/10], Step[160/483], loss: 1.0382
 Epoch [7/10], Step[170/483], loss: 0.7090
 Epoch [7/10], Step[180/483], loss: 1.0196
 Epoch [7/10], Step[190/483], loss: 0.9875
 Epoch [7/10], Step[200/483], loss: 0.7257
 Epoch [7/10], Step[210/483], loss: 0.9018
 Epoch [7/10], Step[220/483], loss: 0.7989
 Epoch [7/10], Step[230/483], loss: 0.7160
 Epoch [7/10], Step[240/483], loss: 0.8986
 Epoch [7/10], Step[250/483], loss: 0.9177
 Epoch [7/10], Step[260/483], loss: 0.6070
 Epoch [7/10], Step[270/483], loss: 0.8780
 Epoch [7/10], Step[280/483], loss: 0.7870
 Epoch [7/10], Step[290/483], loss: 0.6383
 Epoch [7/10], Step[300/483], loss: 0.9210
 Epoch [7/10], Step[310/483], loss: 0.9071
 Epoch [7/10], Step[320/483], loss: 0.9444
 Epoch [7/10], Step[330/483], loss: 0.9165
 Epoch [7/10], Step[340/483], loss: 0.9247
 Epoch [7/10], Step[350/483], loss: 0.8790
 Epoch [7/10], Step[360/483], loss: 0.6568
 Epoch [7/10], Step[370/483], loss: 0.5993
 Epoch [7/10], Step[380/483], loss: 0.7905
 Epoch [7/10], Step[390/483], loss: 0.8869
 Epoch [7/10], Step[400/483], loss: 0.8394
 Epoch [7/10], Step[410/483], loss: 0.6979
 Epoch [7/10], Step[420/483], loss: 0.8351
 Epoch [7/10], Step[430/483], loss: 0.8547
 Epoch [7/10], Step[440/483], loss: 0.8641
 Epoch [7/10], Step[450/483], loss: 0.7071
 Epoch [7/10], Step[460/483], loss: 0.9646
 Epoch [7/10], Step[470/483], loss: 0.9987
 Epoch [7/10], Step[480/483], loss: 0.5879
 ====> Epoch 7: Training loss: 423.6416
 Epoch [8/10], Step[0/483], loss: 0.7579
 Epoch [8/10], Step[10/483], loss: 0.8753
 Epoch [8/10], Step[20/483], loss: 0.9263
 Epoch [8/10], Step[30/483], loss: 0.8651
 Epoch [8/10], Step[40/483], loss: 0.9050
 Epoch [8/10], Step[50/483], loss: 0.9716
 Epoch [8/10], Step[60/483], loss: 1.0364
 Epoch [8/10], Step[70/483], loss: 0.9778
 Epoch [8/10], Step[80/483], loss: 1.0908
 Epoch [8/10], Step[90/483], loss: 0.7346
 Epoch [8/10], Step[100/483], loss: 0.7595
 Epoch [8/10], Step[110/483], loss: 0.9008
 Epoch [8/10], Step[120/483], loss: 0.9632
 Epoch [8/10], Step[130/483], loss: 0.8116
 Epoch [8/10], Step[140/483], loss: 0.9622
 Epoch [8/10], Step[150/483], loss: 0.9173
 Epoch [8/10], Step[160/483], loss: 1.0179
 Epoch [8/10], Step[170/483], loss: 0.6943
 Epoch [8/10], Step[180/483], loss: 1.0020
 Epoch [8/10], Step[190/483], loss: 0.9669
 Epoch [8/10], Step[200/483], loss: 0.7173
 Epoch [8/10], Step[210/483], loss: 0.8944
 Epoch [8/10], Step[220/483], loss: 0.7878
 Epoch [8/10], Step[230/483], loss: 0.7047
 Epoch [8/10], Step[240/483], loss: 0.8772
 Epoch [8/10], Step[250/483], loss: 0.9050
 Epoch [8/10], Step[260/483], loss: 0.5937
 Epoch [8/10], Step[270/483], loss: 0.8748
 Epoch [8/10], Step[280/483], loss: 0.7828
 Epoch [8/10], Step[290/483], loss: 0.6271
 Epoch [8/10], Step[300/483], loss: 0.9185
 Epoch [8/10], Step[310/483], loss: 0.9096
 Epoch [8/10], Step[320/483], loss: 0.9384
 Epoch [8/10], Step[330/483], loss: 0.9042
 Epoch [8/10], Step[340/483], loss: 0.9109
 Epoch [8/10], Step[350/483], loss: 0.8699
 Epoch [8/10], Step[360/483], loss: 0.6492
 Epoch [8/10], Step[370/483], loss: 0.5931
 Epoch [8/10], Step[380/483], loss: 0.7800
 Epoch [8/10], Step[390/483], loss: 0.8735
 Epoch [8/10], Step[400/483], loss: 0.8329
 Epoch [8/10], Step[410/483], loss: 0.6958
 Epoch [8/10], Step[420/483], loss: 0.8244
 Epoch [8/10], Step[430/483], loss: 0.8571
 Epoch [8/10], Step[440/483], loss: 0.8453
 Epoch [8/10], Step[450/483], loss: 0.6961
 Epoch [8/10], Step[460/483], loss: 0.9619
 Epoch [8/10], Step[470/483], loss: 0.9977
 Epoch [8/10], Step[480/483], loss: 0.5799
 ====> Epoch 8: Training loss: 417.8301
 Epoch [9/10], Step[0/483], loss: 0.7453
 Epoch [9/10], Step[10/483], loss: 0.8634
 Epoch [9/10], Step[20/483], loss: 0.9150
 Epoch [9/10], Step[30/483], loss: 0.8514
 Epoch [9/10], Step[40/483], loss: 0.8845
 Epoch [9/10], Step[50/483], loss: 0.9652
 Epoch [9/10], Step[60/483], loss: 1.0166
 Epoch [9/10], Step[70/483], loss: 0.9568
 Epoch [9/10], Step[80/483], loss: 1.0593
 Epoch [9/10], Step[90/483], loss: 0.7221
 Epoch [9/10], Step[100/483], loss: 0.7501
 Epoch [9/10], Step[110/483], loss: 0.8978
 Epoch [9/10], Step[120/483], loss: 0.9669
 Epoch [9/10], Step[130/483], loss: 0.7918
 Epoch [9/10], Step[140/483], loss: 0.9343
 Epoch [9/10], Step[150/483], loss: 0.9192
 Epoch [9/10], Step[160/483], loss: 1.0132
 Epoch [9/10], Step[170/483], loss: 0.6915
 Epoch [9/10], Step[180/483], loss: 0.9862
 Epoch [9/10], Step[190/483], loss: 0.9561
 Epoch [9/10], Step[200/483], loss: 0.7243
 Epoch [9/10], Step[210/483], loss: 0.8856
 Epoch [9/10], Step[220/483], loss: 0.7681
 Epoch [9/10], Step[230/483], loss: 0.7070
 Epoch [9/10], Step[240/483], loss: 0.8776
 Epoch [9/10], Step[250/483], loss: 0.8935
 Epoch [9/10], Step[260/483], loss: 0.5882
 Epoch [9/10], Step[270/483], loss: 0.8693
 Epoch [9/10], Step[280/483], loss: 0.7717
 Epoch [9/10], Step[290/483], loss: 0.6275
 Epoch [9/10], Step[300/483], loss: 0.9012
 Epoch [9/10], Step[310/483], loss: 0.9015
 Epoch [9/10], Step[320/483], loss: 0.9231
 Epoch [9/10], Step[330/483], loss: 0.9019
 Epoch [9/10], Step[340/483], loss: 0.9120
 Epoch [9/10], Step[350/483], loss: 0.8670
 Epoch [9/10], Step[360/483], loss: 0.6426
 Epoch [9/10], Step[370/483], loss: 0.6012
 Epoch [9/10], Step[380/483], loss: 0.7637
 Epoch [9/10], Step[390/483], loss: 0.8638
 Epoch [9/10], Step[400/483], loss: 0.8392
 Epoch [9/10], Step[410/483], loss: 0.6877
 Epoch [9/10], Step[420/483], loss: 0.8150
 Epoch [9/10], Step[430/483], loss: 0.8410
 Epoch [9/10], Step[440/483], loss: 0.8350
 Epoch [9/10], Step[450/483], loss: 0.6888
 Epoch [9/10], Step[460/483], loss: 0.9581
 Epoch [9/10], Step[470/483], loss: 0.9847
 Epoch [9/10], Step[480/483], loss: 0.5880
 ====> Epoch 9: Training loss: 412.9207
 Epoch [10/10], Step[0/483], loss: 0.7397
 Epoch [10/10], Step[10/483], loss: 0.8792
 Epoch [10/10], Step[20/483], loss: 0.9069
 Epoch [10/10], Step[30/483], loss: 0.8422
 Epoch [10/10], Step[40/483], loss: 0.8733
 Epoch [10/10], Step[50/483], loss: 0.9451
 Epoch [10/10], Step[60/483], loss: 1.0104
 Epoch [10/10], Step[70/483], loss: 0.9531
 Epoch [10/10], Step[80/483], loss: 1.0418
 Epoch [10/10], Step[90/483], loss: 0.7136
 Epoch [10/10], Step[100/483], loss: 0.7512
 Epoch [10/10], Step[110/483], loss: 0.8997
 Epoch [10/10], Step[120/483], loss: 0.9566
 Epoch [10/10], Step[130/483], loss: 0.7800
 Epoch [10/10], Step[140/483], loss: 0.9254
 Epoch [10/10], Step[150/483], loss: 0.8987
 Epoch [10/10], Step[160/483], loss: 0.9976
 Epoch [10/10], Step[170/483], loss: 0.6942
 Epoch [10/10], Step[180/483], loss: 0.9697
 Epoch [10/10], Step[190/483], loss: 0.9477
 Epoch [10/10], Step[200/483], loss: 0.7156
 Epoch [10/10], Step[210/483], loss: 0.8761
 Epoch [10/10], Step[220/483], loss: 0.7654
 Epoch [10/10], Step[230/483], loss: 0.6946
 Epoch [10/10], Step[240/483], loss: 0.8512
 Epoch [10/10], Step[250/483], loss: 0.8978
 Epoch [10/10], Step[260/483], loss: 0.5907
 Epoch [10/10], Step[270/483], loss: 0.8644
 Epoch [10/10], Step[280/483], loss: 0.7594
 Epoch [10/10], Step[290/483], loss: 0.6197
 Epoch [10/10], Step[300/483], loss: 0.8935
 Epoch [10/10], Step[310/483], loss: 0.8848
 Epoch [10/10], Step[320/483], loss: 0.9099
 Epoch [10/10], Step[330/483], loss: 0.8750
 Epoch [10/10], Step[340/483], loss: 0.9036
 Epoch [10/10], Step[350/483], loss: 0.8482
 Epoch [10/10], Step[360/483], loss: 0.6379
 Epoch [10/10], Step[370/483], loss: 0.5853
 Epoch [10/10], Step[380/483], loss: 0.7665
 Epoch [10/10], Step[390/483], loss: 0.8508
 Epoch [10/10], Step[400/483], loss: 0.8296
 Epoch [10/10], Step[410/483], loss: 0.6870
 Epoch [10/10], Step[420/483], loss: 0.8080
 Epoch [10/10], Step[430/483], loss: 0.8279
 Epoch [10/10], Step[440/483], loss: 0.8312
 Epoch [10/10], Step[450/483], loss: 0.6836
 Epoch [10/10], Step[460/483], loss: 0.9539
 Epoch [10/10], Step[470/483], loss: 0.9654
 Epoch [10/10], Step[480/483], loss: 0.5788
 ====> Epoch 10: Training loss: 408.7729
 SamplingSpeaker1Model: SamplingSpeaker1Model(
  (listener0): Listener0Model(
    (scene_encoder): LinearSceneEncoder(
      (fc): Linear(in_features=280, out_features=50)
    )
    (string_encoder): LinearStringEncoder(
      (fc): Linear(in_features=1063, out_features=50)
    )
    (scorer): MLPScorer(
      (linear_4): Linear(in_features=50, out_features=50)
      (linear_5): Linear(in_features=50, out_features=50)
      (linear_3): Linear(in_features=50, out_features=1)
    )
  )
  (speaker0): Speaker0Model(
    (scene_encoder): LinearSceneEncoder(
      (fc): Linear(in_features=280, out_features=50)
    )
    (string_decoder): LSTMStringDecoder(
      (embedding): Embedding(1063, 50)
      (lstm): LSTM(50, 50, num_layers=2, batch_first=True)
      (linear): Linear(in_features=50, out_features=1063)
      (dropout): Dropout(p=0.0)
    )
  )
)
