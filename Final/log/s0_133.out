 Loading feature files...
 <s> = 1
 </s> = 2
 All scenes loaded.
 Hyperparameters:Namespace(LR=0.01, alternatives=1, batch_size=100, dec='LSTM', dropout=0.0, epochs=10, hidden_sz=50, log_interval=10, model='s0', no_cuda=False, seed=1)
 Speaker0: Speaker0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=50)
  )
  (string_decoder): LSTMStringDecoder(
    (embedding): Embedding(1063, 50)
    (lstm): LSTM(50, 50, num_layers=2, batch_first=True)
    (linear): Linear(in_features=50, out_features=1063)
    (dropout): Dropout(p=0.0)
  )
)
 Training Speaker0...
 Epoch [1/10], Step[0/483], loss: 6.9994
 Epoch [1/10], Step[10/483], loss: 3.5274
 Epoch [1/10], Step[20/483], loss: 2.7096
 Epoch [1/10], Step[30/483], loss: 2.1253
 Epoch [1/10], Step[40/483], loss: 2.0061
 Epoch [1/10], Step[50/483], loss: 2.0705
 Epoch [1/10], Step[60/483], loss: 1.9976
 Epoch [1/10], Step[70/483], loss: 1.7925
 Epoch [1/10], Step[80/483], loss: 1.9088
 Epoch [1/10], Step[90/483], loss: 1.3014
 Epoch [1/10], Step[100/483], loss: 1.2564
 Epoch [1/10], Step[110/483], loss: 1.4489
 Epoch [1/10], Step[120/483], loss: 1.5208
 Epoch [1/10], Step[130/483], loss: 1.2624
 Epoch [1/10], Step[140/483], loss: 1.4382
 Epoch [1/10], Step[150/483], loss: 1.4735
 Epoch [1/10], Step[160/483], loss: 1.6159
 Epoch [1/10], Step[170/483], loss: 1.0246
 Epoch [1/10], Step[180/483], loss: 1.4148
 Epoch [1/10], Step[190/483], loss: 1.4016
 Epoch [1/10], Step[200/483], loss: 0.9954
 Epoch [1/10], Step[210/483], loss: 1.2282
 Epoch [1/10], Step[220/483], loss: 1.0795
 Epoch [1/10], Step[230/483], loss: 1.0170
 Epoch [1/10], Step[240/483], loss: 1.2569
 Epoch [1/10], Step[250/483], loss: 1.2916
 Epoch [1/10], Step[260/483], loss: 0.8188
 Epoch [1/10], Step[270/483], loss: 1.2268
 Epoch [1/10], Step[280/483], loss: 1.0184
 Epoch [1/10], Step[290/483], loss: 0.8649
 Epoch [1/10], Step[300/483], loss: 1.2174
 Epoch [1/10], Step[310/483], loss: 1.1932
 Epoch [1/10], Step[320/483], loss: 1.3194
 Epoch [1/10], Step[330/483], loss: 1.1711
 Epoch [1/10], Step[340/483], loss: 1.2047
 Epoch [1/10], Step[350/483], loss: 1.1579
 Epoch [1/10], Step[360/483], loss: 0.8983
 Epoch [1/10], Step[370/483], loss: 0.7559
 Epoch [1/10], Step[380/483], loss: 1.0103
 Epoch [1/10], Step[390/483], loss: 1.1337
 Epoch [1/10], Step[400/483], loss: 1.0984
 Epoch [1/10], Step[410/483], loss: 0.8611
 Epoch [1/10], Step[420/483], loss: 1.0568
 Epoch [1/10], Step[430/483], loss: 1.0463
 Epoch [1/10], Step[440/483], loss: 1.1054
 Epoch [1/10], Step[450/483], loss: 0.9169
 Epoch [1/10], Step[460/483], loss: 1.2148
 Epoch [1/10], Step[470/483], loss: 1.3034
 Epoch [1/10], Step[480/483], loss: 0.7191
 ====> Epoch 1: Training loss: 682.6848
 Epoch [2/10], Step[0/483], loss: 0.9333
 Epoch [2/10], Step[10/483], loss: 1.0603
 Epoch [2/10], Step[20/483], loss: 1.1624
 Epoch [2/10], Step[30/483], loss: 1.0871
 Epoch [2/10], Step[40/483], loss: 1.1354
 Epoch [2/10], Step[50/483], loss: 1.2225
 Epoch [2/10], Step[60/483], loss: 1.3196
 Epoch [2/10], Step[70/483], loss: 1.1894
 Epoch [2/10], Step[80/483], loss: 1.3494
 Epoch [2/10], Step[90/483], loss: 0.9179
 Epoch [2/10], Step[100/483], loss: 0.9100
 Epoch [2/10], Step[110/483], loss: 1.0831
 Epoch [2/10], Step[120/483], loss: 1.1749
 Epoch [2/10], Step[130/483], loss: 0.9643
 Epoch [2/10], Step[140/483], loss: 1.1211
 Epoch [2/10], Step[150/483], loss: 1.1435
 Epoch [2/10], Step[160/483], loss: 1.2906
 Epoch [2/10], Step[170/483], loss: 0.8569
 Epoch [2/10], Step[180/483], loss: 1.2146
 Epoch [2/10], Step[190/483], loss: 1.1550
 Epoch [2/10], Step[200/483], loss: 0.8528
 Epoch [2/10], Step[210/483], loss: 1.0474
 Epoch [2/10], Step[220/483], loss: 0.9233
 Epoch [2/10], Step[230/483], loss: 0.8340
 Epoch [2/10], Step[240/483], loss: 1.0936
 Epoch [2/10], Step[250/483], loss: 1.0883
 Epoch [2/10], Step[260/483], loss: 0.6915
 Epoch [2/10], Step[270/483], loss: 1.0467
 Epoch [2/10], Step[280/483], loss: 0.9053
 Epoch [2/10], Step[290/483], loss: 0.7581
 Epoch [2/10], Step[300/483], loss: 1.0778
 Epoch [2/10], Step[310/483], loss: 1.0716
 Epoch [2/10], Step[320/483], loss: 1.1368
 Epoch [2/10], Step[330/483], loss: 1.0436
 Epoch [2/10], Step[340/483], loss: 1.0524
 Epoch [2/10], Step[350/483], loss: 1.0274
 Epoch [2/10], Step[360/483], loss: 0.7939
 Epoch [2/10], Step[370/483], loss: 0.6926
 Epoch [2/10], Step[380/483], loss: 0.9204
 Epoch [2/10], Step[390/483], loss: 1.0356
 Epoch [2/10], Step[400/483], loss: 0.9781
 Epoch [2/10], Step[410/483], loss: 0.7859
 Epoch [2/10], Step[420/483], loss: 0.9509
 Epoch [2/10], Step[430/483], loss: 0.9752
 Epoch [2/10], Step[440/483], loss: 0.9906
 Epoch [2/10], Step[450/483], loss: 0.8206
 Epoch [2/10], Step[460/483], loss: 1.1058
 Epoch [2/10], Step[470/483], loss: 1.1655
 Epoch [2/10], Step[480/483], loss: 0.6705
 ====> Epoch 2: Training loss: 504.8275
 Epoch [3/10], Step[0/483], loss: 0.8371
 Epoch [3/10], Step[10/483], loss: 0.9752
 Epoch [3/10], Step[20/483], loss: 1.0835
 Epoch [3/10], Step[30/483], loss: 1.0018
 Epoch [3/10], Step[40/483], loss: 1.0436
 Epoch [3/10], Step[50/483], loss: 1.1256
 Epoch [3/10], Step[60/483], loss: 1.2129
 Epoch [3/10], Step[70/483], loss: 1.0987
 Epoch [3/10], Step[80/483], loss: 1.2603
 Epoch [3/10], Step[90/483], loss: 0.8522
 Epoch [3/10], Step[100/483], loss: 0.8501
 Epoch [3/10], Step[110/483], loss: 1.0080
 Epoch [3/10], Step[120/483], loss: 1.0743
 Epoch [3/10], Step[130/483], loss: 0.9049
 Epoch [3/10], Step[140/483], loss: 1.0477
 Epoch [3/10], Step[150/483], loss: 1.0549
 Epoch [3/10], Step[160/483], loss: 1.2066
 Epoch [3/10], Step[170/483], loss: 0.8056
 Epoch [3/10], Step[180/483], loss: 1.1194
 Epoch [3/10], Step[190/483], loss: 1.0881
 Epoch [3/10], Step[200/483], loss: 0.7916
 Epoch [3/10], Step[210/483], loss: 0.9911
 Epoch [3/10], Step[220/483], loss: 0.8783
 Epoch [3/10], Step[230/483], loss: 0.7767
 Epoch [3/10], Step[240/483], loss: 1.0316
 Epoch [3/10], Step[250/483], loss: 1.0237
 Epoch [3/10], Step[260/483], loss: 0.6620
 Epoch [3/10], Step[270/483], loss: 0.9694
 Epoch [3/10], Step[280/483], loss: 0.8671
 Epoch [3/10], Step[290/483], loss: 0.7001
 Epoch [3/10], Step[300/483], loss: 1.0137
 Epoch [3/10], Step[310/483], loss: 1.0187
 Epoch [3/10], Step[320/483], loss: 1.0815
 Epoch [3/10], Step[330/483], loss: 0.9803
 Epoch [3/10], Step[340/483], loss: 0.9870
 Epoch [3/10], Step[350/483], loss: 0.9797
 Epoch [3/10], Step[360/483], loss: 0.7412
 Epoch [3/10], Step[370/483], loss: 0.6559
 Epoch [3/10], Step[380/483], loss: 0.8864
 Epoch [3/10], Step[390/483], loss: 0.9771
 Epoch [3/10], Step[400/483], loss: 0.9411
 Epoch [3/10], Step[410/483], loss: 0.7630
 Epoch [3/10], Step[420/483], loss: 0.9049
 Epoch [3/10], Step[430/483], loss: 0.9256
 Epoch [3/10], Step[440/483], loss: 0.9224
 Epoch [3/10], Step[450/483], loss: 0.7836
 Epoch [3/10], Step[460/483], loss: 1.0492
 Epoch [3/10], Step[470/483], loss: 1.0895
 Epoch [3/10], Step[480/483], loss: 0.6412
 ====> Epoch 3: Training loss: 473.0737
 Epoch [4/10], Step[0/483], loss: 0.8025
 Epoch [4/10], Step[10/483], loss: 0.9239
 Epoch [4/10], Step[20/483], loss: 1.0366
 Epoch [4/10], Step[30/483], loss: 0.9628
 Epoch [4/10], Step[40/483], loss: 1.0006
 Epoch [4/10], Step[50/483], loss: 1.0757
 Epoch [4/10], Step[60/483], loss: 1.1433
 Epoch [4/10], Step[70/483], loss: 1.0495
 Epoch [4/10], Step[80/483], loss: 1.1807
 Epoch [4/10], Step[90/483], loss: 0.8135
 Epoch [4/10], Step[100/483], loss: 0.8222
 Epoch [4/10], Step[110/483], loss: 0.9635
 Epoch [4/10], Step[120/483], loss: 1.0238
 Epoch [4/10], Step[130/483], loss: 0.8759
 Epoch [4/10], Step[140/483], loss: 1.0032
 Epoch [4/10], Step[150/483], loss: 1.0090
 Epoch [4/10], Step[160/483], loss: 1.1319
 Epoch [4/10], Step[170/483], loss: 0.7618
 Epoch [4/10], Step[180/483], loss: 1.0656
 Epoch [4/10], Step[190/483], loss: 1.0562
 Epoch [4/10], Step[200/483], loss: 0.7648
 Epoch [4/10], Step[210/483], loss: 0.9347
 Epoch [4/10], Step[220/483], loss: 0.8237
 Epoch [4/10], Step[230/483], loss: 0.7628
 Epoch [4/10], Step[240/483], loss: 0.9822
 Epoch [4/10], Step[250/483], loss: 0.9863
 Epoch [4/10], Step[260/483], loss: 0.6407
 Epoch [4/10], Step[270/483], loss: 0.9274
 Epoch [4/10], Step[280/483], loss: 0.8393
 Epoch [4/10], Step[290/483], loss: 0.6845
 Epoch [4/10], Step[300/483], loss: 0.9823
 Epoch [4/10], Step[310/483], loss: 0.9660
 Epoch [4/10], Step[320/483], loss: 1.0452
 Epoch [4/10], Step[330/483], loss: 0.9416
 Epoch [4/10], Step[340/483], loss: 0.9541
 Epoch [4/10], Step[350/483], loss: 0.9283
 Epoch [4/10], Step[360/483], loss: 0.7147
 Epoch [4/10], Step[370/483], loss: 0.6296
 Epoch [4/10], Step[380/483], loss: 0.8519
 Epoch [4/10], Step[390/483], loss: 0.9512
 Epoch [4/10], Step[400/483], loss: 0.9039
 Epoch [4/10], Step[410/483], loss: 0.7420
 Epoch [4/10], Step[420/483], loss: 0.8791
 Epoch [4/10], Step[430/483], loss: 0.8860
 Epoch [4/10], Step[440/483], loss: 0.8934
 Epoch [4/10], Step[450/483], loss: 0.7583
 Epoch [4/10], Step[460/483], loss: 1.0045
 Epoch [4/10], Step[470/483], loss: 1.0571
 Epoch [4/10], Step[480/483], loss: 0.6153
 ====> Epoch 4: Training loss: 452.7387
 Epoch [5/10], Step[0/483], loss: 0.7779
 Epoch [5/10], Step[10/483], loss: 0.8975
 Epoch [5/10], Step[20/483], loss: 1.0096
 Epoch [5/10], Step[30/483], loss: 0.9293
 Epoch [5/10], Step[40/483], loss: 0.9574
 Epoch [5/10], Step[50/483], loss: 1.0362
 Epoch [5/10], Step[60/483], loss: 1.1031
 Epoch [5/10], Step[70/483], loss: 1.0185
 Epoch [5/10], Step[80/483], loss: 1.1354
 Epoch [5/10], Step[90/483], loss: 0.7917
 Epoch [5/10], Step[100/483], loss: 0.7924
 Epoch [5/10], Step[110/483], loss: 0.9281
 Epoch [5/10], Step[120/483], loss: 0.9883
 Epoch [5/10], Step[130/483], loss: 0.8384
 Epoch [5/10], Step[140/483], loss: 0.9854
 Epoch [5/10], Step[150/483], loss: 0.9898
 Epoch [5/10], Step[160/483], loss: 1.0806
 Epoch [5/10], Step[170/483], loss: 0.7353
 Epoch [5/10], Step[180/483], loss: 1.0575
 Epoch [5/10], Step[190/483], loss: 1.0248
 Epoch [5/10], Step[200/483], loss: 0.7451
 Epoch [5/10], Step[210/483], loss: 0.9140
 Epoch [5/10], Step[220/483], loss: 0.7975
 Epoch [5/10], Step[230/483], loss: 0.7432
 Epoch [5/10], Step[240/483], loss: 0.9571
 Epoch [5/10], Step[250/483], loss: 0.9653
 Epoch [5/10], Step[260/483], loss: 0.6265
 Epoch [5/10], Step[270/483], loss: 0.9089
 Epoch [5/10], Step[280/483], loss: 0.8132
 Epoch [5/10], Step[290/483], loss: 0.6699
 Epoch [5/10], Step[300/483], loss: 0.9591
 Epoch [5/10], Step[310/483], loss: 0.9308
 Epoch [5/10], Step[320/483], loss: 1.0148
 Epoch [5/10], Step[330/483], loss: 0.9129
 Epoch [5/10], Step[340/483], loss: 0.9173
 Epoch [5/10], Step[350/483], loss: 0.9133
 Epoch [5/10], Step[360/483], loss: 0.6889
 Epoch [5/10], Step[370/483], loss: 0.6237
 Epoch [5/10], Step[380/483], loss: 0.8203
 Epoch [5/10], Step[390/483], loss: 0.9302
 Epoch [5/10], Step[400/483], loss: 0.8756
 Epoch [5/10], Step[410/483], loss: 0.7406
 Epoch [5/10], Step[420/483], loss: 0.8550
 Epoch [5/10], Step[430/483], loss: 0.8720
 Epoch [5/10], Step[440/483], loss: 0.8614
 Epoch [5/10], Step[450/483], loss: 0.7345
 Epoch [5/10], Step[460/483], loss: 0.9790
 Epoch [5/10], Step[470/483], loss: 1.0393
 Epoch [5/10], Step[480/483], loss: 0.5959
 ====> Epoch 5: Training loss: 438.6768
 Epoch [6/10], Step[0/483], loss: 0.7645
 Epoch [6/10], Step[10/483], loss: 0.8686
 Epoch [6/10], Step[20/483], loss: 0.9724
 Epoch [6/10], Step[30/483], loss: 0.9015
 Epoch [6/10], Step[40/483], loss: 0.9394
 Epoch [6/10], Step[50/483], loss: 0.9911
 Epoch [6/10], Step[60/483], loss: 1.0675
 Epoch [6/10], Step[70/483], loss: 0.9725
 Epoch [6/10], Step[80/483], loss: 1.0961
 Epoch [6/10], Step[90/483], loss: 0.7600
 Epoch [6/10], Step[100/483], loss: 0.7722
 Epoch [6/10], Step[110/483], loss: 0.9111
 Epoch [6/10], Step[120/483], loss: 0.9787
 Epoch [6/10], Step[130/483], loss: 0.8269
 Epoch [6/10], Step[140/483], loss: 0.9471
 Epoch [6/10], Step[150/483], loss: 0.9750
 Epoch [6/10], Step[160/483], loss: 1.0691
 Epoch [6/10], Step[170/483], loss: 0.7103
 Epoch [6/10], Step[180/483], loss: 1.0232
 Epoch [6/10], Step[190/483], loss: 1.0078
 Epoch [6/10], Step[200/483], loss: 0.7317
 Epoch [6/10], Step[210/483], loss: 0.9037
 Epoch [6/10], Step[220/483], loss: 0.7732
 Epoch [6/10], Step[230/483], loss: 0.7369
 Epoch [6/10], Step[240/483], loss: 0.9346
 Epoch [6/10], Step[250/483], loss: 0.9605
 Epoch [6/10], Step[260/483], loss: 0.6107
 Epoch [6/10], Step[270/483], loss: 0.8874
 Epoch [6/10], Step[280/483], loss: 0.8001
 Epoch [6/10], Step[290/483], loss: 0.6616
 Epoch [6/10], Step[300/483], loss: 0.9383
 Epoch [6/10], Step[310/483], loss: 0.9081
 Epoch [6/10], Step[320/483], loss: 1.0033
 Epoch [6/10], Step[330/483], loss: 0.9032
 Epoch [6/10], Step[340/483], loss: 0.9081
 Epoch [6/10], Step[350/483], loss: 0.9005
 Epoch [6/10], Step[360/483], loss: 0.6678
 Epoch [6/10], Step[370/483], loss: 0.6141
 Epoch [6/10], Step[380/483], loss: 0.7994
 Epoch [6/10], Step[390/483], loss: 0.9215
 Epoch [6/10], Step[400/483], loss: 0.8478
 Epoch [6/10], Step[410/483], loss: 0.7241
 Epoch [6/10], Step[420/483], loss: 0.8451
 Epoch [6/10], Step[430/483], loss: 0.8559
 Epoch [6/10], Step[440/483], loss: 0.8386
 Epoch [6/10], Step[450/483], loss: 0.7156
 Epoch [6/10], Step[460/483], loss: 0.9662
 Epoch [6/10], Step[470/483], loss: 1.0308
 Epoch [6/10], Step[480/483], loss: 0.5885
 ====> Epoch 6: Training loss: 428.6863
 Epoch [7/10], Step[0/483], loss: 0.7511
 Epoch [7/10], Step[10/483], loss: 0.8522
 Epoch [7/10], Step[20/483], loss: 0.9506
 Epoch [7/10], Step[30/483], loss: 0.8771
 Epoch [7/10], Step[40/483], loss: 0.9215
 Epoch [7/10], Step[50/483], loss: 0.9681
 Epoch [7/10], Step[60/483], loss: 1.0458
 Epoch [7/10], Step[70/483], loss: 0.9635
 Epoch [7/10], Step[80/483], loss: 1.0808
 Epoch [7/10], Step[90/483], loss: 0.7481
 Epoch [7/10], Step[100/483], loss: 0.7622
 Epoch [7/10], Step[110/483], loss: 0.8931
 Epoch [7/10], Step[120/483], loss: 0.9669
 Epoch [7/10], Step[130/483], loss: 0.7921
 Epoch [7/10], Step[140/483], loss: 0.9341
 Epoch [7/10], Step[150/483], loss: 0.9527
 Epoch [7/10], Step[160/483], loss: 1.0356
 Epoch [7/10], Step[170/483], loss: 0.6832
 Epoch [7/10], Step[180/483], loss: 0.9923
 Epoch [7/10], Step[190/483], loss: 0.9911
 Epoch [7/10], Step[200/483], loss: 0.7181
 Epoch [7/10], Step[210/483], loss: 0.8847
 Epoch [7/10], Step[220/483], loss: 0.7561
 Epoch [7/10], Step[230/483], loss: 0.7157
 Epoch [7/10], Step[240/483], loss: 0.9246
 Epoch [7/10], Step[250/483], loss: 0.9376
 Epoch [7/10], Step[260/483], loss: 0.5969
 Epoch [7/10], Step[270/483], loss: 0.8805
 Epoch [7/10], Step[280/483], loss: 0.7690
 Epoch [7/10], Step[290/483], loss: 0.6608
 Epoch [7/10], Step[300/483], loss: 0.9228
 Epoch [7/10], Step[310/483], loss: 0.8883
 Epoch [7/10], Step[320/483], loss: 0.9810
 Epoch [7/10], Step[330/483], loss: 0.8804
 Epoch [7/10], Step[340/483], loss: 0.8873
 Epoch [7/10], Step[350/483], loss: 0.8731
 Epoch [7/10], Step[360/483], loss: 0.6594
 Epoch [7/10], Step[370/483], loss: 0.6025
 Epoch [7/10], Step[380/483], loss: 0.7879
 Epoch [7/10], Step[390/483], loss: 0.9034
 Epoch [7/10], Step[400/483], loss: 0.8238
 Epoch [7/10], Step[410/483], loss: 0.7209
 Epoch [7/10], Step[420/483], loss: 0.8231
 Epoch [7/10], Step[430/483], loss: 0.8474
 Epoch [7/10], Step[440/483], loss: 0.8311
 Epoch [7/10], Step[450/483], loss: 0.7094
 Epoch [7/10], Step[460/483], loss: 0.9524
 Epoch [7/10], Step[470/483], loss: 0.9981
 Epoch [7/10], Step[480/483], loss: 0.5819
 ====> Epoch 7: Training loss: 421.0266
 Epoch [8/10], Step[0/483], loss: 0.7409
 Epoch [8/10], Step[10/483], loss: 0.8404
 Epoch [8/10], Step[20/483], loss: 0.9237
 Epoch [8/10], Step[30/483], loss: 0.8596
 Epoch [8/10], Step[40/483], loss: 0.9036
 Epoch [8/10], Step[50/483], loss: 0.9543
 Epoch [8/10], Step[60/483], loss: 1.0231
 Epoch [8/10], Step[70/483], loss: 0.9364
 Epoch [8/10], Step[80/483], loss: 1.0750
 Epoch [8/10], Step[90/483], loss: 0.7428
 Epoch [8/10], Step[100/483], loss: 0.7633
 Epoch [8/10], Step[110/483], loss: 0.8804
 Epoch [8/10], Step[120/483], loss: 0.9683
 Epoch [8/10], Step[130/483], loss: 0.7914
 Epoch [8/10], Step[140/483], loss: 0.9248
 Epoch [8/10], Step[150/483], loss: 0.9330
 Epoch [8/10], Step[160/483], loss: 1.0274
 Epoch [8/10], Step[170/483], loss: 0.6778
 Epoch [8/10], Step[180/483], loss: 0.9964
 Epoch [8/10], Step[190/483], loss: 0.9763
 Epoch [8/10], Step[200/483], loss: 0.6973
 Epoch [8/10], Step[210/483], loss: 0.8689
 Epoch [8/10], Step[220/483], loss: 0.7500
 Epoch [8/10], Step[230/483], loss: 0.7149
 Epoch [8/10], Step[240/483], loss: 0.8914
 Epoch [8/10], Step[250/483], loss: 0.9280
 Epoch [8/10], Step[260/483], loss: 0.5942
 Epoch [8/10], Step[270/483], loss: 0.8499
 Epoch [8/10], Step[280/483], loss: 0.7560
 Epoch [8/10], Step[290/483], loss: 0.6517
 Epoch [8/10], Step[300/483], loss: 0.9092
 Epoch [8/10], Step[310/483], loss: 0.8658
 Epoch [8/10], Step[320/483], loss: 0.9598
 Epoch [8/10], Step[330/483], loss: 0.8712
 Epoch [8/10], Step[340/483], loss: 0.8700
 Epoch [8/10], Step[350/483], loss: 0.8622
 Epoch [8/10], Step[360/483], loss: 0.6439
 Epoch [8/10], Step[370/483], loss: 0.6029
 Epoch [8/10], Step[380/483], loss: 0.7712
 Epoch [8/10], Step[390/483], loss: 0.8667
 Epoch [8/10], Step[400/483], loss: 0.8079
 Epoch [8/10], Step[410/483], loss: 0.7073
 Epoch [8/10], Step[420/483], loss: 0.8185
 Epoch [8/10], Step[430/483], loss: 0.8297
 Epoch [8/10], Step[440/483], loss: 0.8079
 Epoch [8/10], Step[450/483], loss: 0.6971
 Epoch [8/10], Step[460/483], loss: 0.9388
 Epoch [8/10], Step[470/483], loss: 0.9853
 Epoch [8/10], Step[480/483], loss: 0.5756
 ====> Epoch 8: Training loss: 414.5068
 Epoch [9/10], Step[0/483], loss: 0.7323
 Epoch [9/10], Step[10/483], loss: 0.8388
 Epoch [9/10], Step[20/483], loss: 0.9213
 Epoch [9/10], Step[30/483], loss: 0.8508
 Epoch [9/10], Step[40/483], loss: 0.8945
 Epoch [9/10], Step[50/483], loss: 0.9333
 Epoch [9/10], Step[60/483], loss: 1.0182
 Epoch [9/10], Step[70/483], loss: 0.9360
 Epoch [9/10], Step[80/483], loss: 1.0611
 Epoch [9/10], Step[90/483], loss: 0.7344
 Epoch [9/10], Step[100/483], loss: 0.7427
 Epoch [9/10], Step[110/483], loss: 0.8778
 Epoch [9/10], Step[120/483], loss: 0.9522
 Epoch [9/10], Step[130/483], loss: 0.7739
 Epoch [9/10], Step[140/483], loss: 0.9209
 Epoch [9/10], Step[150/483], loss: 0.9183
 Epoch [9/10], Step[160/483], loss: 1.0058
 Epoch [9/10], Step[170/483], loss: 0.6551
 Epoch [9/10], Step[180/483], loss: 0.9643
 Epoch [9/10], Step[190/483], loss: 0.9644
 Epoch [9/10], Step[200/483], loss: 0.7003
 Epoch [9/10], Step[210/483], loss: 0.8602
 Epoch [9/10], Step[220/483], loss: 0.7484
 Epoch [9/10], Step[230/483], loss: 0.7077
 Epoch [9/10], Step[240/483], loss: 0.8795
 Epoch [9/10], Step[250/483], loss: 0.8985
 Epoch [9/10], Step[260/483], loss: 0.5844
 Epoch [9/10], Step[270/483], loss: 0.8509
 Epoch [9/10], Step[280/483], loss: 0.7475
 Epoch [9/10], Step[290/483], loss: 0.6493
 Epoch [9/10], Step[300/483], loss: 0.8726
 Epoch [9/10], Step[310/483], loss: 0.8674
 Epoch [9/10], Step[320/483], loss: 0.9528
 Epoch [9/10], Step[330/483], loss: 0.8697
 Epoch [9/10], Step[340/483], loss: 0.8573
 Epoch [9/10], Step[350/483], loss: 0.8590
 Epoch [9/10], Step[360/483], loss: 0.6408
 Epoch [9/10], Step[370/483], loss: 0.5809
 Epoch [9/10], Step[380/483], loss: 0.7573
 Epoch [9/10], Step[390/483], loss: 0.8576
 Epoch [9/10], Step[400/483], loss: 0.8030
 Epoch [9/10], Step[410/483], loss: 0.7149
 Epoch [9/10], Step[420/483], loss: 0.7906
 Epoch [9/10], Step[430/483], loss: 0.8274
 Epoch [9/10], Step[440/483], loss: 0.7924
 Epoch [9/10], Step[450/483], loss: 0.6892
 Epoch [9/10], Step[460/483], loss: 0.9305
 Epoch [9/10], Step[470/483], loss: 0.9819
 Epoch [9/10], Step[480/483], loss: 0.5689
 ====> Epoch 9: Training loss: 409.4331
 Epoch [10/10], Step[0/483], loss: 0.7302
 Epoch [10/10], Step[10/483], loss: 0.8296
 Epoch [10/10], Step[20/483], loss: 0.9023
 Epoch [10/10], Step[30/483], loss: 0.8407
 Epoch [10/10], Step[40/483], loss: 0.8793
 Epoch [10/10], Step[50/483], loss: 0.9145
 Epoch [10/10], Step[60/483], loss: 0.9875
 Epoch [10/10], Step[70/483], loss: 0.9357
 Epoch [10/10], Step[80/483], loss: 1.0525
 Epoch [10/10], Step[90/483], loss: 0.7281
 Epoch [10/10], Step[100/483], loss: 0.7373
 Epoch [10/10], Step[110/483], loss: 0.8867
 Epoch [10/10], Step[120/483], loss: 0.9456
 Epoch [10/10], Step[130/483], loss: 0.7756
 Epoch [10/10], Step[140/483], loss: 0.9028
 Epoch [10/10], Step[150/483], loss: 0.8899
 Epoch [10/10], Step[160/483], loss: 0.9918
 Epoch [10/10], Step[170/483], loss: 0.6514
 Epoch [10/10], Step[180/483], loss: 0.9659
 Epoch [10/10], Step[190/483], loss: 0.9610
 Epoch [10/10], Step[200/483], loss: 0.7003
 Epoch [10/10], Step[210/483], loss: 0.8592
 Epoch [10/10], Step[220/483], loss: 0.7468
 Epoch [10/10], Step[230/483], loss: 0.7092
 Epoch [10/10], Step[240/483], loss: 0.8685
 Epoch [10/10], Step[250/483], loss: 0.8860
 Epoch [10/10], Step[260/483], loss: 0.5810
 Epoch [10/10], Step[270/483], loss: 0.8466
 Epoch [10/10], Step[280/483], loss: 0.7399
 Epoch [10/10], Step[290/483], loss: 0.6376
 Epoch [10/10], Step[300/483], loss: 0.8725
 Epoch [10/10], Step[310/483], loss: 0.8569
 Epoch [10/10], Step[320/483], loss: 0.9276
 Epoch [10/10], Step[330/483], loss: 0.8556
 Epoch [10/10], Step[340/483], loss: 0.8472
 Epoch [10/10], Step[350/483], loss: 0.8400
 Epoch [10/10], Step[360/483], loss: 0.6428
 Epoch [10/10], Step[370/483], loss: 0.5908
 Epoch [10/10], Step[380/483], loss: 0.7592
 Epoch [10/10], Step[390/483], loss: 0.8463
 Epoch [10/10], Step[400/483], loss: 0.8018
 Epoch [10/10], Step[410/483], loss: 0.7085
 Epoch [10/10], Step[420/483], loss: 0.8029
 Epoch [10/10], Step[430/483], loss: 0.8236
 Epoch [10/10], Step[440/483], loss: 0.7888
 Epoch [10/10], Step[450/483], loss: 0.6799
 Epoch [10/10], Step[460/483], loss: 0.9351
 Epoch [10/10], Step[470/483], loss: 0.9780
 Epoch [10/10], Step[480/483], loss: 0.5638
 ====> Epoch 10: Training loss: 405.1886
