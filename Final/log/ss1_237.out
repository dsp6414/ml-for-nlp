 Loading feature files...
 <s> = 1
 </s> = 2
 All scenes loaded.
 Hyperparameters:Namespace(LR=0.01, alternatives=1, batch_size=100, dec='LSTM', dropout=0.3, epochs=10, hidden_sz=100, k=20, load=None, log_interval=10, model='ss1', no_cuda=False, save='True', seed=1)
 Listener0: Listener0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=100)
  )
  (string_encoder): LinearStringEncoder(
    (fc): Linear(in_features=1063, out_features=100)
  )
  (scorer): MLPScorer(
    (dropout): Dropout(p=0.3)
    (linear_4): Linear(in_features=100, out_features=100)
    (linear_5): Linear(in_features=100, out_features=100)
    (linear_3): Linear(in_features=100, out_features=1)
  )
)
 Speaker0: Speaker0Model(
  (scene_encoder): LinearSceneEncoder(
    (fc): Linear(in_features=280, out_features=100)
  )
  (string_decoder): LSTMStringDecoder(
    (embedding): Embedding(1063, 100)
    (lstm): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.3)
    (linear): Linear(in_features=100, out_features=1063)
    (dropout): Dropout(p=0.3)
  )
)
 Training Listener0...
 Epoch [1/10], Step[0/483], loss: 0.6966
 Epoch [1/10], Step[10/483], loss: 0.7118
 Epoch [1/10], Step[20/483], loss: 0.6812
 Epoch [1/10], Step[30/483], loss: 0.6982
 Epoch [1/10], Step[40/483], loss: 0.7079
 Epoch [1/10], Step[50/483], loss: 0.6977
 Epoch [1/10], Step[60/483], loss: 0.6979
 Epoch [1/10], Step[70/483], loss: 0.6896
 Epoch [1/10], Step[80/483], loss: 0.6864
 Epoch [1/10], Step[90/483], loss: 0.6814
 Epoch [1/10], Step[100/483], loss: 0.6901
 Epoch [1/10], Step[110/483], loss: 0.7176
 Epoch [1/10], Step[120/483], loss: 0.6936
 Epoch [1/10], Step[130/483], loss: 0.6906
 Epoch [1/10], Step[140/483], loss: 0.6985
 Epoch [1/10], Step[150/483], loss: 0.7530
 Epoch [1/10], Step[160/483], loss: 0.6941
 Epoch [1/10], Step[170/483], loss: 0.6858
 Epoch [1/10], Step[180/483], loss: 0.6895
 Epoch [1/10], Step[190/483], loss: 0.6729
 Epoch [1/10], Step[200/483], loss: 0.6333
 Epoch [1/10], Step[210/483], loss: 0.7825
 Epoch [1/10], Step[220/483], loss: 0.6742
 Epoch [1/10], Step[230/483], loss: 0.7168
 Epoch [1/10], Step[240/483], loss: 0.6258
 Epoch [1/10], Step[250/483], loss: 0.6360
 Epoch [1/10], Step[260/483], loss: 0.6672
 Epoch [1/10], Step[270/483], loss: 0.7360
 Epoch [1/10], Step[280/483], loss: 0.6949
 Epoch [1/10], Step[290/483], loss: 0.6320
 Epoch [1/10], Step[300/483], loss: 0.6471
 Epoch [1/10], Step[310/483], loss: 0.7010
 Epoch [1/10], Step[320/483], loss: 0.6648
 Epoch [1/10], Step[330/483], loss: 0.6781
 Epoch [1/10], Step[340/483], loss: 0.6281
 Epoch [1/10], Step[350/483], loss: 0.7383
 Epoch [1/10], Step[360/483], loss: 0.6627
 Epoch [1/10], Step[370/483], loss: 0.6013
 Epoch [1/10], Step[380/483], loss: 0.6656
 Epoch [1/10], Step[390/483], loss: 0.6339
 Epoch [1/10], Step[400/483], loss: 0.6145
 Epoch [1/10], Step[410/483], loss: 0.7330
 Epoch [1/10], Step[420/483], loss: 0.5217
 Epoch [1/10], Step[430/483], loss: 0.7607
 Epoch [1/10], Step[440/483], loss: 0.6669
 Epoch [1/10], Step[450/483], loss: 0.5796
 Epoch [1/10], Step[460/483], loss: 0.6848
 Epoch [1/10], Step[470/483], loss: 0.6536
 Epoch [1/10], Step[480/483], loss: 0.6956
 ====> Epoch 1: Training loss: 325.9539
 Training Accuracy: 0.650290
 ====> Epoch 1: Validation loss: 37.7066
 Validation Accuracy: 0.900833
 Epoch [2/10], Step[0/483], loss: 0.6588
 Epoch [2/10], Step[10/483], loss: 0.6461
 Epoch [2/10], Step[20/483], loss: 0.5321
 Epoch [2/10], Step[30/483], loss: 0.6530
 Epoch [2/10], Step[40/483], loss: 0.5341
 Epoch [2/10], Step[50/483], loss: 0.6670
 Epoch [2/10], Step[60/483], loss: 0.6368
 Epoch [2/10], Step[70/483], loss: 0.5714
 Epoch [2/10], Step[80/483], loss: 0.6657
 Epoch [2/10], Step[90/483], loss: 0.5649
 Epoch [2/10], Step[100/483], loss: 0.6169
 Epoch [2/10], Step[110/483], loss: 0.6452
 Epoch [2/10], Step[120/483], loss: 0.5856
 Epoch [2/10], Step[130/483], loss: 0.6464
 Epoch [2/10], Step[140/483], loss: 0.4647
 Epoch [2/10], Step[150/483], loss: 0.5890
 Epoch [2/10], Step[160/483], loss: 0.6196
 Epoch [2/10], Step[170/483], loss: 0.6213
 Epoch [2/10], Step[180/483], loss: 0.4994
 Epoch [2/10], Step[190/483], loss: 0.6041
 Epoch [2/10], Step[200/483], loss: 0.4680
 Epoch [2/10], Step[210/483], loss: 0.3767
 Epoch [2/10], Step[220/483], loss: 0.5943
 Epoch [2/10], Step[230/483], loss: 0.5758
 Epoch [2/10], Step[240/483], loss: 0.5833
 Epoch [2/10], Step[250/483], loss: 0.5052
 Epoch [2/10], Step[260/483], loss: 0.4407
 Epoch [2/10], Step[270/483], loss: 0.4594
 Epoch [2/10], Step[280/483], loss: 0.6132
 Epoch [2/10], Step[290/483], loss: 0.5753
 Epoch [2/10], Step[300/483], loss: 0.7058
 Epoch [2/10], Step[310/483], loss: 0.5822
 Epoch [2/10], Step[320/483], loss: 0.8169
 Epoch [2/10], Step[330/483], loss: 0.5125
 Epoch [2/10], Step[340/483], loss: 0.4989
 Epoch [2/10], Step[350/483], loss: 0.5926
 Epoch [2/10], Step[360/483], loss: 0.6983
 Epoch [2/10], Step[370/483], loss: 0.4642
 Epoch [2/10], Step[380/483], loss: 0.6151
 Epoch [2/10], Step[390/483], loss: 0.8241
 Epoch [2/10], Step[400/483], loss: 0.7158
 Epoch [2/10], Step[410/483], loss: 0.4975
 Epoch [2/10], Step[420/483], loss: 0.4286
 Epoch [2/10], Step[430/483], loss: 0.5427
 Epoch [2/10], Step[440/483], loss: 0.6040
 Epoch [2/10], Step[450/483], loss: 0.4636
 Epoch [2/10], Step[460/483], loss: 0.6559
 Epoch [2/10], Step[470/483], loss: 0.4617
 Epoch [2/10], Step[480/483], loss: 0.4804
 ====> Epoch 2: Training loss: 274.3651
 Training Accuracy: 0.695921
 ====> Epoch 2: Validation loss: 32.0041
 Validation Accuracy: 0.707833
 Epoch [3/10], Step[0/483], loss: 0.4679
 Epoch [3/10], Step[10/483], loss: 0.4538
 Epoch [3/10], Step[20/483], loss: 0.6222
 Epoch [3/10], Step[30/483], loss: 0.5451
 Epoch [3/10], Step[40/483], loss: 0.4601
 Epoch [3/10], Step[50/483], loss: 0.4685
 Epoch [3/10], Step[60/483], loss: 0.4707
 Epoch [3/10], Step[70/483], loss: 0.4969
 Epoch [3/10], Step[80/483], loss: 0.4810
 Epoch [3/10], Step[90/483], loss: 0.5033
 Epoch [3/10], Step[100/483], loss: 0.4966
 Epoch [3/10], Step[110/483], loss: 0.4632
 Epoch [3/10], Step[120/483], loss: 0.4528
 Epoch [3/10], Step[130/483], loss: 0.5790
 Epoch [3/10], Step[140/483], loss: 0.4173
 Epoch [3/10], Step[150/483], loss: 0.5987
 Epoch [3/10], Step[160/483], loss: 0.5866
 Epoch [3/10], Step[170/483], loss: 0.5765
 Epoch [3/10], Step[180/483], loss: 0.4610
 Epoch [3/10], Step[190/483], loss: 0.6039
 Epoch [3/10], Step[200/483], loss: 0.4333
 Epoch [3/10], Step[210/483], loss: 0.4563
 Epoch [3/10], Step[220/483], loss: 0.4749
 Epoch [3/10], Step[230/483], loss: 0.4588
 Epoch [3/10], Step[240/483], loss: 0.3674
 Epoch [3/10], Step[250/483], loss: 0.4425
 Epoch [3/10], Step[260/483], loss: 0.3277
 Epoch [3/10], Step[270/483], loss: 0.3896
 Epoch [3/10], Step[280/483], loss: 0.4986
 Epoch [3/10], Step[290/483], loss: 0.5188
 Epoch [3/10], Step[300/483], loss: 0.3943
 Epoch [3/10], Step[310/483], loss: 0.5100
 Epoch [3/10], Step[320/483], loss: 0.6155
 Epoch [3/10], Step[330/483], loss: 0.4443
 Epoch [3/10], Step[340/483], loss: 0.3852
 Epoch [3/10], Step[350/483], loss: 0.4663
 Epoch [3/10], Step[360/483], loss: 0.5588
 Epoch [3/10], Step[370/483], loss: 0.3779
 Epoch [3/10], Step[380/483], loss: 0.5096
 Epoch [3/10], Step[390/483], loss: 0.5101
 Epoch [3/10], Step[400/483], loss: 0.4389
 Epoch [3/10], Step[410/483], loss: 0.4245
 Epoch [3/10], Step[420/483], loss: 0.4764
 Epoch [3/10], Step[430/483], loss: 0.4779
 Epoch [3/10], Step[440/483], loss: 0.4799
 Epoch [3/10], Step[450/483], loss: 0.3348
 Epoch [3/10], Step[460/483], loss: 0.5887
 Epoch [3/10], Step[470/483], loss: 0.3741
 Epoch [3/10], Step[480/483], loss: 0.3835
 ====> Epoch 3: Training loss: 229.8204
 Training Accuracy: 0.755362
 ====> Epoch 3: Validation loss: 28.1703
 Validation Accuracy: 0.742167
 Epoch [4/10], Step[0/483], loss: 0.3808
 Epoch [4/10], Step[10/483], loss: 0.3993
 Epoch [4/10], Step[20/483], loss: 0.4767
 Epoch [4/10], Step[30/483], loss: 0.4827
 Epoch [4/10], Step[40/483], loss: 0.5139
 Epoch [4/10], Step[50/483], loss: 0.3773
 Epoch [4/10], Step[60/483], loss: 0.4588
 Epoch [4/10], Step[70/483], loss: 0.3790
 Epoch [4/10], Step[80/483], loss: 0.4231
 Epoch [4/10], Step[90/483], loss: 0.4483
 Epoch [4/10], Step[100/483], loss: 0.4831
 Epoch [4/10], Step[110/483], loss: 0.4864
 Epoch [4/10], Step[120/483], loss: 0.3808
 Epoch [4/10], Step[130/483], loss: 0.5284
 Epoch [4/10], Step[140/483], loss: 0.3639
 Epoch [4/10], Step[150/483], loss: 0.4637
 Epoch [4/10], Step[160/483], loss: 0.5254
 Epoch [4/10], Step[170/483], loss: 0.4941
 Epoch [4/10], Step[180/483], loss: 0.4137
 Epoch [4/10], Step[190/483], loss: 0.4557
 Epoch [4/10], Step[200/483], loss: 0.4718
 Epoch [4/10], Step[210/483], loss: 0.4257
 Epoch [4/10], Step[220/483], loss: 0.4302
 Epoch [4/10], Step[230/483], loss: 0.3695
 Epoch [4/10], Step[240/483], loss: 0.3641
 Epoch [4/10], Step[250/483], loss: 0.4469
 Epoch [4/10], Step[260/483], loss: 0.4146
 Epoch [4/10], Step[270/483], loss: 0.3440
 Epoch [4/10], Step[280/483], loss: 0.4552
 Epoch [4/10], Step[290/483], loss: 0.5344
 Epoch [4/10], Step[300/483], loss: 0.4380
 Epoch [4/10], Step[310/483], loss: 0.4748
 Epoch [4/10], Step[320/483], loss: 0.3504
 Epoch [4/10], Step[330/483], loss: 0.4333
 Epoch [4/10], Step[340/483], loss: 0.2693
 Epoch [4/10], Step[350/483], loss: 0.3878
 Epoch [4/10], Step[360/483], loss: 0.4131
 Epoch [4/10], Step[370/483], loss: 0.3025
 Epoch [4/10], Step[380/483], loss: 0.4168
 Epoch [4/10], Step[390/483], loss: 0.3574
 Epoch [4/10], Step[400/483], loss: 0.3732
 Epoch [4/10], Step[410/483], loss: 0.3808
 Epoch [4/10], Step[420/483], loss: 0.3430
 Epoch [4/10], Step[430/483], loss: 0.4335
 Epoch [4/10], Step[440/483], loss: 0.4739
 Epoch [4/10], Step[450/483], loss: 0.3489
 Epoch [4/10], Step[460/483], loss: 0.3967
 Epoch [4/10], Step[470/483], loss: 0.3854
 Epoch [4/10], Step[480/483], loss: 0.4130
 ====> Epoch 4: Training loss: 203.9679
 Training Accuracy: 0.782153
 ====> Epoch 4: Validation loss: 24.6040
 Validation Accuracy: 0.793833
 Epoch [5/10], Step[0/483], loss: 0.4149
 Epoch [5/10], Step[10/483], loss: 0.3362
 Epoch [5/10], Step[20/483], loss: 0.4618
 Epoch [5/10], Step[30/483], loss: 0.4399
 Epoch [5/10], Step[40/483], loss: 0.3536
 Epoch [5/10], Step[50/483], loss: 0.3690
 Epoch [5/10], Step[60/483], loss: 0.3618
 Epoch [5/10], Step[70/483], loss: 0.3177
 Epoch [5/10], Step[80/483], loss: 0.4430
 Epoch [5/10], Step[90/483], loss: 0.3167
 Epoch [5/10], Step[100/483], loss: 0.3647
 Epoch [5/10], Step[110/483], loss: 0.3938
 Epoch [5/10], Step[120/483], loss: 0.3714
 Epoch [5/10], Step[130/483], loss: 0.5442
 Epoch [5/10], Step[140/483], loss: 0.3720
 Epoch [5/10], Step[150/483], loss: 0.3093
 Epoch [5/10], Step[160/483], loss: 0.3880
 Epoch [5/10], Step[170/483], loss: 0.4143
 Epoch [5/10], Step[180/483], loss: 0.4992
 Epoch [5/10], Step[190/483], loss: 0.2877
 Epoch [5/10], Step[200/483], loss: 0.4582
 Epoch [5/10], Step[210/483], loss: 0.3940
 Epoch [5/10], Step[220/483], loss: 0.4164
 Epoch [5/10], Step[230/483], loss: 0.5044
 Epoch [5/10], Step[240/483], loss: 0.2859
 Epoch [5/10], Step[250/483], loss: 0.4145
 Epoch [5/10], Step[260/483], loss: 0.3091
 Epoch [5/10], Step[270/483], loss: 0.3497
 Epoch [5/10], Step[280/483], loss: 0.4295
 Epoch [5/10], Step[290/483], loss: 0.3782
 Epoch [5/10], Step[300/483], loss: 0.4314
 Epoch [5/10], Step[310/483], loss: 0.3770
 Epoch [5/10], Step[320/483], loss: 0.3347
 Epoch [5/10], Step[330/483], loss: 0.3545
 Epoch [5/10], Step[340/483], loss: 0.3432
 Epoch [5/10], Step[350/483], loss: 0.3750
 Epoch [5/10], Step[360/483], loss: 0.3786
 Epoch [5/10], Step[370/483], loss: 0.3021
 Epoch [5/10], Step[380/483], loss: 0.4048
 Epoch [5/10], Step[390/483], loss: 0.3389
 Epoch [5/10], Step[400/483], loss: 0.3776
 Epoch [5/10], Step[410/483], loss: 0.5082
 Epoch [5/10], Step[420/483], loss: 0.3232
 Epoch [5/10], Step[430/483], loss: 0.5433
 Epoch [5/10], Step[440/483], loss: 0.4169
 Epoch [5/10], Step[450/483], loss: 0.3752
 Epoch [5/10], Step[460/483], loss: 0.3594
 Epoch [5/10], Step[470/483], loss: 0.3203
 Epoch [5/10], Step[480/483], loss: 0.3852
 ====> Epoch 5: Training loss: 180.8509
 Training Accuracy: 0.816874
 ====> Epoch 5: Validation loss: 21.3164
 Validation Accuracy: 0.828833
 Epoch [6/10], Step[0/483], loss: 0.3093
 Epoch [6/10], Step[10/483], loss: 0.4002
 Epoch [6/10], Step[20/483], loss: 0.3809
 Epoch [6/10], Step[30/483], loss: 0.4496
 Epoch [6/10], Step[40/483], loss: 0.3663
 Epoch [6/10], Step[50/483], loss: 0.3262
 Epoch [6/10], Step[60/483], loss: 0.3398
 Epoch [6/10], Step[70/483], loss: 0.2855
 Epoch [6/10], Step[80/483], loss: 0.3787
 Epoch [6/10], Step[90/483], loss: 0.3435
 Epoch [6/10], Step[100/483], loss: 0.3436
 Epoch [6/10], Step[110/483], loss: 0.3083
 Epoch [6/10], Step[120/483], loss: 0.3295
 Epoch [6/10], Step[130/483], loss: 0.4317
 Epoch [6/10], Step[140/483], loss: 0.2861
 Epoch [6/10], Step[150/483], loss: 0.3854
 Epoch [6/10], Step[160/483], loss: 0.2372
 Epoch [6/10], Step[170/483], loss: 0.3186
 Epoch [6/10], Step[180/483], loss: 0.2818
 Epoch [6/10], Step[190/483], loss: 0.5268
 Epoch [6/10], Step[200/483], loss: 0.3484
 Epoch [6/10], Step[210/483], loss: 0.3554
 Epoch [6/10], Step[220/483], loss: 0.2975
 Epoch [6/10], Step[230/483], loss: 0.3803
 Epoch [6/10], Step[240/483], loss: 0.3746
 Epoch [6/10], Step[250/483], loss: 0.4042
 Epoch [6/10], Step[260/483], loss: 0.2560
 Epoch [6/10], Step[270/483], loss: 0.2396
 Epoch [6/10], Step[280/483], loss: 0.2933
 Epoch [6/10], Step[290/483], loss: 0.3586
 Epoch [6/10], Step[300/483], loss: 0.3663
 Epoch [6/10], Step[310/483], loss: 0.3672
 Epoch [6/10], Step[320/483], loss: 0.2871
 Epoch [6/10], Step[330/483], loss: 0.3617
 Epoch [6/10], Step[340/483], loss: 0.2351
 Epoch [6/10], Step[350/483], loss: 0.3812
 Epoch [6/10], Step[360/483], loss: 0.2944
 Epoch [6/10], Step[370/483], loss: 0.3701
 Epoch [6/10], Step[380/483], loss: 0.3382
 Epoch [6/10], Step[390/483], loss: 0.3385
 Epoch [6/10], Step[400/483], loss: 0.3903
 Epoch [6/10], Step[410/483], loss: 0.3415
 Epoch [6/10], Step[420/483], loss: 0.2771
 Epoch [6/10], Step[430/483], loss: 0.3087
 Epoch [6/10], Step[440/483], loss: 0.3811
 Epoch [6/10], Step[450/483], loss: 0.3012
 Epoch [6/10], Step[460/483], loss: 0.4032
 Epoch [6/10], Step[470/483], loss: 0.3265
 Epoch [6/10], Step[480/483], loss: 0.3611
 ====> Epoch 6: Training loss: 160.9401
 Training Accuracy: 0.846025
 ====> Epoch 6: Validation loss: 19.6156
 Validation Accuracy: 0.844167
 Epoch [7/10], Step[0/483], loss: 0.3388
 Epoch [7/10], Step[10/483], loss: 0.3264
 Epoch [7/10], Step[20/483], loss: 0.3536
 Epoch [7/10], Step[30/483], loss: 0.3693
 Epoch [7/10], Step[40/483], loss: 0.2807
 Epoch [7/10], Step[50/483], loss: 0.3172
 Epoch [7/10], Step[60/483], loss: 0.2817
 Epoch [7/10], Step[70/483], loss: 0.2290
 Epoch [7/10], Step[80/483], loss: 0.3792
 Epoch [7/10], Step[90/483], loss: 0.3303
 Epoch [7/10], Step[100/483], loss: 0.4320
 Epoch [7/10], Step[110/483], loss: 0.3254
 Epoch [7/10], Step[120/483], loss: 0.3165
 Epoch [7/10], Step[130/483], loss: 0.3451
 Epoch [7/10], Step[140/483], loss: 0.3717
 Epoch [7/10], Step[150/483], loss: 0.2090
 Epoch [7/10], Step[160/483], loss: 0.3240
 Epoch [7/10], Step[170/483], loss: 0.2887
 Epoch [7/10], Step[180/483], loss: 0.3906
 Epoch [7/10], Step[190/483], loss: 0.4256
 Epoch [7/10], Step[200/483], loss: 0.3357
 Epoch [7/10], Step[210/483], loss: 0.3737
 Epoch [7/10], Step[220/483], loss: 0.3148
 Epoch [7/10], Step[230/483], loss: 0.3719
 Epoch [7/10], Step[240/483], loss: 0.3159
 Epoch [7/10], Step[250/483], loss: 0.2424
 Epoch [7/10], Step[260/483], loss: 0.3537
 Epoch [7/10], Step[270/483], loss: 0.2670
 Epoch [7/10], Step[280/483], loss: 0.3728
 Epoch [7/10], Step[290/483], loss: 0.3844
 Epoch [7/10], Step[300/483], loss: 0.3069
 Epoch [7/10], Step[310/483], loss: 0.4782
 Epoch [7/10], Step[320/483], loss: 0.2561
 Epoch [7/10], Step[330/483], loss: 0.3937
 Epoch [7/10], Step[340/483], loss: 0.3000
 Epoch [7/10], Step[350/483], loss: 0.3917
 Epoch [7/10], Step[360/483], loss: 0.2664
 Epoch [7/10], Step[370/483], loss: 0.3006
 Epoch [7/10], Step[380/483], loss: 0.2808
 Epoch [7/10], Step[390/483], loss: 0.3078
 Epoch [7/10], Step[400/483], loss: 0.4012
 Epoch [7/10], Step[410/483], loss: 0.3304
 Epoch [7/10], Step[420/483], loss: 0.2517
 Epoch [7/10], Step[430/483], loss: 0.3438
 Epoch [7/10], Step[440/483], loss: 0.2820
 Epoch [7/10], Step[450/483], loss: 0.2454
 Epoch [7/10], Step[460/483], loss: 0.3281
 Epoch [7/10], Step[470/483], loss: 0.3034
 Epoch [7/10], Step[480/483], loss: 0.2956
 ====> Epoch 7: Training loss: 151.9531
 Training Accuracy: 0.843209
 ====> Epoch 7: Validation loss: 17.9458
 Validation Accuracy: 0.851333
 Epoch [8/10], Step[0/483], loss: 0.2680
 Epoch [8/10], Step[10/483], loss: 0.3171
 Epoch [8/10], Step[20/483], loss: 0.3077
 Epoch [8/10], Step[30/483], loss: 0.2893
 Epoch [8/10], Step[40/483], loss: 0.2846
 Epoch [8/10], Step[50/483], loss: 0.2612
 Epoch [8/10], Step[60/483], loss: 0.3081
 Epoch [8/10], Step[70/483], loss: 0.2460
 Epoch [8/10], Step[80/483], loss: 0.4113
 Epoch [8/10], Step[90/483], loss: 0.2693
 Epoch [8/10], Step[100/483], loss: 0.2891
 Epoch [8/10], Step[110/483], loss: 0.3077
 Epoch [8/10], Step[120/483], loss: 0.3038
 Epoch [8/10], Step[130/483], loss: 0.2067
 Epoch [8/10], Step[140/483], loss: 0.3541
 Epoch [8/10], Step[150/483], loss: 0.2822
 Epoch [8/10], Step[160/483], loss: 0.4044
 Epoch [8/10], Step[170/483], loss: 0.3618
 Epoch [8/10], Step[180/483], loss: 0.3567
 Epoch [8/10], Step[190/483], loss: 0.4359
 Epoch [8/10], Step[200/483], loss: 0.2476
 Epoch [8/10], Step[210/483], loss: 0.2444
 Epoch [8/10], Step[220/483], loss: 0.2757
 Epoch [8/10], Step[230/483], loss: 0.2831
 Epoch [8/10], Step[240/483], loss: 0.2517
 Epoch [8/10], Step[250/483], loss: 0.2942
 Epoch [8/10], Step[260/483], loss: 0.2479
 Epoch [8/10], Step[270/483], loss: 0.2404
 Epoch [8/10], Step[280/483], loss: 0.2771
 Epoch [8/10], Step[290/483], loss: 0.3620
 Epoch [8/10], Step[300/483], loss: 0.2956
 Epoch [8/10], Step[310/483], loss: 0.2885
 Epoch [8/10], Step[320/483], loss: 0.2648
 Epoch [8/10], Step[330/483], loss: 0.4685
 Epoch [8/10], Step[340/483], loss: 0.2784
 Epoch [8/10], Step[350/483], loss: 0.3956
 Epoch [8/10], Step[360/483], loss: 0.3319
 Epoch [8/10], Step[370/483], loss: 0.2984
 Epoch [8/10], Step[380/483], loss: 0.3347
 Epoch [8/10], Step[390/483], loss: 0.3416
 Epoch [8/10], Step[400/483], loss: 0.4632
 Epoch [8/10], Step[410/483], loss: 0.2746
 Epoch [8/10], Step[420/483], loss: 0.2904
 Epoch [8/10], Step[430/483], loss: 0.3503
 Epoch [8/10], Step[440/483], loss: 0.2709
 Epoch [8/10], Step[450/483], loss: 0.3097
 Epoch [8/10], Step[460/483], loss: 0.2846
 Epoch [8/10], Step[470/483], loss: 0.2757
 Epoch [8/10], Step[480/483], loss: 0.2921
 ====> Epoch 8: Training loss: 144.3337
 Training Accuracy: 0.851222
 ====> Epoch 8: Validation loss: 17.8245
 Validation Accuracy: 0.849333
 Epoch [9/10], Step[0/483], loss: 0.2908
 Epoch [9/10], Step[10/483], loss: 0.2734
 Epoch [9/10], Step[20/483], loss: 0.2368
 Epoch [9/10], Step[30/483], loss: 0.2570
 Epoch [9/10], Step[40/483], loss: 0.2838
 Epoch [9/10], Step[50/483], loss: 0.2129
 Epoch [9/10], Step[60/483], loss: 0.3011
 Epoch [9/10], Step[70/483], loss: 0.2275
 Epoch [9/10], Step[80/483], loss: 0.4130
 Epoch [9/10], Step[90/483], loss: 0.2469
 Epoch [9/10], Step[100/483], loss: 0.2274
 Epoch [9/10], Step[110/483], loss: 0.2736
 Epoch [9/10], Step[120/483], loss: 0.1962
 Epoch [9/10], Step[130/483], loss: 0.1946
 Epoch [9/10], Step[140/483], loss: 0.2713
 Epoch [9/10], Step[150/483], loss: 0.2826
 Epoch [9/10], Step[160/483], loss: 0.2518
 Epoch [9/10], Step[170/483], loss: 0.2906
 Epoch [9/10], Step[180/483], loss: 0.3211
 Epoch [9/10], Step[190/483], loss: 0.2824
 Epoch [9/10], Step[200/483], loss: 0.3985
 Epoch [9/10], Step[210/483], loss: 0.2509
 Epoch [9/10], Step[220/483], loss: 0.3141
 Epoch [9/10], Step[230/483], loss: 0.2916
 Epoch [9/10], Step[240/483], loss: 0.3137
 Epoch [9/10], Step[250/483], loss: 0.3097
 Epoch [9/10], Step[260/483], loss: 0.1601
 Epoch [9/10], Step[270/483], loss: 0.2542
 Epoch [9/10], Step[280/483], loss: 0.3336
 Epoch [9/10], Step[290/483], loss: 0.3229
 Epoch [9/10], Step[300/483], loss: 0.2600
 Epoch [9/10], Step[310/483], loss: 0.3651
 Epoch [9/10], Step[320/483], loss: 0.3423
 Epoch [9/10], Step[330/483], loss: 0.3701
 Epoch [9/10], Step[340/483], loss: 0.2552
 Epoch [9/10], Step[350/483], loss: 0.4468
 Epoch [9/10], Step[360/483], loss: 0.2717
 Epoch [9/10], Step[370/483], loss: 0.2017
 Epoch [9/10], Step[380/483], loss: 0.3265
 Epoch [9/10], Step[390/483], loss: 0.3219
 Epoch [9/10], Step[400/483], loss: 0.3373
 Epoch [9/10], Step[410/483], loss: 0.3688
 Epoch [9/10], Step[420/483], loss: 0.2997
 Epoch [9/10], Step[430/483], loss: 0.2431
 Epoch [9/10], Step[440/483], loss: 0.3195
 Epoch [9/10], Step[450/483], loss: 0.2238
 Epoch [9/10], Step[460/483], loss: 0.3542
 Epoch [9/10], Step[470/483], loss: 0.3279
 Epoch [9/10], Step[480/483], loss: 0.3273
 ====> Epoch 9: Training loss: 142.7624
 Training Accuracy: 0.853085
 ====> Epoch 9: Validation loss: 17.4153
 Validation Accuracy: 0.859333
 Epoch [10/10], Step[0/483], loss: 0.3513
 Epoch [10/10], Step[10/483], loss: 0.2493
 Epoch [10/10], Step[20/483], loss: 0.2387
 Epoch [10/10], Step[30/483], loss: 0.2829
 Epoch [10/10], Step[40/483], loss: 0.2731
 Epoch [10/10], Step[50/483], loss: 0.1689
 Epoch [10/10], Step[60/483], loss: 0.3486
 Epoch [10/10], Step[70/483], loss: 0.2260
 Epoch [10/10], Step[80/483], loss: 0.3360
 Epoch [10/10], Step[90/483], loss: 0.3030
 Epoch [10/10], Step[100/483], loss: 0.2583
 Epoch [10/10], Step[110/483], loss: 0.2989
 Epoch [10/10], Step[120/483], loss: 0.2610
 Epoch [10/10], Step[130/483], loss: 0.3561
 Epoch [10/10], Step[140/483], loss: 0.2295
 Epoch [10/10], Step[150/483], loss: 0.3480
 Epoch [10/10], Step[160/483], loss: 0.3400
 Epoch [10/10], Step[170/483], loss: 0.2365
 Epoch [10/10], Step[180/483], loss: 0.2594
 Epoch [10/10], Step[190/483], loss: 0.3057
 Epoch [10/10], Step[200/483], loss: 0.2447
 Epoch [10/10], Step[210/483], loss: 0.2288
 Epoch [10/10], Step[220/483], loss: 0.3052
 Epoch [10/10], Step[230/483], loss: 0.3661
 Epoch [10/10], Step[240/483], loss: 0.2868
 Epoch [10/10], Step[250/483], loss: 0.3099
 Epoch [10/10], Step[260/483], loss: 0.1662
 Epoch [10/10], Step[270/483], loss: 0.3061
 Epoch [10/10], Step[280/483], loss: 0.3299
 Epoch [10/10], Step[290/483], loss: 0.3000
 Epoch [10/10], Step[300/483], loss: 0.3781
 Epoch [10/10], Step[310/483], loss: 0.3401
 Epoch [10/10], Step[320/483], loss: 0.2275
 Epoch [10/10], Step[330/483], loss: 0.2758
 Epoch [10/10], Step[340/483], loss: 0.2192
 Epoch [10/10], Step[350/483], loss: 0.3067
 Epoch [10/10], Step[360/483], loss: 0.2268
 Epoch [10/10], Step[370/483], loss: 0.3119
 Epoch [10/10], Step[380/483], loss: 0.2726
 Epoch [10/10], Step[390/483], loss: 0.3758
 Epoch [10/10], Step[400/483], loss: 0.2861
 Epoch [10/10], Step[410/483], loss: 0.3064
 Epoch [10/10], Step[420/483], loss: 0.2875
 Epoch [10/10], Step[430/483], loss: 0.2717
 Epoch [10/10], Step[440/483], loss: 0.3458
 Epoch [10/10], Step[450/483], loss: 0.2761
 Epoch [10/10], Step[460/483], loss: 0.3129
 Epoch [10/10], Step[470/483], loss: 0.3395
 Epoch [10/10], Step[480/483], loss: 0.3351
 ====> Epoch 10: Training loss: 138.0177
 Training Accuracy: 0.854720
 ====> Epoch 10: Validation loss: 17.7034
 Validation Accuracy: 0.850000
 Training Speaker0...
 Epoch [1/10], Step[0/483], loss: 7.0647
 Epoch [1/10], Step[10/483], loss: 2.8371
 Epoch [1/10], Step[20/483], loss: 2.2330
 Epoch [1/10], Step[30/483], loss: 1.9397
 Epoch [1/10], Step[40/483], loss: 1.8790
 Epoch [1/10], Step[50/483], loss: 1.9500
 Epoch [1/10], Step[60/483], loss: 1.9536
 Epoch [1/10], Step[70/483], loss: 1.6866
 Epoch [1/10], Step[80/483], loss: 1.8002
 Epoch [1/10], Step[90/483], loss: 1.2921
 Epoch [1/10], Step[100/483], loss: 1.2325
 Epoch [1/10], Step[110/483], loss: 1.4548
 Epoch [1/10], Step[120/483], loss: 1.5283
 Epoch [1/10], Step[130/483], loss: 1.2799
 Epoch [1/10], Step[140/483], loss: 1.4782
 Epoch [1/10], Step[150/483], loss: 1.4938
 Epoch [1/10], Step[160/483], loss: 1.6337
 Epoch [1/10], Step[170/483], loss: 1.0415
 Epoch [1/10], Step[180/483], loss: 1.4508
 Epoch [1/10], Step[190/483], loss: 1.4538
 Epoch [1/10], Step[200/483], loss: 1.0224
 Epoch [1/10], Step[210/483], loss: 1.2509
 Epoch [1/10], Step[220/483], loss: 1.1316
 Epoch [1/10], Step[230/483], loss: 1.0137
 Epoch [1/10], Step[240/483], loss: 1.2807
 Epoch [1/10], Step[250/483], loss: 1.3333
 Epoch [1/10], Step[260/483], loss: 0.8480
 Epoch [1/10], Step[270/483], loss: 1.2837
 Epoch [1/10], Step[280/483], loss: 1.0468
 Epoch [1/10], Step[290/483], loss: 0.9035
 Epoch [1/10], Step[300/483], loss: 1.2695
 Epoch [1/10], Step[310/483], loss: 1.2465
 Epoch [1/10], Step[320/483], loss: 1.3511
 Epoch [1/10], Step[330/483], loss: 1.2084
 Epoch [1/10], Step[340/483], loss: 1.2534
 Epoch [1/10], Step[350/483], loss: 1.2108
 Epoch [1/10], Step[360/483], loss: 0.9273
 Epoch [1/10], Step[370/483], loss: 0.7871
 Epoch [1/10], Step[380/483], loss: 1.0513
 Epoch [1/10], Step[390/483], loss: 1.1630
 Epoch [1/10], Step[400/483], loss: 1.1413
 Epoch [1/10], Step[410/483], loss: 0.9246
 Epoch [1/10], Step[420/483], loss: 1.0770
 Epoch [1/10], Step[430/483], loss: 1.0869
 Epoch [1/10], Step[440/483], loss: 1.1359
 Epoch [1/10], Step[450/483], loss: 0.9423
 Epoch [1/10], Step[460/483], loss: 1.2427
 Epoch [1/10], Step[470/483], loss: 1.3608
 Epoch [1/10], Step[480/483], loss: 0.7628
 ====> Epoch 1: Training loss: 675.5405
 ====> Epoch 1: Validation loss: 63.9203
 Epoch [2/10], Step[0/483], loss: 0.8972
 Epoch [2/10], Step[10/483], loss: 1.0401
 Epoch [2/10], Step[20/483], loss: 1.1358
 Epoch [2/10], Step[30/483], loss: 1.0570
 Epoch [2/10], Step[40/483], loss: 1.0950
 Epoch [2/10], Step[50/483], loss: 1.1826
 Epoch [2/10], Step[60/483], loss: 1.2742
 Epoch [2/10], Step[70/483], loss: 1.1301
 Epoch [2/10], Step[80/483], loss: 1.3131
 Epoch [2/10], Step[90/483], loss: 0.8842
 Epoch [2/10], Step[100/483], loss: 0.8620
 Epoch [2/10], Step[110/483], loss: 1.0591
 Epoch [2/10], Step[120/483], loss: 1.1313
 Epoch [2/10], Step[130/483], loss: 0.9297
 Epoch [2/10], Step[140/483], loss: 1.1008
 Epoch [2/10], Step[150/483], loss: 1.0946
 Epoch [2/10], Step[160/483], loss: 1.2541
 Epoch [2/10], Step[170/483], loss: 0.8041
 Epoch [2/10], Step[180/483], loss: 1.1428
 Epoch [2/10], Step[190/483], loss: 1.1230
 Epoch [2/10], Step[200/483], loss: 0.8125
 Epoch [2/10], Step[210/483], loss: 0.9866
 Epoch [2/10], Step[220/483], loss: 0.9042
 Epoch [2/10], Step[230/483], loss: 0.7899
 Epoch [2/10], Step[240/483], loss: 1.0338
 Epoch [2/10], Step[250/483], loss: 1.0386
 Epoch [2/10], Step[260/483], loss: 0.6662
 Epoch [2/10], Step[270/483], loss: 0.9791
 Epoch [2/10], Step[280/483], loss: 0.8549
 Epoch [2/10], Step[290/483], loss: 0.7197
 Epoch [2/10], Step[300/483], loss: 1.0382
 Epoch [2/10], Step[310/483], loss: 1.0289
 Epoch [2/10], Step[320/483], loss: 1.0961
 Epoch [2/10], Step[330/483], loss: 1.0009
 Epoch [2/10], Step[340/483], loss: 1.0292
 Epoch [2/10], Step[350/483], loss: 0.9815
 Epoch [2/10], Step[360/483], loss: 0.7460
 Epoch [2/10], Step[370/483], loss: 0.6439
 Epoch [2/10], Step[380/483], loss: 0.8831
 Epoch [2/10], Step[390/483], loss: 0.9803
 Epoch [2/10], Step[400/483], loss: 0.9469
 Epoch [2/10], Step[410/483], loss: 0.7473
 Epoch [2/10], Step[420/483], loss: 0.8996
 Epoch [2/10], Step[430/483], loss: 0.9193
 Epoch [2/10], Step[440/483], loss: 0.9328
 Epoch [2/10], Step[450/483], loss: 0.7715
 Epoch [2/10], Step[460/483], loss: 1.0503
 Epoch [2/10], Step[470/483], loss: 1.1114
 Epoch [2/10], Step[480/483], loss: 0.6451
 ====> Epoch 2: Training loss: 482.0576
 ====> Epoch 2: Validation loss: 57.8145
 Epoch [3/10], Step[0/483], loss: 0.7969
 Epoch [3/10], Step[10/483], loss: 0.9123
 Epoch [3/10], Step[20/483], loss: 0.9932
 Epoch [3/10], Step[30/483], loss: 0.9360
 Epoch [3/10], Step[40/483], loss: 0.9955
 Epoch [3/10], Step[50/483], loss: 1.0455
 Epoch [3/10], Step[60/483], loss: 1.1326
 Epoch [3/10], Step[70/483], loss: 1.0526
 Epoch [3/10], Step[80/483], loss: 1.1751
 Epoch [3/10], Step[90/483], loss: 0.7969
 Epoch [3/10], Step[100/483], loss: 0.7946
 Epoch [3/10], Step[110/483], loss: 0.9692
 Epoch [3/10], Step[120/483], loss: 1.0427
 Epoch [3/10], Step[130/483], loss: 0.8617
 Epoch [3/10], Step[140/483], loss: 0.9936
 Epoch [3/10], Step[150/483], loss: 0.9963
 Epoch [3/10], Step[160/483], loss: 1.1365
 Epoch [3/10], Step[170/483], loss: 0.7259
 Epoch [3/10], Step[180/483], loss: 1.0267
 Epoch [3/10], Step[190/483], loss: 1.0335
 Epoch [3/10], Step[200/483], loss: 0.7614
 Epoch [3/10], Step[210/483], loss: 0.9229
 Epoch [3/10], Step[220/483], loss: 0.8270
 Epoch [3/10], Step[230/483], loss: 0.7350
 Epoch [3/10], Step[240/483], loss: 0.9477
 Epoch [3/10], Step[250/483], loss: 0.9506
 Epoch [3/10], Step[260/483], loss: 0.6237
 Epoch [3/10], Step[270/483], loss: 0.9144
 Epoch [3/10], Step[280/483], loss: 0.8146
 Epoch [3/10], Step[290/483], loss: 0.6770
 Epoch [3/10], Step[300/483], loss: 0.9615
 Epoch [3/10], Step[310/483], loss: 0.9370
 Epoch [3/10], Step[320/483], loss: 1.0344
 Epoch [3/10], Step[330/483], loss: 0.9427
 Epoch [3/10], Step[340/483], loss: 0.9278
 Epoch [3/10], Step[350/483], loss: 0.9237
 Epoch [3/10], Step[360/483], loss: 0.6901
 Epoch [3/10], Step[370/483], loss: 0.6101
 Epoch [3/10], Step[380/483], loss: 0.8101
 Epoch [3/10], Step[390/483], loss: 0.8993
 Epoch [3/10], Step[400/483], loss: 0.9017
 Epoch [3/10], Step[410/483], loss: 0.7134
 Epoch [3/10], Step[420/483], loss: 0.8288
 Epoch [3/10], Step[430/483], loss: 0.8649
 Epoch [3/10], Step[440/483], loss: 0.8667
 Epoch [3/10], Step[450/483], loss: 0.7404
 Epoch [3/10], Step[460/483], loss: 0.9932
 Epoch [3/10], Step[470/483], loss: 1.0403
 Epoch [3/10], Step[480/483], loss: 0.6054
 ====> Epoch 3: Training loss: 442.7102
 ====> Epoch 3: Validation loss: 55.6737
 Epoch [4/10], Step[0/483], loss: 0.7543
 Epoch [4/10], Step[10/483], loss: 0.8592
 Epoch [4/10], Step[20/483], loss: 0.9230
 Epoch [4/10], Step[30/483], loss: 0.8816
 Epoch [4/10], Step[40/483], loss: 0.9294
 Epoch [4/10], Step[50/483], loss: 0.9779
 Epoch [4/10], Step[60/483], loss: 1.0588
 Epoch [4/10], Step[70/483], loss: 0.9468
 Epoch [4/10], Step[80/483], loss: 1.0903
 Epoch [4/10], Step[90/483], loss: 0.7490
 Epoch [4/10], Step[100/483], loss: 0.7634
 Epoch [4/10], Step[110/483], loss: 0.9067
 Epoch [4/10], Step[120/483], loss: 0.9843
 Epoch [4/10], Step[130/483], loss: 0.8118
 Epoch [4/10], Step[140/483], loss: 0.9377
 Epoch [4/10], Step[150/483], loss: 0.9426
 Epoch [4/10], Step[160/483], loss: 1.0508
 Epoch [4/10], Step[170/483], loss: 0.6812
 Epoch [4/10], Step[180/483], loss: 0.9701
 Epoch [4/10], Step[190/483], loss: 0.9926
 Epoch [4/10], Step[200/483], loss: 0.7172
 Epoch [4/10], Step[210/483], loss: 0.8895
 Epoch [4/10], Step[220/483], loss: 0.7850
 Epoch [4/10], Step[230/483], loss: 0.7177
 Epoch [4/10], Step[240/483], loss: 0.8653
 Epoch [4/10], Step[250/483], loss: 0.9128
 Epoch [4/10], Step[260/483], loss: 0.5986
 Epoch [4/10], Step[270/483], loss: 0.8632
 Epoch [4/10], Step[280/483], loss: 0.7792
 Epoch [4/10], Step[290/483], loss: 0.6422
 Epoch [4/10], Step[300/483], loss: 0.9143
 Epoch [4/10], Step[310/483], loss: 0.8744
 Epoch [4/10], Step[320/483], loss: 0.9707
 Epoch [4/10], Step[330/483], loss: 0.8836
 Epoch [4/10], Step[340/483], loss: 0.8715
 Epoch [4/10], Step[350/483], loss: 0.8804
 Epoch [4/10], Step[360/483], loss: 0.6512
 Epoch [4/10], Step[370/483], loss: 0.5886
 Epoch [4/10], Step[380/483], loss: 0.7682
 Epoch [4/10], Step[390/483], loss: 0.8623
 Epoch [4/10], Step[400/483], loss: 0.8498
 Epoch [4/10], Step[410/483], loss: 0.6969
 Epoch [4/10], Step[420/483], loss: 0.7816
 Epoch [4/10], Step[430/483], loss: 0.8197
 Epoch [4/10], Step[440/483], loss: 0.8236
 Epoch [4/10], Step[450/483], loss: 0.7008
 Epoch [4/10], Step[460/483], loss: 0.9468
 Epoch [4/10], Step[470/483], loss: 0.9831
 Epoch [4/10], Step[480/483], loss: 0.5826
 ====> Epoch 4: Training loss: 419.3972
 ====> Epoch 4: Validation loss: 55.2476
 Epoch [5/10], Step[0/483], loss: 0.7241
 Epoch [5/10], Step[10/483], loss: 0.8380
 Epoch [5/10], Step[20/483], loss: 0.8970
 Epoch [5/10], Step[30/483], loss: 0.8413
 Epoch [5/10], Step[40/483], loss: 0.8763
 Epoch [5/10], Step[50/483], loss: 0.9410
 Epoch [5/10], Step[60/483], loss: 1.0189
 Epoch [5/10], Step[70/483], loss: 0.9141
 Epoch [5/10], Step[80/483], loss: 1.0429
 Epoch [5/10], Step[90/483], loss: 0.7225
 Epoch [5/10], Step[100/483], loss: 0.7436
 Epoch [5/10], Step[110/483], loss: 0.8663
 Epoch [5/10], Step[120/483], loss: 0.9533
 Epoch [5/10], Step[130/483], loss: 0.7872
 Epoch [5/10], Step[140/483], loss: 0.9159
 Epoch [5/10], Step[150/483], loss: 0.9108
 Epoch [5/10], Step[160/483], loss: 1.0013
 Epoch [5/10], Step[170/483], loss: 0.6696
 Epoch [5/10], Step[180/483], loss: 0.9519
 Epoch [5/10], Step[190/483], loss: 0.9604
 Epoch [5/10], Step[200/483], loss: 0.6967
 Epoch [5/10], Step[210/483], loss: 0.8532
 Epoch [5/10], Step[220/483], loss: 0.7568
 Epoch [5/10], Step[230/483], loss: 0.6888
 Epoch [5/10], Step[240/483], loss: 0.8437
 Epoch [5/10], Step[250/483], loss: 0.8726
 Epoch [5/10], Step[260/483], loss: 0.5804
 Epoch [5/10], Step[270/483], loss: 0.8400
 Epoch [5/10], Step[280/483], loss: 0.7700
 Epoch [5/10], Step[290/483], loss: 0.6192
 Epoch [5/10], Step[300/483], loss: 0.8850
 Epoch [5/10], Step[310/483], loss: 0.8634
 Epoch [5/10], Step[320/483], loss: 0.9427
 Epoch [5/10], Step[330/483], loss: 0.8603
 Epoch [5/10], Step[340/483], loss: 0.8483
 Epoch [5/10], Step[350/483], loss: 0.8392
 Epoch [5/10], Step[360/483], loss: 0.6379
 Epoch [5/10], Step[370/483], loss: 0.5608
 Epoch [5/10], Step[380/483], loss: 0.7435
 Epoch [5/10], Step[390/483], loss: 0.8512
 Epoch [5/10], Step[400/483], loss: 0.8054
 Epoch [5/10], Step[410/483], loss: 0.6703
 Epoch [5/10], Step[420/483], loss: 0.7758
 Epoch [5/10], Step[430/483], loss: 0.7971
 Epoch [5/10], Step[440/483], loss: 0.7922
 Epoch [5/10], Step[450/483], loss: 0.6734
 Epoch [5/10], Step[460/483], loss: 0.9309
 Epoch [5/10], Step[470/483], loss: 0.9502
 Epoch [5/10], Step[480/483], loss: 0.5709
 ====> Epoch 5: Training loss: 405.2595
 ====> Epoch 5: Validation loss: 54.8599
 Epoch [6/10], Step[0/483], loss: 0.7107
 Epoch [6/10], Step[10/483], loss: 0.8125
 Epoch [6/10], Step[20/483], loss: 0.8608
 Epoch [6/10], Step[30/483], loss: 0.8162
 Epoch [6/10], Step[40/483], loss: 0.8523
 Epoch [6/10], Step[50/483], loss: 0.8995
 Epoch [6/10], Step[60/483], loss: 0.9812
 Epoch [6/10], Step[70/483], loss: 0.8779
 Epoch [6/10], Step[80/483], loss: 1.0123
 Epoch [6/10], Step[90/483], loss: 0.6989
 Epoch [6/10], Step[100/483], loss: 0.7134
 Epoch [6/10], Step[110/483], loss: 0.8382
 Epoch [6/10], Step[120/483], loss: 0.9303
 Epoch [6/10], Step[130/483], loss: 0.7712
 Epoch [6/10], Step[140/483], loss: 0.8941
 Epoch [6/10], Step[150/483], loss: 0.9018
 Epoch [6/10], Step[160/483], loss: 0.9750
 Epoch [6/10], Step[170/483], loss: 0.6620
 Epoch [6/10], Step[180/483], loss: 0.9148
 Epoch [6/10], Step[190/483], loss: 0.9314
 Epoch [6/10], Step[200/483], loss: 0.6877
 Epoch [6/10], Step[210/483], loss: 0.8427
 Epoch [6/10], Step[220/483], loss: 0.7527
 Epoch [6/10], Step[230/483], loss: 0.6861
 Epoch [6/10], Step[240/483], loss: 0.8181
 Epoch [6/10], Step[250/483], loss: 0.8711
 Epoch [6/10], Step[260/483], loss: 0.5725
 Epoch [6/10], Step[270/483], loss: 0.8302
 Epoch [6/10], Step[280/483], loss: 0.7364
 Epoch [6/10], Step[290/483], loss: 0.6049
 Epoch [6/10], Step[300/483], loss: 0.8621
 Epoch [6/10], Step[310/483], loss: 0.8515
 Epoch [6/10], Step[320/483], loss: 0.9340
 Epoch [6/10], Step[330/483], loss: 0.8330
 Epoch [6/10], Step[340/483], loss: 0.8300
 Epoch [6/10], Step[350/483], loss: 0.7985
 Epoch [6/10], Step[360/483], loss: 0.6340
 Epoch [6/10], Step[370/483], loss: 0.5572
 Epoch [6/10], Step[380/483], loss: 0.7305
 Epoch [6/10], Step[390/483], loss: 0.8312
 Epoch [6/10], Step[400/483], loss: 0.7992
 Epoch [6/10], Step[410/483], loss: 0.6646
 Epoch [6/10], Step[420/483], loss: 0.7509
 Epoch [6/10], Step[430/483], loss: 0.7918
 Epoch [6/10], Step[440/483], loss: 0.7862
 Epoch [6/10], Step[450/483], loss: 0.6558
 Epoch [6/10], Step[460/483], loss: 0.9108
 Epoch [6/10], Step[470/483], loss: 0.9048
 Epoch [6/10], Step[480/483], loss: 0.5597
 ====> Epoch 6: Training loss: 395.2671
 ====> Epoch 6: Validation loss: 54.6989
 Epoch [7/10], Step[0/483], loss: 0.7081
 Epoch [7/10], Step[10/483], loss: 0.8117
 Epoch [7/10], Step[20/483], loss: 0.8612
 Epoch [7/10], Step[30/483], loss: 0.7956
 Epoch [7/10], Step[40/483], loss: 0.8372
 Epoch [7/10], Step[50/483], loss: 0.8866
 Epoch [7/10], Step[60/483], loss: 0.9645
 Epoch [7/10], Step[70/483], loss: 0.8826
 Epoch [7/10], Step[80/483], loss: 0.9954
 Epoch [7/10], Step[90/483], loss: 0.6928
 Epoch [7/10], Step[100/483], loss: 0.7069
 Epoch [7/10], Step[110/483], loss: 0.8398
 Epoch [7/10], Step[120/483], loss: 0.9011
 Epoch [7/10], Step[130/483], loss: 0.7505
 Epoch [7/10], Step[140/483], loss: 0.8754
 Epoch [7/10], Step[150/483], loss: 0.8596
 Epoch [7/10], Step[160/483], loss: 0.9368
 Epoch [7/10], Step[170/483], loss: 0.6428
 Epoch [7/10], Step[180/483], loss: 0.9247
 Epoch [7/10], Step[190/483], loss: 0.9067
 Epoch [7/10], Step[200/483], loss: 0.6713
 Epoch [7/10], Step[210/483], loss: 0.8133
 Epoch [7/10], Step[220/483], loss: 0.7371
 Epoch [7/10], Step[230/483], loss: 0.6683
 Epoch [7/10], Step[240/483], loss: 0.8046
 Epoch [7/10], Step[250/483], loss: 0.8549
 Epoch [7/10], Step[260/483], loss: 0.5641
 Epoch [7/10], Step[270/483], loss: 0.8161
 Epoch [7/10], Step[280/483], loss: 0.7238
 Epoch [7/10], Step[290/483], loss: 0.5932
 Epoch [7/10], Step[300/483], loss: 0.8454
 Epoch [7/10], Step[310/483], loss: 0.8237
 Epoch [7/10], Step[320/483], loss: 0.9233
 Epoch [7/10], Step[330/483], loss: 0.8276
 Epoch [7/10], Step[340/483], loss: 0.8254
 Epoch [7/10], Step[350/483], loss: 0.7996
 Epoch [7/10], Step[360/483], loss: 0.6234
 Epoch [7/10], Step[370/483], loss: 0.5393
 Epoch [7/10], Step[380/483], loss: 0.7029
 Epoch [7/10], Step[390/483], loss: 0.8079
 Epoch [7/10], Step[400/483], loss: 0.7837
 Epoch [7/10], Step[410/483], loss: 0.6572
 Epoch [7/10], Step[420/483], loss: 0.7544
 Epoch [7/10], Step[430/483], loss: 0.7862
 Epoch [7/10], Step[440/483], loss: 0.7705
 Epoch [7/10], Step[450/483], loss: 0.6624
 Epoch [7/10], Step[460/483], loss: 0.8903
 Epoch [7/10], Step[470/483], loss: 0.8963
 Epoch [7/10], Step[480/483], loss: 0.5455
 ====> Epoch 7: Training loss: 387.8095
 ====> Epoch 7: Validation loss: 54.7692
 Epoch [8/10], Step[0/483], loss: 0.7095
 Epoch [8/10], Step[10/483], loss: 0.8041
 Epoch [8/10], Step[20/483], loss: 0.8416
 Epoch [8/10], Step[30/483], loss: 0.7868
 Epoch [8/10], Step[40/483], loss: 0.8165
 Epoch [8/10], Step[50/483], loss: 0.8594
 Epoch [8/10], Step[60/483], loss: 0.9490
 Epoch [8/10], Step[70/483], loss: 0.8543
 Epoch [8/10], Step[80/483], loss: 0.9892
 Epoch [8/10], Step[90/483], loss: 0.6718
 Epoch [8/10], Step[100/483], loss: 0.6983
 Epoch [8/10], Step[110/483], loss: 0.8329
 Epoch [8/10], Step[120/483], loss: 0.8922
 Epoch [8/10], Step[130/483], loss: 0.7416
 Epoch [8/10], Step[140/483], loss: 0.8668
 Epoch [8/10], Step[150/483], loss: 0.8631
 Epoch [8/10], Step[160/483], loss: 0.9228
 Epoch [8/10], Step[170/483], loss: 0.6371
 Epoch [8/10], Step[180/483], loss: 0.8918
 Epoch [8/10], Step[190/483], loss: 0.8937
 Epoch [8/10], Step[200/483], loss: 0.6681
 Epoch [8/10], Step[210/483], loss: 0.8200
 Epoch [8/10], Step[220/483], loss: 0.7078
 Epoch [8/10], Step[230/483], loss: 0.6638
 Epoch [8/10], Step[240/483], loss: 0.8031
 Epoch [8/10], Step[250/483], loss: 0.8532
 Epoch [8/10], Step[260/483], loss: 0.5505
 Epoch [8/10], Step[270/483], loss: 0.8129
 Epoch [8/10], Step[280/483], loss: 0.7222
 Epoch [8/10], Step[290/483], loss: 0.5817
 Epoch [8/10], Step[300/483], loss: 0.8267
 Epoch [8/10], Step[310/483], loss: 0.8135
 Epoch [8/10], Step[320/483], loss: 0.8956
 Epoch [8/10], Step[330/483], loss: 0.8090
 Epoch [8/10], Step[340/483], loss: 0.8067
 Epoch [8/10], Step[350/483], loss: 0.7956
 Epoch [8/10], Step[360/483], loss: 0.6128
 Epoch [8/10], Step[370/483], loss: 0.5482
 Epoch [8/10], Step[380/483], loss: 0.7005
 Epoch [8/10], Step[390/483], loss: 0.8036
 Epoch [8/10], Step[400/483], loss: 0.7664
 Epoch [8/10], Step[410/483], loss: 0.6360
 Epoch [8/10], Step[420/483], loss: 0.7249
 Epoch [8/10], Step[430/483], loss: 0.7912
 Epoch [8/10], Step[440/483], loss: 0.7596
 Epoch [8/10], Step[450/483], loss: 0.6345
 Epoch [8/10], Step[460/483], loss: 0.8844
 Epoch [8/10], Step[470/483], loss: 0.8910
 Epoch [8/10], Step[480/483], loss: 0.5409
 ====> Epoch 8: Training loss: 382.1021
 ====> Epoch 8: Validation loss: 54.8232
 Epoch [9/10], Step[0/483], loss: 0.6911
 Epoch [9/10], Step[10/483], loss: 0.7968
 Epoch [9/10], Step[20/483], loss: 0.8322
 Epoch [9/10], Step[30/483], loss: 0.7685
 Epoch [9/10], Step[40/483], loss: 0.8093
 Epoch [9/10], Step[50/483], loss: 0.8208
 Epoch [9/10], Step[60/483], loss: 0.9372
 Epoch [9/10], Step[70/483], loss: 0.8596
 Epoch [9/10], Step[80/483], loss: 0.9561
 Epoch [9/10], Step[90/483], loss: 0.6672
 Epoch [9/10], Step[100/483], loss: 0.6959
 Epoch [9/10], Step[110/483], loss: 0.8150
 Epoch [9/10], Step[120/483], loss: 0.8761
 Epoch [9/10], Step[130/483], loss: 0.7263
 Epoch [9/10], Step[140/483], loss: 0.8676
 Epoch [9/10], Step[150/483], loss: 0.8572
 Epoch [9/10], Step[160/483], loss: 0.9138
 Epoch [9/10], Step[170/483], loss: 0.6277
 Epoch [9/10], Step[180/483], loss: 0.8949
 Epoch [9/10], Step[190/483], loss: 0.8873
 Epoch [9/10], Step[200/483], loss: 0.6635
 Epoch [9/10], Step[210/483], loss: 0.8029
 Epoch [9/10], Step[220/483], loss: 0.7000
 Epoch [9/10], Step[230/483], loss: 0.6522
 Epoch [9/10], Step[240/483], loss: 0.7721
 Epoch [9/10], Step[250/483], loss: 0.8438
 Epoch [9/10], Step[260/483], loss: 0.5562
 Epoch [9/10], Step[270/483], loss: 0.8203
 Epoch [9/10], Step[280/483], loss: 0.7165
 Epoch [9/10], Step[290/483], loss: 0.5671
 Epoch [9/10], Step[300/483], loss: 0.8386
 Epoch [9/10], Step[310/483], loss: 0.8153
 Epoch [9/10], Step[320/483], loss: 0.8774
 Epoch [9/10], Step[330/483], loss: 0.8077
 Epoch [9/10], Step[340/483], loss: 0.8093
 Epoch [9/10], Step[350/483], loss: 0.7697
 Epoch [9/10], Step[360/483], loss: 0.6103
 Epoch [9/10], Step[370/483], loss: 0.5338
 Epoch [9/10], Step[380/483], loss: 0.6850
 Epoch [9/10], Step[390/483], loss: 0.8090
 Epoch [9/10], Step[400/483], loss: 0.7567
 Epoch [9/10], Step[410/483], loss: 0.6340
 Epoch [9/10], Step[420/483], loss: 0.7051
 Epoch [9/10], Step[430/483], loss: 0.7630
 Epoch [9/10], Step[440/483], loss: 0.7501
 Epoch [9/10], Step[450/483], loss: 0.6352
 Epoch [9/10], Step[460/483], loss: 0.8784
 Epoch [9/10], Step[470/483], loss: 0.8834
 Epoch [9/10], Step[480/483], loss: 0.5376
 ====> Epoch 9: Training loss: 377.3709
 ====> Epoch 9: Validation loss: 54.7704
 Epoch [10/10], Step[0/483], loss: 0.6887
 Epoch [10/10], Step[10/483], loss: 0.8010
 Epoch [10/10], Step[20/483], loss: 0.8390
 Epoch [10/10], Step[30/483], loss: 0.7678
 Epoch [10/10], Step[40/483], loss: 0.7958
 Epoch [10/10], Step[50/483], loss: 0.8425
 Epoch [10/10], Step[60/483], loss: 0.9150
 Epoch [10/10], Step[70/483], loss: 0.8503
 Epoch [10/10], Step[80/483], loss: 0.9604
 Epoch [10/10], Step[90/483], loss: 0.6574
 Epoch [10/10], Step[100/483], loss: 0.6690
 Epoch [10/10], Step[110/483], loss: 0.8092
 Epoch [10/10], Step[120/483], loss: 0.8723
 Epoch [10/10], Step[130/483], loss: 0.7310
 Epoch [10/10], Step[140/483], loss: 0.8373
 Epoch [10/10], Step[150/483], loss: 0.8286
 Epoch [10/10], Step[160/483], loss: 0.9290
 Epoch [10/10], Step[170/483], loss: 0.6090
 Epoch [10/10], Step[180/483], loss: 0.8729
 Epoch [10/10], Step[190/483], loss: 0.8682
 Epoch [10/10], Step[200/483], loss: 0.6410
 Epoch [10/10], Step[210/483], loss: 0.7968
 Epoch [10/10], Step[220/483], loss: 0.7063
 Epoch [10/10], Step[230/483], loss: 0.6675
 Epoch [10/10], Step[240/483], loss: 0.7879
 Epoch [10/10], Step[250/483], loss: 0.8323
 Epoch [10/10], Step[260/483], loss: 0.5406
 Epoch [10/10], Step[270/483], loss: 0.8038
 Epoch [10/10], Step[280/483], loss: 0.7159
 Epoch [10/10], Step[290/483], loss: 0.5691
 Epoch [10/10], Step[300/483], loss: 0.8079
 Epoch [10/10], Step[310/483], loss: 0.7884
 Epoch [10/10], Step[320/483], loss: 0.8800
 Epoch [10/10], Step[330/483], loss: 0.7990
 Epoch [10/10], Step[340/483], loss: 0.7931
 Epoch [10/10], Step[350/483], loss: 0.7595
 Epoch [10/10], Step[360/483], loss: 0.6081
 Epoch [10/10], Step[370/483], loss: 0.5349
 Epoch [10/10], Step[380/483], loss: 0.6900
 Epoch [10/10], Step[390/483], loss: 0.7814
 Epoch [10/10], Step[400/483], loss: 0.7430
 Epoch [10/10], Step[410/483], loss: 0.6332
 Epoch [10/10], Step[420/483], loss: 0.7244
 Epoch [10/10], Step[430/483], loss: 0.7692
 Epoch [10/10], Step[440/483], loss: 0.7497
 Epoch [10/10], Step[450/483], loss: 0.6299
 Epoch [10/10], Step[460/483], loss: 0.8608
 Epoch [10/10], Step[470/483], loss: 0.8741
 Epoch [10/10], Step[480/483], loss: 0.5285
 ====> Epoch 10: Training loss: 373.4394
 ====> Epoch 10: Validation loss: 55.0597
 SamplingSpeaker1Model: SamplingSpeaker1Model(
  (listener0): Listener0Model(
    (scene_encoder): LinearSceneEncoder(
      (fc): Linear(in_features=280, out_features=100)
    )
    (string_encoder): LinearStringEncoder(
      (fc): Linear(in_features=1063, out_features=100)
    )
    (scorer): MLPScorer(
      (dropout): Dropout(p=0.3)
      (linear_4): Linear(in_features=100, out_features=100)
      (linear_5): Linear(in_features=100, out_features=100)
      (linear_3): Linear(in_features=100, out_features=1)
    )
  )
  (speaker0): Speaker0Model(
    (scene_encoder): LinearSceneEncoder(
      (fc): Linear(in_features=280, out_features=100)
    )
    (string_decoder): LSTMStringDecoder(
      (embedding): Embedding(1063, 100)
      (lstm): LSTM(100, 100, num_layers=2, batch_first=True, dropout=0.3)
      (linear): Linear(in_features=100, out_features=1063)
      (dropout): Dropout(p=0.3)
    )
  )
)
 Saved model to models/ss1237.pth
